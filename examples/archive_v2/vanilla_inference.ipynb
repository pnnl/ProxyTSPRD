{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b516849a-1ff0-4930-972e-fbbbed72e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import nvtx\n",
    "\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------- CUSTOM FUNCTIONS ------------------------------------------------\n",
    "# Custom Library\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "    \n",
    "from proxy_apps.apps.timeseries_prediction import deepDMD, proxyDeepDMD, proxyDeepDMDMGPU, proxyDeepDMDPyTorch, hyperparameters\n",
    "\n",
    "from proxy_apps.utils.tf import TimingCallback\n",
    "from proxy_apps.utils.data.main import NpEncoder\n",
    "from proxy_apps.utils import file_reader, path_handler\n",
    "from proxy_apps.utils.data.grid import GridNetworkDataHandler, GridNetworkTFDataHandler, GridNetworkNewGen, GridDataGenPyTorch\n",
    "\n",
    "\n",
    "import functools\n",
    "import math\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "# from tensorflow.keras.utils import Progbar\n",
    "\n",
    "# ------------------------------- CUSTOM FUNCTIONS ------------------------------------------------\n",
    "# Custom Library\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "    \n",
    "from proxy_apps.apps.timeseries_prediction import hyperparameters, deepDMD, proxyDeepDMD, proxyDeepDMDMGPU, proxyDeepDMDPyTorch\n",
    "\n",
    "from proxy_apps.utils.tf import TimingCallback\n",
    "from proxy_apps.utils.data.main import NpEncoder\n",
    "from proxy_apps.utils import file_reader, path_handler\n",
    "from proxy_apps.utils.data.grid import GridNetworkDataHandler, GridNetworkTFDataHandler, GridNetworkNewGen, TransientDataset, GridDataGenPyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8378f783-5d63-4874-aad5-9f226add1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Setup\n",
    "config = file_reader.read_config()\n",
    "\n",
    "_N_EPOCHS = 20\n",
    "_BATCH_SIZE = 65536\n",
    "_APP_NAME = config[\"info\"][\"app_name\"]\n",
    "_NROWS = int(config[\"data\"][\"n_rows\"])\n",
    "_NCOLS = int(config[\"data\"][\"n_cols\"])\n",
    "_REPEAT_COLS = int(config[\"data\"][\"repeat_cols\"])\n",
    "_WINDOW_SIZE = int(config[\"data\"][\"window_size\"])\n",
    "_SHIFT_SIZE = int(config[\"data\"][\"shift_size\"])\n",
    "_STRIDE = int(config[\"data\"][\"stride\"])\n",
    "_N_SIGNALS = int(config[\"data\"][\"n_signals\"])\n",
    "\n",
    "_DTYPE = config[\"model\"][\"dtype\"]\n",
    "\n",
    "_MIXED_PRECISION = False\n",
    "_ONNX_IMPL = True\n",
    "_INFERENCE_BS = 8192\n",
    "\n",
    "_N_GPUS = 1\n",
    "_N_CPUS = 16\n",
    "\n",
    "_LABEL = \"Baseline\"\n",
    "_SUFFIX =  \"gpu\" + '_' + \\\n",
    "            \"a100\" + '_' + \\\n",
    "            'ng' + str(_N_GPUS) + '_' + \\\n",
    "            'nc' + str(_N_CPUS) + '_' + \\\n",
    "            'e' + str(_N_EPOCHS) + '_' + \\\n",
    "            'b' + str(_BATCH_SIZE) + '_' + \\\n",
    "            'r' + str(_REPEAT_COLS) + '_' + \\\n",
    "            'mp' + str(0) + '_' + _LABEL\n",
    "\n",
    "performance_dict = dict()\n",
    "\n",
    "# current directory\n",
    "curr_dir = \"./\"\n",
    "\n",
    "# output directory\n",
    "output_dir = path_handler.get_absolute_path(curr_dir, config[\"info\"][\"data_dir\"] + config[\"info\"][\"name\"] + \"/\" + config[\"info\"][\"app_name\"] + \"/\" + _DTYPE + \"/R\" + str(_REPEAT_COLS) + \"/\")\n",
    "model_dir = path_handler.get_absolute_path(curr_dir, config[\"model\"][\"model_dir\"] + config[\"info\"][\"name\"] + \"/\" + config[\"info\"][\"app_name\"] + \"/\" + _DTYPE + \"/R\" + str(_REPEAT_COLS) + \"/\")\n",
    "\n",
    "hyper_param_dict = config[\"model\"][\"hyperparameters\"]\n",
    "hyper_param_dict['original_dim']       = _REPEAT_COLS * _NCOLS   # input data dimension\n",
    "hyper_param_dict['num_epochs']         = _N_EPOCHS  # Number of epochs  \n",
    "hyper_param_dict['batch_size']         = _BATCH_SIZE\n",
    "\n",
    "hyper_param_dict['dtype']         = _DTYPE\n",
    "hp = hyperparameters.HyperParameters(hyper_param_dict)\n",
    "hp.model_name         = _LABEL\n",
    "\n",
    "performance_dict[\"n_epochs\"] = hp.ep\n",
    "performance_dict[\"batch_size\"] = hp.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37563530-d7ba-4b03-bf23-8873cdcf8098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow version:  2.4.0\n",
      "[INFO] Eager mode:  True\n"
     ]
    }
   ],
   "source": [
    "if _LABEL == \"PyTorch\":\n",
    "    import torch\n",
    "    print(\"[INFO] PyTorch version: \", torch.__version__)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    \n",
    "    if _DTYPE == \"float64\": torch.set_default_dtype(torch.float64)\n",
    "    else: torch.set_default_dtype(torch.float32)\n",
    "        \n",
    "    def get_indexer(n_rows, window_size, shift_size, start_point, leave_last):\n",
    "        return np.arange(window_size)[None, :] + start_point + shift_size*np.arange(((n_rows - window_size - leave_last - start_point) // shift_size) + 1)[:, None]\n",
    "else:   \n",
    "    import tensorflow as tf\n",
    "    import tf2onnx\n",
    "\n",
    "    # TensorFlow Setup\n",
    "    print(\"[INFO] Tensorflow version: \", tf.__version__)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    for gpu in logical_gpus:\n",
    "        print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)\n",
    "\n",
    "    # tf.compat.v1.disable_eager_execution()\n",
    "    print(\"[INFO] Eager mode: \", tf.executing_eagerly()) # For easy reset of notebook state.\n",
    "\n",
    "    # Setup TensorFlow\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "\n",
    "    # Setup Precision\n",
    "    if _LABEL in [\"Baseline\"]: \n",
    "        tf.keras.backend.set_floatx('float64')\n",
    "    elif _LABEL in [\"TFDataGen\", \"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "        tf.keras.backend.set_floatx(_DTYPE)\n",
    "        if _MIXED_PRECISION:\n",
    "            # set floatx\n",
    "            _DTYPE = 'float32'\n",
    "            hp.d_type         = _DTYPE\n",
    "            tf.keras.backend.set_floatx(_DTYPE)\n",
    "            # set policy\n",
    "            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            # check dtypes\n",
    "            print('Compute dtype: %s' % policy.compute_dtype)\n",
    "            print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "    # Mirror Strategy for MGPUs\n",
    "    if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "        mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    # To avoid GPU Congestion\n",
    "    os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\"\n",
    "\n",
    "    @tf.function(experimental_compile=True)\n",
    "    def get_indexer(n_rows, window_size, shift_size, start_point, leave_last):\n",
    "        return np.arange(window_size)[None, :] + start_point + shift_size*np.arange(((n_rows - window_size - leave_last - start_point) // shift_size) + 1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e05de25-cc30-4bf5-9663-235fe7880211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading the datasets from the directory: /qfs/people/jain432/pacer/data/TrainingDataIEEE68bus\n",
      "[INFO]: Loading data for 30 scenarios ...\n",
      "[INFO]: Loaded 30/30 scenarios ...\n",
      "[INFO]: Total number of scenarios loaded: 30\n",
      "[INFO]: Shape of each scenario loaded:  (1400, 1360)\n",
      "[INFO]: Done ...\n",
      "Done processing 30/30 datasets ...\n",
      "[INFO]: Original dataset size: 1400\n",
      "[INFO]: Chosen dataset size: 800\n",
      "[INFO]: Length of X_data:  1800\n",
      "[INFO]: Length of each window after down sampling:  (800, 1360)\n",
      "[INFO]: X_array shape:  (1440000, 1360)\n",
      "[INFO]: Y_array shape:  (1440000, 1360)\n",
      "680\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------- CREATE DATA HANDLER ------------------------------------------------   \n",
    "\n",
    "data_handler_nvtx = nvtx.start_range(\"Create Data Handler\")\n",
    "dh_start = time.time()    \n",
    "inp_data_dir = config[\"info\"][\"input_dir\"]\n",
    "if _LABEL in [\"Baseline\", \"TFDataOpt\"]:\n",
    "    data_handler = GridNetworkDataHandler(scenario_dir=path_handler.get_absolute_path(curr_dir, inp_data_dir),\n",
    "                                            n_rows=_NROWS,\n",
    "                                            n_cols=_NCOLS,\n",
    "                                            repeat_cols=_REPEAT_COLS,\n",
    "                                            dtype=_DTYPE\n",
    "                                         ) \n",
    "\n",
    "    scenario_data = data_handler.load_grid_data()\n",
    "\n",
    "    # ------------------------------- DATA PREPROCESSING ------------------------------------------------\n",
    "\n",
    "    # Yp, Yf = data_handler.create_inference_windows(scenario_data)\n",
    "    X_data, Y_data = data_handler.create_windows(scenario_data)\n",
    "\n",
    "    # ------------------------------- DATA NORMALIZATION ------------------------------------------------\n",
    "\n",
    "    # Yp_array, Yf_array = data_handler.scale_inference_data(Yp, Yf)\n",
    "    X_array, Y_array = data_handler.scale_data(X_data, Y_data)\n",
    "\n",
    "elif _LABEL in [\"TFDataGen\", \"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "    if _ONNX_IMPL:\n",
    "        data_handler = GridNetworkDataHandler(scenario_dir=path_handler.get_absolute_path(curr_dir, inp_data_dir),\n",
    "                                            n_rows=_NROWS,\n",
    "                                            n_cols=_NCOLS,\n",
    "                                            repeat_cols=_REPEAT_COLS,\n",
    "                                            dtype=_DTYPE\n",
    "                                         ) \n",
    "\n",
    "        scenario_data = data_handler.load_grid_data()\n",
    "\n",
    "        # ------------------------------- DATA PREPROCESSING ------------------------------------------------\n",
    "\n",
    "        # Yp, Yf = data_handler.create_inference_windows(scenario_data)\n",
    "        X_data, Y_data = data_handler.create_windows(scenario_data)\n",
    "\n",
    "        # ------------------------------- DATA NORMALIZATION ------------------------------------------------\n",
    "\n",
    "        # Yp_array, Yf_array = data_handler.scale_inference_data(Yp, Yf)\n",
    "        X_array, Y_array = data_handler.scale_data(X_data, Y_data)\n",
    "    else:\n",
    "        data_handler = GridNetworkNewGen(scenario_dir=path_handler.get_absolute_path(curr_dir, inp_data_dir),\n",
    "                                                n_rows=_NROWS,\n",
    "                                                n_cols=_NCOLS,\n",
    "                                                repeat_cols=_REPEAT_COLS,\n",
    "                                                d_type=_DTYPE\n",
    "                                             )\n",
    "\n",
    "        # yp_indexer = get_indexer(_NROWS, _NROWS-1, _SHIFT_SIZE, 0, 1)\n",
    "        # yf_indexer = get_indexer(_NROWS, _NROWS-1, _SHIFT_SIZE, 1, 0)\n",
    "        x_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 0, _N_SIGNALS)\n",
    "        y_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 1, 0)\n",
    "\n",
    "        # scenario_data = data_handler.get_training_data(yp_indexer, yf_indexer)\n",
    "        scenario_data = data_handler.get_training_data(x_indexer, y_indexer, deterministic=True)\n",
    "    \n",
    "elif _LABEL == \"PyTorch\":\n",
    "    if _ONNX_IMPL:\n",
    "        data_handler = GridNetworkDataHandler(scenario_dir=path_handler.get_absolute_path(curr_dir, inp_data_dir),\n",
    "                                            n_rows=_NROWS,\n",
    "                                            n_cols=_NCOLS,\n",
    "                                            repeat_cols=_REPEAT_COLS,\n",
    "                                            dtype=_DTYPE\n",
    "                                         ) \n",
    "\n",
    "        scenario_data = data_handler.load_grid_data()\n",
    "\n",
    "        # ------------------------------- DATA PREPROCESSING ------------------------------------------------\n",
    "\n",
    "        # Yp, Yf = data_handler.create_inference_windows(scenario_data)\n",
    "        X_data, Y_data = data_handler.create_windows(scenario_data)\n",
    "\n",
    "        # ------------------------------- DATA NORMALIZATION ------------------------------------------------\n",
    "\n",
    "        # Yp_array, Yf_array = data_handler.scale_inference_data(Yp, Yf)\n",
    "        X_array, Y_array = data_handler.scale_data(X_data, Y_data)\n",
    "    else:\n",
    "        scenario_dir=path_handler.get_absolute_path(curr_dir, inp_data_dir)\n",
    "        dir_list = [scenario_dir + \"/\" + f + \"/\" for f in os.listdir(scenario_dir)[:3]]\n",
    "\n",
    "        # yp_indexer = get_indexer(_NROWS, _NROWS-1, _SHIFT_SIZE, 0, 1)\n",
    "        # yf_indexer = get_indexer(_NROWS, _NROWS-1, _SHIFT_SIZE, 1, 0)\n",
    "        x_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 0, _N_SIGNALS)\n",
    "        y_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 1, 0)\n",
    "\n",
    "        # test_size = yp_indexer.shape[0] * yp_indexer.shape[1] * len(dir_list)\n",
    "        test_size = x_indexer.shape[0] * x_indexer.shape[1] * len(dir_list)\n",
    "\n",
    "        # dataset = GridDataGenPyTorch(dir_list, _NROWS, _NCOLS, _REPEAT_COLS, yp_indexer, yf_indexer)\n",
    "        # test_dataloader = torch.utils.data.DataLoader(dataset, batch_size=test_size)  \n",
    "        test_data = GridDataGenPyTorch(dir_list, _NROWS, _NCOLS, _REPEAT_COLS, x_indexer, y_indexer)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=_INFERENCE_BS)    \n",
    "\n",
    "dh_stop = time.time()\n",
    "performance_dict['data_handler_time'] = dh_stop-dh_start\n",
    "nvtx.end_range(data_handler_nvtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b13f113-f81d-42c7-9b9a-42b8cb5d2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in scenario_data:\n",
    "#     print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8181663-662f-4900-982e-84f9bc89d152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/qfs/people/jain432/pacer/models/deepDMD/power_systems/scenarios_30/float64/R10/gpu_a100_ng1_nc16_e20_b65536_r10_mp0_Baseline'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_handler.get_absolute_path(model_dir, _SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a0fb25e-9c46-4be0-ab6d-032feadb5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_model = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir, _SUFFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e97c80c-ba6a-4b02-9447-0565f22cce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n",
      "(1, 1424)\n",
      "(1, 1424)\n",
      "0.0008125413080226986 0.0005938154345194646\n"
     ]
    }
   ],
   "source": [
    "freq_pred_error_list = []\n",
    "vol_pred_error_list = []\n",
    "for X_actual in scenario_data:\n",
    "    X = X_actual[500:502, :]\n",
    "    X_scaled = X.copy()\n",
    "    \n",
    "    # normalize the data\n",
    "    scale_factor = 2*np.pi\n",
    "    X_scaled[:, :1360//2]  = scale_factor * (X[:, :1360//2] - 60)\n",
    "    X_scaled[:, 1360//2:] = 10 * (X[:, 1360//2:] - 1)\n",
    "    \n",
    "    Psi_X = K_model.encoder(X_scaled[:1, :], training=False)\n",
    "    PSI_X = tf.concat([X_scaled[:1, :], tf.cast(Psi_X, hp.d_type)], 1)\n",
    "    # 1-time step evolution on observable space:\n",
    "    prediction = np.matmul(PSI_X, K_model.KO)\n",
    "    print(prediction.shape)\n",
    "    \n",
    "    true_freq = X[1:2, :68]\n",
    "    pred_freq = 60 + (1 / scale_factor) * prediction[:, :68]\n",
    "    freq_pred_error = np.sqrt(np.mean(np.square(true_freq - pred_freq)))\n",
    "    freq_pred_error_list.append(freq_pred_error)\n",
    "    \n",
    "    true_voltage = X[1:2, (1360//2):(1360//2)+68]\n",
    "    pred_voltage = 1 + 0.1 * prediction[:, (1360//2):(1360//2)+68]\n",
    "    vol_pred_error = np.sqrt(np.mean(np.square(true_voltage - pred_voltage)))\n",
    "    vol_pred_error_list.append(vol_pred_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d800b4e-07f8-479a-9520-6ede80bbb5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c409c839-6292-4689-877c-fe3f14c69d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a06b4fda-9559-4fae-8fe7-3e99bafa6087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n",
      "(1, 1424)\n",
      "(1, 1424)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47b5d7f5-fbc2-4abf-b09f-66cdfe2c7924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2777f3a-5b68-48d0-afa4-dfe0e37ad7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00081254])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7671b94-f268-466f-9f58-8d1e4750de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Shape of Koopman operator (1424, 1424)\n",
      "[INFO]: Norm of Koopman operator 70.98882296316371\n",
      "[INFO]: Trace of K_deepDMD: 1.5469405504898734\n",
      "[Output] Largest 10 eigenvalues of the Koopman operator\n",
      "------------------------------\n",
      "[1.9204 1.9204 1.9106 1.9106 1.9092 1.9092 1.907  1.907  1.898  1.898 ]\n"
     ]
    }
   ],
   "source": [
    "K_deepDMD = K_model.KO.numpy()\n",
    "\n",
    "print('[INFO]: Shape of Koopman operator', K_deepDMD.shape)\n",
    "print('[INFO]: Norm of Koopman operator', np.linalg.norm(K_deepDMD))\n",
    "print('[INFO]: Trace of K_deepDMD:',np.trace(K_deepDMD))\n",
    "# print('[INFO]: One time-step error with K_deepDMD:', np.linalg.norm(PSI_Y - np.matmul(PSI_X, K_deepDMD), ord = 'fro'))\n",
    "\n",
    "[eigenvaluesK,eigenvectorsK] = np.linalg.eig(K_deepDMD)\n",
    "abs_eigenvaluesK = np.absolute(eigenvaluesK)#.tolist()\n",
    "abs_eigenvaluesK_sorted = np.sort(abs_eigenvaluesK)[::-1]\n",
    "idx_eigenvaluesK_sorted = np.argsort(abs_eigenvaluesK)[::-1]\n",
    "largest_n_eigenvalues = 10\n",
    "print('[Output] Largest', largest_n_eigenvalues, 'eigenvalues of the Koopman operator')\n",
    "print('------------------------------')\n",
    "print(np.around(abs_eigenvaluesK_sorted[0:largest_n_eigenvalues], decimals = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "700a2c39-57f7-47dd-8cf8-c70cb90fc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = X_actual[500:510, :68]\n",
    "pred = 60+(1/scale_factor)*X_pred[:10, :68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aaebe85-f3c3-439a-83cf-c516113c504b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(10), true, 'b')\n",
    "plt.plot(np.arange(10), pred, 'r--',linewidth = 2)\n",
    "plt.title('On the State space - Scenario ')\n",
    "plt.show()\n",
    "\n",
    "# # plt.plot(data_window,o_Vm_data[range(end_point,end_point+nts)],'b')\n",
    "# # plt.plot(data_window,1+0.1*X_pred[:,68:136],'r--',linewidth = 2)\n",
    "# # plt.title('On the State space - Scenario ' + str(test_scen))\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e064710-f175-4197-9011-4f3bea2f0ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.057815352290281e+274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(true, pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c71dc2a-a314-44d4-9604-ba370ecfadeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 9.65616669e-003, 2.07179200e-002, 3.75780811e-002,\n",
       "       6.12440790e-002, 1.27602093e-001, 2.29879532e-001, 4.35198597e-001,\n",
       "       8.24004207e-001, 1.39730700e+000, 2.69679589e+000, 5.84655630e+000,\n",
       "       9.72277080e+000, 1.81053659e+001, 3.73180334e+001, 6.69535214e+001,\n",
       "       1.32555647e+002, 2.61161190e+002, 3.96884313e+002, 8.06158536e+002,\n",
       "       1.83645822e+003, 3.20054837e+003, 6.20718965e+003, 1.20719771e+004,\n",
       "       2.07534562e+004, 4.10688361e+004, 7.19871885e+004, 1.53811179e+005,\n",
       "       2.69766790e+005, 4.91426212e+005, 9.68226650e+005, 1.58623739e+006,\n",
       "       3.58302874e+006, 7.56450489e+006, 1.14666510e+007, 2.18726765e+007,\n",
       "       5.41491589e+007, 8.87063742e+007, 1.79814748e+008, 3.19105983e+008,\n",
       "       6.90047239e+008, 1.03311916e+009, 2.27082205e+009, 3.61793400e+009,\n",
       "       8.75143148e+009, 1.57012471e+010, 2.82327980e+010, 5.97161914e+010,\n",
       "       9.61283365e+010, 1.73269518e+011, 2.97867659e+011, 6.61004429e+011,\n",
       "       1.47162292e+012, 2.49639850e+012, 5.28658440e+012, 9.00179704e+012,\n",
       "       1.63417094e+013, 3.77069636e+013, 5.17867256e+013, 1.14097274e+014,\n",
       "       2.20877659e+014, 4.44210683e+014, 8.65247023e+014, 1.67237873e+015,\n",
       "       3.43266902e+015, 4.99100706e+015, 9.73588861e+015, 2.04830382e+016,\n",
       "       3.12518456e+016, 7.56274129e+016, 1.52233578e+017, 2.88766629e+017,\n",
       "       4.70617973e+017, 1.02106139e+018, 1.77507539e+018, 2.66035121e+018,\n",
       "       6.51728684e+018, 1.21090429e+019, 2.52880174e+019, 5.24848805e+019,\n",
       "       1.03377061e+020, 1.87117271e+020, 3.03551213e+020, 5.57373865e+020,\n",
       "       9.98397684e+020, 1.85718303e+021, 4.34573917e+021, 9.26045138e+021,\n",
       "       1.73375576e+022, 3.37205852e+022, 6.88272267e+022, 1.08120979e+023,\n",
       "       1.76798391e+023, 3.78223397e+023, 7.31589117e+023, 1.47009071e+024,\n",
       "       3.02268070e+024, 6.72823326e+024, 1.14880393e+025, 2.07217602e+025,\n",
       "       3.88635086e+025, 6.52402308e+025, 1.21943872e+026, 2.80245268e+026,\n",
       "       5.44592124e+026, 1.04266163e+027, 2.15338010e+027, 3.99104612e+027,\n",
       "       6.12258735e+027, 1.18363934e+028, 2.32304648e+028, 4.34105772e+028,\n",
       "       9.20121880e+028, 2.00295422e+029, 3.94172788e+029, 6.56919647e+029,\n",
       "       1.41657481e+030, 2.10731600e+030, 3.97755280e+030, 7.73090671e+030,\n",
       "       1.62726499e+031, 3.30609573e+031, 6.88474975e+031, 1.41771104e+032,\n",
       "       2.41088835e+032, 4.26476326e+032, 8.90315233e+032, 1.32734570e+033,\n",
       "       2.79375151e+033, 5.72540504e+033, 1.29403570e+034, 2.41900529e+034,\n",
       "       4.56871158e+034, 9.26497765e+034, 1.26098952e+035, 2.70540730e+035,\n",
       "       5.49881910e+035, 1.05573337e+036, 2.19201709e+036, 4.53321827e+036,\n",
       "       9.36879386e+036, 1.49293092e+037, 2.70126789e+037, 5.18290139e+037,\n",
       "       7.44029422e+037, 1.85053599e+038, 3.79076306e+038, 8.22598766e+038,\n",
       "       1.52895843e+039, 3.09638216e+039, 5.82800945e+039, 8.04296094e+039,\n",
       "       1.77784033e+040, 3.13527249e+040, 6.30739181e+040, 1.35363211e+041,\n",
       "       2.98174327e+041, 5.73766173e+041, 9.70245049e+041, 1.89464253e+042,\n",
       "       3.34416337e+042, 5.09213953e+042, 1.23067000e+043, 2.34798523e+043,\n",
       "       5.10190017e+043, 9.83014258e+043, 2.07803232e+044, 3.51329646e+044,\n",
       "       5.88923443e+044, 1.13863676e+045, 1.90399123e+045, 4.07336415e+045,\n",
       "       9.31095817e+045, 1.92409389e+046, 3.64798090e+046, 6.92742953e+046,\n",
       "       1.29950253e+047, 1.90708969e+047, 3.39503686e+047, 7.49259128e+047,\n",
       "       1.47977988e+048, 3.25611207e+048, 6.79464991e+048, 1.35478577e+049,\n",
       "       2.22531925e+049, 4.18913443e+049, 7.39907906e+049, 1.18309457e+050,\n",
       "       2.56451891e+050, 5.71567757e+050, 1.20591080e+051, 2.27610357e+051,\n",
       "       4.62851917e+051, 7.99941652e+051, 1.25795871e+052, 2.51831564e+052,\n",
       "       4.86527135e+052, 9.54388077e+052, 2.05926178e+053, 4.39685386e+053,\n",
       "       8.49207584e+053, 1.43338237e+054, 2.84417765e+054, 4.35660894e+054,\n",
       "       7.96602028e+054, 1.70970797e+055, 3.74991700e+055, 7.65544729e+055,\n",
       "       1.53262058e+056, 3.13450973e+056, 5.15165346e+056, 8.88236581e+056,\n",
       "       1.66423725e+057, 2.80013452e+057, 6.07439182e+057, 1.35350934e+058,\n",
       "       2.90393527e+058, 5.40245570e+058, 1.01198335e+059, 1.92811619e+059,\n",
       "       2.75111042e+059, 5.49032983e+059, 1.09007451e+060, 2.32970002e+060,\n",
       "       4.81749260e+060, 1.01651686e+061, 2.00706626e+061, 3.24034449e+061,\n",
       "       5.98288463e+061, 1.05999113e+062, 1.83221943e+062, 4.17892013e+062,\n",
       "       8.82613095e+062, 1.85756089e+063, 3.47869291e+063, 6.81271856e+063,\n",
       "       1.19095417e+064, 1.77730978e+064, 3.69944309e+064, 6.82195089e+064,\n",
       "       1.49234707e+065, 3.20657448e+065, 6.79498162e+065, 1.27833183e+066,\n",
       "       2.20498732e+066, 4.20023185e+066, 6.70478858e+066, 1.17764556e+067,\n",
       "       2.61365376e+067, 5.57093440e+067, 1.17899454e+068, 2.33217378e+068,\n",
       "       4.59137085e+068, 7.67050941e+068, 1.29903198e+069, 2.50731421e+069,\n",
       "       4.27654022e+069, 9.47935833e+069, 2.06888789e+070, 4.40452336e+070,\n",
       "       8.12726620e+070, 1.52602528e+071, 2.71281517e+071, 4.11337045e+071,\n",
       "       7.94596944e+071, 1.74001387e+072, 3.60828752e+072, 7.61987657e+072,\n",
       "       1.56740092e+073, 3.01059163e+073, 4.91292140e+073, 8.85322638e+073,\n",
       "       1.53111492e+074, 2.73061878e+074, 6.17247775e+074, 1.36385290e+075,\n",
       "       2.83751966e+075, 5.33952518e+075, 1.03484594e+076, 1.75590700e+076,\n",
       "       2.82868236e+076, 5.47351543e+076, 1.07200139e+077, 2.27122177e+077,\n",
       "       4.89720476e+077, 1.03155920e+078, 1.91515450e+078, 3.32693950e+078,\n",
       "       6.15717288e+078, 9.96453901e+078, 1.87492109e+079, 4.04824625e+079,\n",
       "       8.73525810e+079, 1.80449983e+080, 3.54143878e+080, 6.90969436e+080,\n",
       "       1.11916571e+081, 1.94286770e+081, 3.53952958e+081, 6.73241207e+081,\n",
       "       1.48507896e+082, 3.25657862e+082, 6.75092204e+082, 1.24482485e+083,\n",
       "       2.29939414e+083, 4.06113073e+083, 6.14371710e+083, 1.22141601e+084,\n",
       "       2.55838729e+084, 5.61251051e+084, 1.16896791e+085, 2.39250085e+085,\n",
       "       4.50482131e+085, 7.36834593e+085, 1.34286414e+086, 2.31236370e+086,\n",
       "       4.35820183e+086, 9.61770573e+086, 2.09896088e+087, 4.33416821e+087,\n",
       "       8.14626998e+087, 1.54022119e+088, 2.58652483e+088, 4.19796211e+088,\n",
       "       8.48001289e+088, 1.66519611e+089, 3.61593854e+089, 7.63399987e+089,\n",
       "       1.57874003e+090, 2.89653478e+090, 4.99442319e+090, 9.04990443e+090,\n",
       "       1.45328611e+091, 2.82960467e+091, 6.26106864e+091, 1.36438469e+092,\n",
       "       2.79945528e+092, 5.46165769e+092, 1.03578516e+093, 1.70476104e+093,\n",
       "       2.90009921e+093, 5.39923608e+093, 1.02920598e+094, 2.30617924e+094,\n",
       "       4.99729553e+094, 1.03183166e+095, 1.89139926e+095, 3.44788548e+095,\n",
       "       5.96978602e+095, 9.50411342e+095, 1.89724755e+096, 4.04615362e+096,\n",
       "       8.73347659e+096, 1.80857335e+097, 3.65148996e+097, 6.72970251e+097,\n",
       "       1.11091972e+098, 1.96160647e+098, 3.48192050e+098, 6.81229472e+098,\n",
       "       1.52076480e+099, 3.28244256e+099, 6.68082599e+099, 1.24758057e+100,\n",
       "       2.32340828e+100, 3.83880628e+100, 6.37706893e+100, 1.24813254e+101,\n",
       "       2.57150823e+101, 5.61057486e+101, 1.18963044e+102, 2.41438175e+102,\n",
       "       4.37593352e+102, 7.61756133e+102, 1.35127286e+103, 2.23876759e+103,\n",
       "       4.40747480e+103, 9.68878702e+103, 2.11016099e+104, 4.29904298e+104,\n",
       "       8.33350345e+104, 1.54859328e+105, 2.52571998e+105, 4.40353442e+105,\n",
       "       8.19929130e+105, 1.64943625e+106, 3.62230945e+106, 7.77942074e+106,\n",
       "       1.57791985e+107, 2.86854995e+107, 5.17374445e+107, 8.74918932e+107,\n",
       "       1.43136748e+108, 2.91950781e+108, 6.32457042e+108, 1.37173045e+109,\n",
       "       2.81215888e+109, 5.58486526e+109, 1.01691285e+110, 1.67338210e+110,\n",
       "       2.96372614e+110, 5.21237177e+110, 1.06185737e+111, 2.34807485e+111,\n",
       "       5.09379770e+111, 1.02465066e+112, 1.90372724e+112, 3.48267258e+112,\n",
       "       5.76521767e+112, 9.78623360e+112, 1.94031196e+113, 4.02071406e+113,\n",
       "       8.77081420e+113, 1.83509950e+114, 3.67705669e+114, 6.60408426e+114,\n",
       "       1.13800556e+115, 2.00157950e+115, 3.39723362e+115, 6.95968330e+115,\n",
       "       1.52724346e+116, 3.29948890e+116, 6.63687641e+116, 1.27284674e+117,\n",
       "       2.32012595e+117, 3.78328788e+117, 6.54605408e+117, 1.24133337e+118,\n",
       "       2.57427010e+118, 5.69932165e+118, 1.21015186e+119, 2.41570861e+119,\n",
       "       4.37423381e+119, 7.77942794e+119, 1.31196769e+120, 2.19541271e+120,\n",
       "       4.51765211e+120, 9.81596459e+120, 2.12989532e+121, 4.34303300e+121,\n",
       "       8.51031761e+121, 1.52165191e+122, 2.52677135e+122, 4.45253201e+122,\n",
       "       8.10922016e+122, 1.67218209e+123, 3.68816574e+123, 7.89018775e+123,\n",
       "       1.56903360e+124, 2.89530400e+124, 5.19873889e+124, 8.55765173e+124,\n",
       "       1.48264509e+125, 2.98433841e+125, 6.34565741e+125, 1.37576007e+126,\n",
       "       2.85012849e+126, 5.61633546e+126, 9.98288229e+126, 1.71796869e+127,\n",
       "       2.96751557e+127, 5.18331578e+127, 1.07780741e+128, 2.38776813e+128,\n",
       "       5.13205082e+128, 1.02311544e+129, 1.94136252e+129, 3.48269257e+129,\n",
       "       5.69991091e+129, 9.98179576e+129, 1.91285140e+130, 4.04839543e+130,\n",
       "       8.87311717e+130, 1.87071679e+131, 3.68530369e+131, 6.61348360e+131,\n",
       "       1.16404893e+132, 1.95099422e+132, 3.40429600e+132, 7.08823907e+132,\n",
       "       1.54666531e+133, 3.32078052e+133, 6.70148079e+133, 1.29388606e+134,\n",
       "       2.28410165e+134, 3.78219887e+134, 6.66253838e+134, 1.23894283e+135,\n",
       "       2.63385526e+135, 5.78391924e+135, 1.22627229e+136, 2.40646251e+136,\n",
       "       4.40331206e+136, 7.80975824e+136, 1.28333795e+137, 2.26335490e+137,\n",
       "       4.59122564e+137, 9.91616661e+137, 2.14539656e+138, 4.40633019e+138])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.square(true - pred), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c73479ea-eaa9-4d28-8989-9d2f584332e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60.01310509 60.01336733 60.01314312 ... 59.99460114 59.99529744\n",
      "  60.02425645]\n",
      " [60.01344439 60.01357317 60.01375692 ... 59.99262008 59.99467266\n",
      "  60.02449405]\n",
      " [60.01377608 60.01381505 60.01438396 ... 59.99070123 59.99414582\n",
      "  60.02465385]\n",
      " ...\n",
      " [60.00188673 60.00238885 60.00230898 ... 59.99857115 59.99841384\n",
      "  59.99920727]\n",
      " [60.00188124 60.00240226 60.00231099 ... 59.99865476 59.99848123\n",
      "  59.99917263]\n",
      " [60.00186805 60.00240533 60.00230555 ... 59.99874176 59.9985525\n",
      "  59.99914048]] [[ 6.00131051e+001  6.00133673e+001  6.00131431e+001 ...  5.99946011e+001\n",
      "   5.99952974e+001  6.00242564e+001]\n",
      " [ 5.23520841e+001  5.31601054e+001  4.21695576e+001 ...  1.14842250e+001\n",
      "  -3.21080663e+001  4.75087245e+001]\n",
      " [ 1.60425428e+001  4.88396267e+001  5.94919817e+001 ... -1.71939106e+001\n",
      "  -3.68478594e+001 -2.77801854e+001]\n",
      " ...\n",
      " [ 3.53269393e+140  3.56417289e+140  2.86604119e+140 ...  7.04071245e+140\n",
      "  -6.68837845e+140  3.01041118e+140]\n",
      " [-1.05768470e+141 -6.08804032e+140 -2.09264852e+140 ... -1.66261728e+141\n",
      "   1.04690974e+141 -1.78915784e+140]\n",
      " [ 4.47398391e+141  9.95432112e+140 -1.13603559e+141 ...  3.75483122e+141\n",
      "  -3.16909558e+141  5.25831758e+140]]\n"
     ]
    }
   ],
   "source": [
    "print(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c4ba60b-5b1c-446d-8520-cc0c8147beaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1360)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample[:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a5661d8-fbc5-492d-ac6f-21942554d36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 64), dtype=float64, numpy=\n",
       "array([[ 0.03889353,  0.15695275, -0.25292904,  0.02416481, -0.18614257,\n",
       "         0.1662427 ,  0.1466191 ,  0.16321775,  0.1741261 , -0.32866705,\n",
       "        -0.04944772,  0.05444738, -0.08701353, -0.06137395,  0.34878444,\n",
       "        -0.04926592, -0.0297088 ,  0.20480288, -0.242424  ,  0.01968326,\n",
       "        -0.25172332,  0.0125362 ,  0.15993956,  0.27172054,  0.18000747,\n",
       "         0.0254842 , -0.16951441, -0.01228959, -0.24354125,  0.38447215,\n",
       "        -0.11373239,  0.17380006,  0.15021436,  0.0398318 , -0.10002584,\n",
       "        -0.10465889, -0.18138068,  0.25041057, -0.26153101, -0.37674222,\n",
       "         0.12404643, -0.13294811, -0.34491756,  0.05624561, -0.09973732,\n",
       "         0.18106083,  0.30097408,  0.34590279,  0.15482867, -0.05668979,\n",
       "        -0.41749866, -0.07513196,  0.25742234,  0.00975031,  0.17803908,\n",
       "        -0.05197487, -0.13980094, -0.23909916, -0.12063594,  0.12663973,\n",
       "        -0.43254519, -0.14235045, -0.07235258,  0.4691693 ]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cc918af-8748-4fb1-9616-09618c46fa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/qfs/people/jain432/pacer/models/deepDMD/power_systems/scenarios_30/float64/R10/gpu_a100_ng1_nc16_e20_b65536_r10_mp0_TFDataOptMGPU.onnx\n",
      "Inference Time:  74.76259231567383\n",
      "Koopman loss:  [1476.5338332118351, 1474.8093597151374, 1474.5320823898232, 1474.5763575231156, 1474.7359027087903, 1475.951769929042, 1475.0850525814446, 1473.0086336115896, 1472.3111791246201, 1472.621995109185, 1472.903957167874, 1474.360071340889, 1475.596292695343, 1474.4028614287174, 1474.4828487683835, 1474.6730729537292, 1474.7500992400733, 1475.2339871506408, 1475.9549024396242, 1474.6690226722294, 1474.4767677510943, 1474.616022122719, 1474.8522554288618, 1478.0056700486175, 1476.9376093979286, 1475.9047156134357, 1475.322150335797, 1475.2023403560893, 1475.326457350214, 1473.6336035068398, 1472.3300447748888, 1472.6811655773488, 1473.2565175264872, 1473.6485487674183, 1474.0333558932664, 1474.3672978470022, 1474.0621591643692, 1474.1584866045862, 1474.5070208071184, 1474.816712651875, 1475.0250530166925, 1483.019162633953, 1475.577789906995, 1471.4433656925685, 1471.393246867244, 1471.6203662846472, 1472.394172164002, 1473.47993069266, 1473.3575040450062, 1473.498637183546, 1473.7995425751858, 1474.151344847411, 1474.7000240791865, 1475.473548233557, 1475.3991867498748, 1475.52720254019, 1475.6204722948833, 1475.6781271256016, 1476.0313275908509, 1475.5055608236617, 1474.0410355296726, 1474.0062111443824, 1474.1822087001242, 1474.4666381821357, 1501.3959968988788, 1494.7228209615862, 1477.7852440843571, 1471.4928106265006, 1469.3489857356544, 1469.1488045521921, 1473.9854885504403, 1473.858508381746, 1472.7716377899635, 1472.86781285117, 1473.2935246677366, 1473.7099017751445, 1491.014164282288, 1479.023054411452, 1470.5039236587618, 1469.0823009729274, 1469.013791863647, 1469.8531499721462, 1478.7286523601722, 1475.669443428265, 1474.714603987915, 1474.7207158113488, 1474.9281222093277, 1476.9825195026103, 1478.1067475130667, 1474.5043124487738, 1473.0107092049561, 1473.1102568213923, 1473.230246306013, 1477.3069041280714, 1481.4332881405885, 1478.9462544545545, 1477.8122089681947, 1477.2826190428145, 1477.104519939839, 1483.34955455496, 1487.1952769754541, 1478.936283173198, 1475.7281367509995, 1475.0231619411902, 1474.87464474117, 1475.4140471073442, 1475.2442911225257, 1475.3292601896226, 1475.4541764503974, 1475.5671746637074, 1475.6514895516614, 1481.642323181026, 1478.7573631215425, 1477.2008194409607, 1476.343035998058, 1476.0947650509772, 1476.0128788002658, 1488.0322091423939, 1483.0068130634086, 1479.9179447250597, 1478.4476296804771, 1477.7164753376735, 1477.4476669732692, 1477.8989804209968, 1474.016454108062, 1473.1166609812278, 1472.9780044596507, 1473.1878044122127, 1473.8893891530245, 1476.1134305168637, 1476.0727547898384, 1476.061831033512, 1476.0384329422568, 1476.0355540343119, 1478.3217248777394, 1477.1439357838362, 1473.9478813808885, 1472.8206947712733, 1472.8875502436174, 1473.08394429192, 1474.9776391745131, 1472.0443832433375, 1469.422375437677, 1470.0245621736774, 1470.7623378632463, 1471.418880623411, 1477.3593898621177, 1477.9604100067402, 1476.5002841304038, 1476.1604449280537, 1476.0686809787528, 1476.0279264072608, 1480.7795239352538, 1476.841159976239, 1473.9526297340235, 1472.969580069499, 1473.2295002547357, 1473.64843171238, 1492.0012827482535, 1484.1026129016966, 1477.1995368351747, 1475.624966334246, 1474.436950916813, 1474.3011640787104, 1474.2682983379846, 1474.060783563253, 1473.891259546245, 1474.2555368587991, 1474.4908262205945, 1474.7134020444778, 1473.4607210913452, 1471.207130234179, 1471.2590419746527, 1471.9749186368604, 1472.513848862107]\n",
      "Psi_X shape: (8192, 64)\n",
      "Psi_Y shape: (8192, 64)\n",
      "PSI_X shape: (8192, 1424)\n",
      "PSI_X shape: (8192, 1424)\n",
      "[INFO]: Shape of Koopman operator (1424, 1424)\n",
      "[INFO]: Norm of Koopman operator 70.99352780538425\n",
      "[INFO]: Trace of K_deepDMD: 1.091947353908822\n",
      "[INFO]: One time-step error with K_deepDMD: 1472.5138488621064\n"
     ]
    }
   ],
   "source": [
    "if _LABEL == \"Baseline\":\n",
    "    K_model = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir, _SUFFIX))\n",
    "    \n",
    "    # inference\n",
    "    Kloss = []\n",
    "    n_instances = X_array.shape[0] // _INFERENCE_BS\n",
    "    X_batch = np.array_split(X_array[:_INFERENCE_BS*n_instances], n_instances)\n",
    "    Y_batch = np.array_split(Y_array[:_INFERENCE_BS*n_instances], n_instances)\n",
    "    inf_time_start = time.time()\n",
    "    for X_sample, Y_sample in zip(X_batch, Y_batch):\n",
    "        Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_value = K_model.predict([X_sample, Y_sample], batch_size=_INFERENCE_BS)\n",
    "        Kloss.append(Kloss_value)\n",
    "    inf_time_stop = time.time()    \n",
    "    # print(Psi_X.shape, PSI_X.shape, Psi_Y.shape, PSI_Y.shape, Kloss.shape)\n",
    "    \n",
    "    # performance_dict[\"inference_size\"] = Yp_array.shape[0]\n",
    "    performance_dict[\"inference_time\"] = inf_time_stop - inf_time_start\n",
    "    performance_dict[\"test_Kloss_model\"] = Kloss\n",
    "      \n",
    "elif _LABEL in [\"TFDataGen\", \"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "    if _ONNX_IMPL:\n",
    "        print(path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\"))\n",
    "        tf_model = ort.InferenceSession(path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\"))\n",
    "        encoder = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir, _SUFFIX))\n",
    "\n",
    "        Kloss = []\n",
    "        n_instances = X_array.shape[0] // _INFERENCE_BS\n",
    "        X_batch = np.array_split(X_array[:_INFERENCE_BS*n_instances].astype(hp.d_type), n_instances)\n",
    "        Y_batch = np.array_split(Y_array[:_INFERENCE_BS*n_instances].astype(hp.d_type), n_instances)\n",
    "        inf_time_start = time.time()\n",
    "        for X_sample, Y_sample in zip(X_batch, Y_batch):\n",
    "            # print(X_sample.shape, Y_sample.shape)\n",
    "            Psi_X = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: X_sample})[0]\n",
    "            Psi_Y = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: Y_sample})[0]\n",
    "\n",
    "            PSI_X    = tf.concat([X_sample, tf.cast(Psi_X, hp.d_type)], 1)\n",
    "            PSI_Y    = tf.concat([Y_sample, tf.cast(Psi_Y, hp.d_type)], 1) \n",
    "\n",
    "            # 1-time step evolution on observable space:\n",
    "            K_PSI_X  = tf.matmul(PSI_X, encoder.KO) \n",
    "\n",
    "            # 1-step Koopman loss on observable space:        \n",
    "            Kloss_value   = tf.norm(PSI_Y - K_PSI_X, axis = [0,1], ord = 'fro')\n",
    "\n",
    "            # Regularization loss on Koopman operator:\n",
    "            Reg_loss= tf.math.scalar_mul(hp.rf, tf.norm(encoder.KO, axis = [0,1], ord = 'fro')) \n",
    "\n",
    "            # res = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: Y_sample})\n",
    "            # Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_value = K_model.predict([X_sample, Y_sample], batch_size=_INFERENCE_BS)\n",
    "            Kloss.append(Kloss_value.numpy())\n",
    "        inf_time_stop = time.time()    \n",
    "    else:\n",
    "        encoder = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir, _SUFFIX))\n",
    "        test_size = x_indexer.shape[0] * x_indexer.shape[1] * len(data_handler.dir_list)\n",
    "        print(\"Test Size: \", test_size)\n",
    "\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            _INFERENCE_BS = _INFERENCE_BS * mirrored_strategy.num_replicas_in_sync\n",
    "            print(mirrored_strategy.num_replicas_in_sync)\n",
    "\n",
    "        test_data = scenario_data.batch(_INFERENCE_BS, drop_remainder=True)\n",
    "        # test_data = test_data.cache()\n",
    "\n",
    "        # for multi-gpu, split the data\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            test_data = mirrored_strategy.experimental_distribute_dataset(test_data)\n",
    "\n",
    "        inf_time_start = time.time()\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            trainer = proxyDeepDMDMGPU.NeuralNetworkModel(hp, encoder)\n",
    "            Kloss = []\n",
    "            for t in test_data:\n",
    "                Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_val = trainer.distributed_test_step(t)\n",
    "                Kloss.append(Kloss_val.numpy())\n",
    "        else:\n",
    "            K_model = proxyDeepDMD.NeuralNetworkModel(hp)\n",
    "            K_model.encoder = encoder\n",
    "            Kloss = []\n",
    "            for t in test_data:\n",
    "                Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_val = K_model.predict(t, batch_size=_INFERENCE_BS)\n",
    "                Kloss.append(Kloss_val)\n",
    "        # print(Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss)\n",
    "        inf_time_stop = time.time()\n",
    "    \n",
    "    print(\"Inference Time: \", inf_time_stop-inf_time_start)\n",
    "    \n",
    "    # performance_dict[\"inference_size\"] = test_size\n",
    "    performance_dict[\"inference_time\"] = inf_time_stop - inf_time_start\n",
    "    performance_dict[\"test_Kloss_model\"] = Kloss\n",
    "\n",
    "elif _LABEL == \"PyTorch\":\n",
    "    if _ONNX_IMPL:\n",
    "        tf_model = ort.InferenceSession(path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\"))\n",
    "        encoder = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir + \"onnx/\", _SUFFIX + \"_onnx\"))\n",
    "\n",
    "        Kloss = []\n",
    "        n_instances = X_array.shape[0] // _INFERENCE_BS\n",
    "        X_batch = np.array_split(X_array[:_INFERENCE_BS*n_instances], n_instances).astype(hp.d_type)\n",
    "        Y_batch = np.array_split(Y_array[:_INFERENCE_BS*n_instances], n_instances).astype(hp.d_type)\n",
    "        inf_time_start = time.time()\n",
    "        for X_sample, Y_sample in zip(X_batch, Y_batch):\n",
    "            Psi_X = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: X_sample})[0]\n",
    "            Psi_Y = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: Y_sample})[0]\n",
    "\n",
    "            PSI_X    = tf.concat([X_sample, tf.cast(Psi_X, hp.d_type)], 1)\n",
    "            PSI_Y    = tf.concat([Y_sample, tf.cast(Psi_Y, hp.d_type)], 1) \n",
    "\n",
    "            # 1-time step evolution on observable space:\n",
    "            K_PSI_X  = tf.matmul(PSI_X, encoder.KO) \n",
    "\n",
    "            # 1-step Koopman loss on observable space:        \n",
    "            Kloss_value   = tf.norm(PSI_Y - K_PSI_X, axis = [0,1], ord = 'fro')\n",
    "\n",
    "            # Regularization loss on Koopman operator:\n",
    "            Reg_loss= tf.math.scalar_mul(hp.rf, tf.norm(encoder.KO, axis = [0,1], ord = 'fro')) \n",
    "\n",
    "            # res = tf_model.run(None, input_feed={tf_model.get_inputs()[0].name: Y_sample})\n",
    "            # Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_value = K_model.predict([X_sample, Y_sample], batch_size=_INFERENCE_BS)\n",
    "            Kloss.append(Kloss_value)\n",
    "        inf_time_stop = time.time()    \n",
    "        print(\"Inference Time: \", inf_time_stop-inf_time_start)\n",
    "    else:\n",
    "        K_model = torch.load(path_handler.get_absolute_path(model_dir, _SUFFIX), map_location=device)\n",
    "        optimizer = torch.optim.Adagrad(K_model.parameters(), lr=hp.lr)\n",
    "        trainer = proxyDeepDMDPyTorch.NeuralNetworkModel(hp, K_model, optimizer, device)\n",
    "\n",
    "        inf_time_start = time.time()\n",
    "        Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss = trainer.predict(test_dataloader)\n",
    "        inf_time_stop = time.time()\n",
    "\n",
    "    # performance_dict[\"inference_size\"] = test_size\n",
    "    performance_dict[\"inference_time\"] = inf_time_stop - inf_time_start\n",
    "    performance_dict[\"test_Kloss_model\"] = Kloss\n",
    "     \n",
    "print(\"Koopman loss: \", Kloss)\n",
    "\n",
    "print('Psi_X shape:', Psi_X.shape)\n",
    "print('Psi_Y shape:', Psi_Y.shape)\n",
    "print('PSI_X shape:', PSI_X.shape)\n",
    "print('PSI_X shape:', PSI_Y.shape)\n",
    "\n",
    "if _LABEL in [\"Baseline\"]:\n",
    "    K_deepDMD = K_model.KO.numpy()\n",
    "elif _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "    if _ONNX_IMPL: K_deepDMD = encoder.KO.numpy()\n",
    "    else: K_deepDMD = trainer.encoder.KO.numpy()\n",
    "elif _LABEL in [\"TFDataGen\"]:\n",
    "    K_deepDMD = K_model.encoder.KO.numpy()\n",
    "elif _LABEL in [\"PyTorch\"]:\n",
    "    if _ONNX_IMPL: K_deepDMD = K_model.KO.numpy()\n",
    "    else:\n",
    "        if torch.cuda.device_count() > 1: K_deepDMD = trainer.encoder.module.KO.cpu().data.numpy()\n",
    "        else: K_deepDMD = trainer.encoder.KO.cpu().data.numpy()\n",
    "    \n",
    "print('[INFO]: Shape of Koopman operator', K_deepDMD.shape)\n",
    "print('[INFO]: Norm of Koopman operator', np.linalg.norm(K_deepDMD))\n",
    "print('[INFO]: Trace of K_deepDMD:',np.trace(K_deepDMD))\n",
    "print('[INFO]: One time-step error with K_deepDMD:', np.linalg.norm(PSI_Y - np.matmul(PSI_X, K_deepDMD), ord = 'fro'))\n",
    "\n",
    "[eigenvaluesK, eigenvectorsK] = np.linalg.eig(K_deepDMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fea9fd5e-de40-4e0f-b449-8a9e1e48b79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x2b02625a1470>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6766158c-eebf-4df0-98bc-887eb259574f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceSession' object has no attribute 'KO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d315a27dc677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'InferenceSession' object has no attribute 'KO'"
     ]
    }
   ],
   "source": [
    "tf_model.KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3f124f-bd06-4c3e-b259-fb1e8a003719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.3584679 , -0.35451121, -0.19742742, ...,  0.63062228,\n",
       "          0.16466774, -0.20814444],\n",
       "        [ 0.3584836 , -0.35459771, -0.19747718, ...,  0.63058373,\n",
       "          0.1646974 , -0.20819372],\n",
       "        [ 0.3584963 , -0.35467823, -0.19752379, ...,  0.63054654,\n",
       "          0.16472336, -0.2082369 ],\n",
       "        ...,\n",
       "        [ 0.35779349, -0.35355369, -0.19742723, ...,  0.63117904,\n",
       "          0.16425268, -0.20718148],\n",
       "        [ 0.35780183, -0.35358168, -0.19744011, ...,  0.63116507,\n",
       "          0.16426312, -0.20720567],\n",
       "        [ 0.35781036, -0.35361014, -0.19745366, ...,  0.63115142,\n",
       "          0.16427369, -0.20722982]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667ea3d2-086e-44a0-943e-12ac21f90724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48ad7d7-d332-417c-8a2d-6141a60631de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epochs': 20,\n",
       " 'batch_size': 65536,\n",
       " 'data_handler_time': 0.6131823062896729,\n",
       " 'inference_time': 58.371277809143066,\n",
       " 'test_Kloss_model': [61.112448449770966,\n",
       "  34.86950358999813,\n",
       "  21.058687113362044,\n",
       "  14.359497257929952,\n",
       "  11.693853284936946,\n",
       "  42.00541714721199,\n",
       "  61.698960150223826,\n",
       "  34.47326731317706,\n",
       "  21.195942189633104,\n",
       "  12.703181203471996,\n",
       "  8.81594986352653,\n",
       "  23.29078099022695,\n",
       "  31.89932005009393,\n",
       "  19.81281861364859,\n",
       "  14.136849965847018,\n",
       "  11.281858474250809,\n",
       "  10.38212897612368,\n",
       "  37.431768493608146,\n",
       "  36.05551935831266,\n",
       "  21.185003440561314,\n",
       "  13.748637225999698,\n",
       "  10.971524814094213,\n",
       "  10.233846196106887,\n",
       "  39.50225495061105,\n",
       "  34.063577130104115,\n",
       "  22.396882988864892,\n",
       "  15.074068206872653,\n",
       "  12.021932101753602,\n",
       "  11.120008848596107,\n",
       "  53.396510968245806,\n",
       "  36.63398332850572,\n",
       "  21.53958216369862,\n",
       "  13.466654541133474,\n",
       "  9.890971060287553,\n",
       "  8.58014871911081,\n",
       "  36.75387704766827,\n",
       "  22.394766130040598,\n",
       "  13.218569475553954,\n",
       "  10.267136683563033,\n",
       "  9.804337982331518,\n",
       "  10.027188449428857,\n",
       "  79.52246402146429,\n",
       "  50.34213119267784,\n",
       "  32.028117104269654,\n",
       "  20.48221468848076,\n",
       "  13.509535512752848,\n",
       "  21.661698656400958,\n",
       "  37.36870074018382,\n",
       "  22.07174813539398,\n",
       "  15.362087599827593,\n",
       "  11.507396437608723,\n",
       "  9.633146668457686,\n",
       "  14.994796408755292,\n",
       "  18.719077225014704,\n",
       "  14.17247710202364,\n",
       "  12.363583185268821,\n",
       "  11.863083205809723,\n",
       "  11.78822714689992,\n",
       "  41.9745437763479,\n",
       "  40.206771232964904,\n",
       "  22.463254228949722,\n",
       "  13.628152081600733,\n",
       "  10.750260441154524,\n",
       "  9.626991046709392,\n",
       "  141.78530690374532,\n",
       "  128.62091042869238,\n",
       "  83.1300819849286,\n",
       "  55.1548289924336,\n",
       "  35.203963779741365,\n",
       "  24.21794857440653,\n",
       "  42.838854346543066,\n",
       "  33.9982638362494,\n",
       "  19.920898576536192,\n",
       "  13.477996128323115,\n",
       "  9.930129789625983,\n",
       "  8.499489397170644,\n",
       "  110.4405742271915,\n",
       "  79.82425242201377,\n",
       "  50.47746362829762,\n",
       "  34.58760268590401,\n",
       "  21.94398378849628,\n",
       "  15.084561173832652,\n",
       "  58.98041472894845,\n",
       "  35.1956915926823,\n",
       "  20.112590661199942,\n",
       "  14.306642816801192,\n",
       "  11.599761972377246,\n",
       "  39.07531322025617,\n",
       "  71.45109780802765,\n",
       "  40.791830755643524,\n",
       "  25.94181500034524,\n",
       "  17.03655222654009,\n",
       "  11.743110090051301,\n",
       "  50.520381039012584,\n",
       "  59.059912708317306,\n",
       "  32.90354831025236,\n",
       "  22.06987470948786,\n",
       "  17.35824497949622,\n",
       "  15.726955149734923,\n",
       "  70.3031189639239,\n",
       "  79.07711449994045,\n",
       "  47.281283973881514,\n",
       "  29.566284551137894,\n",
       "  19.76458117214953,\n",
       "  15.009705286072318,\n",
       "  20.730007903887238,\n",
       "  18.579641359697252,\n",
       "  14.444211099517764,\n",
       "  12.54243124906086,\n",
       "  11.847975710041066,\n",
       "  11.748036537837079,\n",
       "  74.91135372247953,\n",
       "  58.65905723964167,\n",
       "  30.633736750797127,\n",
       "  19.08253783899065,\n",
       "  14.79279617643787,\n",
       "  13.293277654791783,\n",
       "  79.80570427934981,\n",
       "  55.92226358505694,\n",
       "  35.613519898547146,\n",
       "  25.414982518509802,\n",
       "  20.670561254121296,\n",
       "  18.13481324483519,\n",
       "  55.75681288308655,\n",
       "  33.918350817241716,\n",
       "  21.676897151633028,\n",
       "  13.059444717608663,\n",
       "  9.317244964760354,\n",
       "  9.736568964986867,\n",
       "  17.428791829568958,\n",
       "  14.801579523710453,\n",
       "  13.475563517759381,\n",
       "  12.970569596847598,\n",
       "  12.804871798318894,\n",
       "  40.40166898380446,\n",
       "  57.429769940513765,\n",
       "  34.6476236031009,\n",
       "  23.90634675101551,\n",
       "  15.106475951108045,\n",
       "  10.806314842901523,\n",
       "  55.90385013118894,\n",
       "  67.32633552280136,\n",
       "  40.81109949521906,\n",
       "  25.599055582827173,\n",
       "  16.253134149975576,\n",
       "  11.143184972141109,\n",
       "  41.54110738010705,\n",
       "  39.06525370428766,\n",
       "  26.15105798887828,\n",
       "  18.944140630846746,\n",
       "  15.526256003631097,\n",
       "  13.855936983531858,\n",
       "  59.98289507284205,\n",
       "  51.0965404292094,\n",
       "  32.66764228893953,\n",
       "  20.571471453396796,\n",
       "  13.866317208113246,\n",
       "  10.558818434450837,\n",
       "  91.02966481461675,\n",
       "  63.29522116103474,\n",
       "  40.1746136433779,\n",
       "  25.942035217711034,\n",
       "  17.85914838210924,\n",
       "  12.586305525110161,\n",
       "  32.79570766013343,\n",
       "  20.831375877008288,\n",
       "  14.786916910341994,\n",
       "  11.372782153633793,\n",
       "  10.152962816186406,\n",
       "  28.531153939977585,\n",
       "  63.07105265901991,\n",
       "  34.769674304890266,\n",
       "  18.909996548523218,\n",
       "  11.106676631827888,\n",
       "  7.836108175254676,\n",
       "  5.824530894908495]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603807fd-abc3-4692-8d97-2b82c44f59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_location = \"cpu\"\n",
    "if torch.cuda.is_available(): map_location = None\n",
    "torch_model = torch.load(path_handler.get_absolute_path(model_dir, _SUFFIX), map_location=map_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49ecfe11-8868-4cbc-961a-ca4e1717102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kloss = []\n",
    "n_instances = X_array.shape[0] // _INFERENCE_BS\n",
    "X_batch = np.array_split(X_array[:_INFERENCE_BS*n_instances], n_instances)\n",
    "Y_batch = np.array_split(Y_array[:_INFERENCE_BS*n_instances], n_instances)\n",
    "# inf_time_start = time.time()\n",
    "# for X_sample, Y_sample in zip(X_batch, Y_batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf95900-156c-4b17-90f4-cfad2d7c355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_dir=path_handler.get_absolute_path(curr_dir, config[\"info\"][\"input_dir\"])\n",
    "dir_list = [scenario_dir + \"/\" + f + \"/\" for f in os.listdir(scenario_dir)]\n",
    "\n",
    "x_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 0, _N_SIGNALS)\n",
    "y_indexer = get_indexer(_NROWS, _WINDOW_SIZE, _SHIFT_SIZE, 1, 0)\n",
    "\n",
    "dataset = GridDataGenPyTorch(dir_list, _NROWS, _NCOLS, _REPEAT_COLS, x_indexer, y_indexer)  \n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=_BATCH_SIZE, pin_memory=True, num_workers=int(_N_CPUS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a3807-82a8-4309-a664-d7e106d386af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(X_batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5744d-abe4-4783-a354-260c2d21971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(X_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bf97f-8ccd-4f40-be1f-b73d81f47456",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model(torch.tensor(X_batch[0]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c91a33-0408-40ed-a44b-50d2ad1ce90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2e725ee94115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# the model's input names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the model's output names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                  )\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    278\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                 \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     graph, params, torch_out, module = _create_jit_graph(model, args,\n\u001b[0;32m--> 459\u001b[0;31m                                                          _retain_param_name)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args, _retain_param_name)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mtrace_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mwarn_on_static_input_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0m_create_interpreter_name_lookup_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/qfs/people/jain432/pacer/code/src/proxy_apps/apps/timeseries_prediction/proxyDeepDMDPyTorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data, training)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;31m# print(\"\\tIn Model: input size\", input_data.size(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m#       \"output size\", fx.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/qfs/people/jain432/pacer/code/src/proxy_apps/apps/timeseries_prediction/proxyDeepDMDPyTorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# return torch.nn.functional.elu(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/onnx/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(torch_model,               # model being run\n",
    "                  (torch.tensor(X_batch[0]), False),\n",
    "                  \"test.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=9,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=False,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  training=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d73ae4-5aaf-484b-8d70-546378af24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea5ab0-c554-4b4f-b2ab-bf2ae740841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5165f14-4e0d-478d-ba4e-eda274000148",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_model.get_inputs():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24a1dc-d528-4284-8d15-3a4dd466956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if _LABEL in [\"TFDataGen\", \"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "    if ONNX_IMPL:\n",
    "        sess_ort = ort.InferenceSession(path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\"))\n",
    "    else:\n",
    "        encoder = tf.keras.models.load_model(path_handler.get_absolute_path(model_dir, _SUFFIX))\n",
    "        test_size = x_indexer.shape[0] * x_indexer.shape[1] * len(data_handler.dir_list)\n",
    "        print(\"Test Size: \", test_size)\n",
    "\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            _INFERENCE_BS = _INFERENCE_BS * mirrored_strategy.num_replicas_in_sync\n",
    "            print(mirrored_strategy.num_replicas_in_sync)\n",
    "\n",
    "        test_data = scenario_data.batch(_INFERENCE_BS, drop_remainder=False).take(2)\n",
    "        # test_data = test_data.cache()\n",
    "\n",
    "        # for multi-gpu, split the data\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            test_data = mirrored_strategy.experimental_distribute_dataset(test_data)\n",
    "\n",
    "        inf_time_start = time.time()\n",
    "        if _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "            trainer = proxyDeepDMDMGPU.NeuralNetworkModel(hp, encoder)\n",
    "            Kloss = []\n",
    "            for t in test_data:\n",
    "                Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_val = trainer.distributed_test_step(t)\n",
    "                Kloss.append(Kloss_val.numpy())\n",
    "        else:\n",
    "            K_model = proxyDeepDMD.NeuralNetworkModel(hp)\n",
    "            K_model.encoder = encoder\n",
    "            Kloss = []\n",
    "            for t in test_data:\n",
    "                Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss_val = K_model.predict(t, batch_size=_INFERENCE_BS)\n",
    "                Kloss.append(Kloss_val)\n",
    "        # print(Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss)\n",
    "        inf_time_stop = time.time()\n",
    "    \n",
    "elif _LABEL == \"PyTorch\":\n",
    "    \n",
    "    K_model = torch.load(path_handler.get_absolute_path(model_dir, _SUFFIX), map_location=device)\n",
    "    optimizer = torch.optim.Adagrad(K_model.parameters(), lr=hp.lr)\n",
    "    trainer = proxyDeepDMDPyTorch.NeuralNetworkModel(hp, K_model, optimizer, device)\n",
    "    \n",
    "    inf_time_start = time.time()\n",
    "    Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss = trainer.predict(test_dataloader)\n",
    "    inf_time_stop = time.time()\n",
    "    \n",
    "print(\"Koopman loss: \", Kloss)\n",
    "\n",
    "print('Psi_X shape:', Psi_X.shape)\n",
    "print('Psi_Y shape:', Psi_Y.shape)\n",
    "print('PSI_X shape:', PSI_X.shape)\n",
    "print('PSI_X shape:', PSI_Y.shape)\n",
    "\n",
    "if _LABEL in [\"Baseline\"]:\n",
    "    K_deepDMD = K_model.KO.numpy()\n",
    "elif _LABEL in [\"TFDataOptMGPU\", \"TFDataOptMGPUAcc\"]:\n",
    "    K_deepDMD = trainer.encoder.KO.numpy()\n",
    "elif _LABEL in [\"TFDataGen\"]:\n",
    "    K_deepDMD = K_model.encoder.KO.numpy()\n",
    "elif _LABEL in [\"PyTorch\"]:\n",
    "    if torch.cuda.device_count() > 1: K_deepDMD = trainer.encoder.module.KO.cpu().data.numpy()\n",
    "    else: K_deepDMD = trainer.encoder.KO.cpu().data.numpy()\n",
    "    \n",
    "print('[INFO]: Shape of Koopman operator', K_deepDMD.shape)\n",
    "print('[INFO]: Norm of Koopman operator', np.linalg.norm(K_deepDMD))\n",
    "print('[INFO]: Trace of K_deepDMD:',np.trace(K_deepDMD))\n",
    "print('[INFO]: One time-step error with K_deepDMD:', np.linalg.norm(PSI_Y - np.matmul(PSI_X, K_deepDMD), ord = 'fro'))\n",
    "\n",
    "[eigenvaluesK, eigenvectorsK] = np.linalg.eig(K_deepDMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fcbd2-8305-4213-8a27-a0bc3e19bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc64711-4ec4-47f0-a2cb-6c25100df52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Encoder(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e2449-6081-4a6b-b8d3-921f87bfda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch_out = torch_model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f96403-3e3a-4707-adcf-7883b95bb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_ort = ort.InferenceSession(\"test.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f514bf-3f27-4cf3-b7aa-8c2b369b8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125db52-2f2f-4e2c-94d1-6d6acb66eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ort.InferenceSession(path_handler.get_absolute_path(model_dir, _SUFFIX + \".onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6474ad-723a-41f3-9313-10345cb8a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153ce6d-7441-44c4-8aaa-9f401393f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2onnx.tfonnx import process_tf_graph, tf_optimize\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.graph_util import convert_variables_to_constants as freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a790c-749f-49d8-a1b9-d9c6a28d1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generating mnist.onnx in python script\")\n",
    "graph_def = freeze_graph(sess_tf, sess_tf.graph_def, [output_tensor.name[:-2]])\n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "    onnx_graph = process_tf_graph(graph, opset=7, input_names=[input_tensor.name], output_names=[output_tensor.name])\n",
    "model_proto = onnx_graph.make_model(\"test\")\n",
    "print(\"ONNX model is saved at ./output/mnist4.onnx\")\n",
    "with open(\"./output/mnist4.onnx\", \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae0af7-0ecc-4a8b-90f3-ba2d72c50ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
