{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import nvtx\n",
    "\n",
    "import argparse\n",
    "\n",
    "import math\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "# ------------------------------- CUSTOM FUNCTIONS ------------------------------------------------\n",
    "# Custom Library\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "    \n",
    "from proxy_apps.apps.timeseries_prediction import deepDMD, proxyDeepDMD, proxyDeepDMD_Backup\n",
    "\n",
    "from proxy_apps.utils.tf import TimingCallback\n",
    "from proxy_apps.utils.data.main import NpEncoder\n",
    "from proxy_apps.utils import file_reader, path_handler\n",
    "from proxy_apps.utils.data.grid import GridNetworkDataHandler, GridNetworkTFDataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "# System Setup\n",
    "config = file_reader.read_config()\n",
    "\n",
    "_N_EPOCHS = 2\n",
    "_BATCH_SIZE = 64000\n",
    "_APP_NAME = config[\"info\"][\"app_name\"]\n",
    "_NROWS = int(config[\"data\"][\"n_rows\"])\n",
    "_NCOLS = int(config[\"data\"][\"n_cols\"])\n",
    "_REPEAT_COLS = int(config[\"data\"][\"repeat_cols\"])\n",
    "_DTYPE = config[\"model\"][\"dtype\"]\n",
    "\n",
    "_LABEL = \"Baseline\"\n",
    "_SUFFIX =  \"gpu\" + '_' + \\\n",
    "            \"a100\" + '_' + \\\n",
    "            'ng' + str(1) + '_' + \\\n",
    "            'nc' + str(-1) + '_' + \\\n",
    "            'e' + str(_N_EPOCHS) + '_' + \\\n",
    "            'b' + str(_BATCH_SIZE) + '_' + \\\n",
    "            'r' + str(_REPEAT_COLS) + '_' + _LABEL\n",
    "\n",
    "performance_dict = dict()\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# current directory\n",
    "curr_dir = \"./\"\n",
    "\n",
    "# output directory\n",
    "output_dir = path_handler.get_absolute_path(curr_dir, config[\"info\"][\"output_dir\"] + config[\"info\"][\"name\"] + \"/\" + config[\"info\"][\"app_name\"] + \"/\" + _DTYPE + \"/R\" + str(_REPEAT_COLS) + \"/\")\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "# TensorFlow Setup\n",
    "print(\"[INFO] Tensorflow version: \", tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Eager mode:  True\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Eager mode: \", tf.executing_eagerly()) # For easy reset of notebook state.\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "# tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "\n",
    "# if _LABEL in [\"Baseline\"]: tf.keras.backend.set_floatx('float64')\n",
    "# elif _LABEL in [\"TFDataOpt\", \"TFDataOptMGPU\"]:\n",
    "#     tf.keras.backend.set_floatx(_DTYPE)\n",
    "# elif _LABEL in [\"TFDataOptMP\", \"TFDataOptMGPUMP\"]:\n",
    "#     _DTYPE = \"float32\"\n",
    "#     policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "#     tf.keras.mixed_precision.set_global_policy(policy)\n",
    "#     # tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "\n",
    "# if _LABEL in [\"TFDataOpt\", \"TFDataOptMP\", \"TFDataOptMGPU\", \"TFDataOptMGPUMP\"]:\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "os.environ[\"TF_GPU_THREAD_MODE\"] = \"gpu_private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading the datasets from the directory: /qfs/people/jain432/pacer/data/TrainingDataIEEE68bus\n",
      "[INFO]: Loading data for 30 scenarios ...\n",
      "[INFO]: Total number of scenarios loaded: 30\n",
      "[INFO]: Shape of each scenario loaded:  (1400, 136)\n",
      "[INFO]: Done ...\n",
      "[INFO]: Time taken for loading datasets: 2.448899745941162 seconds\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------- DATA LOADING ------------------------------------------------   \n",
    "\n",
    "data_loading = nvtx.start_range(\"Data Loading\")\n",
    "l_start = time.time()\n",
    "data_handler = GridNetworkDataHandler(scenario_dir=path_handler.get_absolute_path(curr_dir, config[\"info\"][\"input_dir\"]),\n",
    "                                        n_rows=_NROWS,\n",
    "                                        n_cols=_NCOLS,\n",
    "                                        repeat_cols=_REPEAT_COLS,\n",
    "                                        dtype=_DTYPE\n",
    "                                     ) \n",
    "\n",
    "scenario_data = data_handler.load_grid_data()\n",
    "l_stop = time.time()\n",
    "print('[INFO]: Time taken for loading datasets:', l_stop - l_start, 'seconds')\n",
    "performance_dict['data_loading_time'] = l_stop-l_start\n",
    "nvtx.end_range(data_loading)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Original dataset size: 1400\n",
      "[INFO]: Chosen dataset size: 800\n",
      "[INFO]: Length of X_data:  1800\n",
      "[INFO]: Length of each window after down sampling:  (800, 136)\n",
      "[INFO]: Time taken for creating X datasets: 3.1523194313049316 seconds\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------- DATA PREPROCESSING ------------------------------------------------\n",
    "\n",
    "data_processing = nvtx.start_range(\"Data Processing\")\n",
    "i_start = time.time()\n",
    "X_data, Y_data, U_data, V_data, Yp, Yf = data_handler.create_windows(scenario_data)\n",
    "i_stop = time.time()\n",
    "print('[INFO]: Time taken for creating X datasets:', i_stop - i_start, 'seconds')\n",
    "performance_dict['data_processing_time'] = i_stop-i_start\n",
    "nvtx.end_range(data_processing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Yp_array shape:  (41970, 136)\n",
      "[INFO]: Yf_array shape:  (41970, 136)\n",
      "[INFO]: X_array shape:  (1440000, 136)\n",
      "[INFO]: Y_array shape:  (1440000, 136)\n",
      "[INFO]: U_array shape:  (1440000, 136)\n",
      "[INFO]: V_array shape:  (1440000, 136)\n",
      "[INFO]: Time taken for normalization: 12.533467531204224 seconds\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------- DATA NORMALIZATION ------------------------------------------------\n",
    "\n",
    "data_norm = nvtx.start_range(\"Data Normalization\")\n",
    "n_start = time.time()\n",
    "X_array, Y_array, U_array, V_array, Yp_array, Yf_array = data_handler.scale_data(X_data, Y_data, U_data, V_data, Yp, Yf)\n",
    "n_stop = time.time()\n",
    "print('[INFO]: Time taken for normalization:', n_stop - n_start, 'seconds')\n",
    "\n",
    "performance_dict['data_scaling_time'] = n_stop-n_start\n",
    "nvtx.end_range(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- MODEL SETUP ------------------------------------------------\n",
    "# timing callback\n",
    "timing_cb = TimingCallback()\n",
    "\n",
    "# Stopping criteria if the training loss doesn't go down by 1e-3\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', min_delta = 1e-3, verbose = 1, mode='min', patience = 3, \n",
    "    baseline=None, restore_best_weights=True)\n",
    "\n",
    "# Create a TensorBoard Profiler\n",
    "logs = path_handler.get_absolute_path(curr_dir, config[\"model\"][\"tb_log_dir\"] + _APP_NAME + \"/\" + _DTYPE + \"/R\" + str(_REPEAT_COLS) + \"/tensorboard/\" + _SUFFIX)\n",
    "# tb_callback = tf.keras.callbacks.TensorBoard(log_dir=logs, histogram_freq=1, embeddings_freq=1, profile_batch=(5,15))\n",
    "\n",
    "# all callbacks\n",
    "callbacks=[early_stop_cb, timing_cb]#, tb_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hyperparameters - we can keep it as a dict instead of creating a separate class\n",
    "hyper_param_dict = config[\"model\"][\"hyperparameters\"]\n",
    "hyper_param_dict['original_dim']       = _REPEAT_COLS * _NCOLS   # input data dimension\n",
    "hyper_param_dict['num_epochs']         = _N_EPOCHS  # Number of epochs  \n",
    "hyper_param_dict['batch_size']         = _BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def train_step(X, Y):\n",
    "    # Open a GradientTape to record the operations run\n",
    "    # during the forward pass, which enables auto-differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Run the forward pass of the layer.\n",
    "        # The operations that the layer applies\n",
    "        # to its inputs are going to be recorded\n",
    "        # on the GradientTape.\n",
    "        Psi_X    = K_model(X, training=True)\n",
    "        Psi_Y    = K_model(Y, training=True)    \n",
    "\n",
    "        PSI_X    = tf.concat([X, Psi_X], 1)\n",
    "        PSI_Y    = tf.concat([Y, Psi_Y], 1) \n",
    "\n",
    "        # 1-time step evolution on observable space:\n",
    "        K_PSI_X  = tf.matmul(PSI_X, K_model.KO) \n",
    "\n",
    "        # 1-step Koopman loss on observable space:        \n",
    "        K_loss   = tf.norm(PSI_Y - K_PSI_X, axis = [0,1], ord = 'fro')\n",
    "\n",
    "        # Regularization loss on Koopman operator:\n",
    "        Reg_loss= tf.math.scalar_mul(hp.rf, tf.norm(K_model.KO, axis = [0,1], ord = 'fro'))   \n",
    "\n",
    "        # Compute the loss value for this minibatch.\n",
    "        loss_value = K_loss + Reg_loss\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.\n",
    "    grads = tape.gradient(loss_value, K_model.trainable_weights)\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, K_model.trainable_weights))\n",
    "    \n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(dist_inputs):\n",
    "    per_replica_losses = mirrored_strategy.run(train_step, args=(dist_inputs[0],dist_inputs[1]))\n",
    "    print(per_replica_losses)\n",
    "    return mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = Yp_array.shape[0]\n",
    "\n",
    "Xd_array = tf.data.Dataset.from_tensor_slices(X_array)\n",
    "Yd_array = tf.data.Dataset.from_tensor_slices(Y_array)\n",
    "Ud_array = tf.data.Dataset.from_tensor_slices(U_array)\n",
    "Vd_array = tf.data.Dataset.from_tensor_slices(V_array)\n",
    "Ydp_array = tf.data.Dataset.from_tensor_slices(Yp_array)\n",
    "Ydf_array = tf.data.Dataset.from_tensor_slices(Yf_array)\n",
    "\n",
    "hyper_param_dict['dtype']         = _DTYPE\n",
    "hp = proxyDeepDMD.HyperParameters(hyper_param_dict)\n",
    "hp.model_name         = _LABEL\n",
    "\n",
    "performance_dict[\"n_epochs\"] = hp.ep\n",
    "performance_dict[\"batch_size\"] = hp.bs\n",
    "# performance_dict[\"n_training_batches\"] = n_batches_training\n",
    "# performance_dict[\"n_val_batches\"] = n_batches - n_batches_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- MODEL TRAINING ------------------------------------------------\n",
    "# Initialize, build, and fit the model\n",
    "# with mirrored_strategy.scope():\n",
    "with mirrored_strategy.scope():\n",
    "    K_model = proxyDeepDMD.Encoder(hp)\n",
    "    optimizer = tf.optimizers.Adagrad(hp.lr)\n",
    "\n",
    "BATCH_SIZE = hp.bs # * mirrored_strategy.num_replicas_in_sync\n",
    "zip_data = tf.data.Dataset.zip((Xd_array, Yd_array)).batch(BATCH_SIZE)\n",
    "\n",
    "training_dataset = zip_data.cache()\n",
    "training_dataset = training_dataset.shuffle(buffer_size=BATCH_SIZE)\n",
    "training_dataset = training_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "training_dataset = mirrored_strategy.experimental_distribute_dataset(training_dataset)#.cache()#.with_options(options)# .take(n_batches_training)\n",
    "# training_dataset = training_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "K_model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/2\n",
      "Tensor(\"add:0\", shape=(), dtype=float64, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "Tensor(\"add:0\", shape=(), dtype=float64, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "15/23 [==================>...........] - ETA: 8s - loss: 807.2462 Tensor(\"add:0\", shape=(), dtype=float64, device=/job:localhost/replica:0/task:0/device:CPU:0)\n",
      "23/23 [==============================] - 37s 1s/step - loss: 744.6418\n",
      "\n",
      "epoch 2/2\n",
      "23/23 [==============================] - 26s 1s/step - loss: 506.7132\n",
      "63.135339975357056\n"
     ]
    }
   ],
   "source": [
    "m_start = time.time()\n",
    "for epoch in range(hp.ep):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1, hp.ep))\n",
    "    pb_i = Progbar(math.ceil(1440000//hp.bs)+1, stateful_metrics=['loss'])\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for step, inp_data in enumerate(training_dataset):\n",
    "        total_loss += distributed_train_step(inp_data)\n",
    "        num_batches += 1\n",
    "        \n",
    "        loss_value = total_loss / num_batches\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        pb_i.add(hp.bs//hp.bs, values=[('loss', loss_value)])\n",
    "\n",
    "m_stop = time.time()\n",
    "print(m_stop-m_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (DenseLayer)     multiple                  17536     \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (DenseLayer)   multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (DenseLayer)   multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_layer_3 (DenseLayer)   multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "linear_layer (LinearLayer)   multiple                  4160      \n",
      "=================================================================\n",
      "Total params: 90,624\n",
      "Trainable params: 90,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - 25s 1s/step - loss: 849.7967\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 24s 1s/step - loss: 571.0389\n",
      "[INFO]: Time taken for model training (time module): 51.75946640968323 seconds\n",
      "[INFO]: Time taken for model training (Keras): 49.36934209614992 seconds\n"
     ]
    }
   ],
   "source": [
    "hp = deepDMD.HyperParameters(hyper_param_dict)\n",
    "hp.model_name         = _LABEL\n",
    "\n",
    "performance_dict[\"n_epochs\"] = hp.ep\n",
    "performance_dict[\"batch_size\"] = hp.bs\n",
    "performance_dict[\"n_training_batches\"] = 1 - hp.vs\n",
    "performance_dict[\"n_val_batches\"] = hp.vs\n",
    "\n",
    "# ------------------------------- MODEL TRAINING ------------------------------------------------\n",
    "# Initialize, build, and fit the model\n",
    "m_start = time.time()\n",
    "BaselineModel = deepDMD.NeuralNetworkModel(hp)\n",
    "BaselineModel.compile(optimizer=tf.optimizers.Adagrad(hp.lr))\n",
    "\n",
    "history = BaselineModel.fit([X_array, Y_array], batch_size=hp.bs, \n",
    "                  epochs=hp.ep, \n",
    "                  callbacks=callbacks, \n",
    "                  shuffle=True)\n",
    "\n",
    "m_stop = time.time()\n",
    "\n",
    "# print info\n",
    "print('[INFO]: Time taken for model training (time module):', m_stop - m_start, 'seconds')\n",
    "print('[INFO]: Time taken for model training (Keras):', sum(timing_cb.logs), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"neural_network_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder (Encoder)            multiple                  50624     \n",
      "=================================================================\n",
      "Total params: 90,624\n",
      "Trainable params: 90,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BaselineModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
