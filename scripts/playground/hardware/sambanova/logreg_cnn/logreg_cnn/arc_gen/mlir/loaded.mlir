module @program attributes {arc.AIRMappingDecisionIsSpatial = false, arc.kAIRAddnOpt = true, arc.kAIRAdvancedLoadSplitOpt = true, arc.kAIRAnnotateHyperFunctionArguments = false, arc.kAIRBufferBeforeConcatAddn = false, arc.kAIRBufferNonRedundancy = "", arc.kAIRDDRBoundSections = [], arc.kAIRDPTilingOptimization = false, arc.kAIRDisableConcatStoreOpt = false, arc.kAIRDisableLoadTilerOptWithDimOrdering = false, arc.kAIRDisableOptimizeRereadBuffer = false, arc.kAIREnableRemoteRead = false, arc.kAIREnableSkipBufferExtensionOpt = false, arc.kAIREnableStoreTilerOptWithDimOrdering = false, arc.kAIRForceDRAMFirstThenP2P = false, arc.kAIRMappingDecisionGlobalNumBatches = 1 : i64, arc.kAIRMappingDecisionSectionDRAMTransferSize = [2347854, 4646526, 11532640], arc.kAIRMappingDecisionSectionDRAMTransferTime = [0.021866094321012497, 0.043274145573377609, 0.10740607976913452], arc.kAIRMappingDecisionSectionLatencies = [5.6866094382712618E-5, 7.8274148108903319E-5, 1.4240607561077923E-4], arc.kAIRMappingDecisionSectionNames = ["$FWD", "$BCKWD", "$OPT"], arc.kAIRMappingDecisionSectionPCUs = [1.750000e+02, 1.240000e+02, 4.000000e+00], arc.kAIRMappingDecisionSectionPMUs = [[186, 4, 6, 33, 7, 17, 7], [163, 4, 14, 41, 11, 22, 5], [0, 4, 0, 33, 0, 0, 0]], arc.kAIRMappingDecisionSectionResourceScales = [1.1000000238418579, 1.2000000476837158, 0.89999997615814208], arc.kAIRMappingDecisionSectionTypes = ["Forward", "Backward", "Optimizer"], arc.kAIRMappingDecisionSectionUniqueNames = ["ptconvcnn__lambda_layer__indexselect_as_initial", "ptconvcnn__reshape_1_recompute__as_initial", "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_as_initial"], arc.kAIRMetaPipeWithOneIterationRemoval = false, arc.kAIRTransposeMatMulTransformation = false, arc.kAddStreamingBuffers = false, arc.kAppName = "logreg_torch_samba", arc.kArchMajor = 1 : i64, arc.kArchMinor = 0 : i64, arc.kBoxLayoutSize = 2 : i64, arc.kBoxLayoutType = 0 : i64, arc.kConcisePrinting = false, arc.kDataParallelBf16StochasticRounding = false, arc.kDataParallelBf16StochasticRoundingHighStaticBatchSize = false, arc.kDataParallelBf16StochasticRoundingSeedName = "", arc.kDataParallelFactor = 1 : i64, arc.kDataParallelInHostMemory = false, arc.kDataParallelReduceOnlyMode = false, arc.kDebugMode = false, arc.kDisableFuseToTwoHeadBuffers = false, arc.kEliminateBufferTimeout = 100 : i64, arc.kEnableAutoGrouping = true, arc.kEnableBufferBarriers = true, arc.kEnableFuseToLinearTraining = false, arc.kEnablePcuHeartBeat = false, arc.kEnableWrDoneInstrument = false, arc.kExperimentalOptimization = true, arc.kExperimentalRAILCrossEntropy = true, arc.kExperimentalRAILCrossEntropyGrad = true, arc.kGenerateReference = false, arc.kGenerateTensorboard = false, arc.kHasGraphData = true, arc.kHeuristicRuntimeLayouts = true, arc.kHeuristicSliceLayouts = false, arc.kHeuristicTilerLayouts = true, arc.kIsBf16Conversion = true, arc.kIteration = 1 : i64, arc.kLayoutTimeout = 1000 : i64, arc.kLegalizeDataflow = true, arc.kLegalizeSamples = false, arc.kLowered = false, arc.kMacAutogen = true, arc.kMaximumGroupLatencyFactor = 5.000000e-02 : f32, arc.kMoveViews = false, arc.kOptimizationLevel = 3 : i64, arc.kOptimizeDramTransfers = 1 : i64, arc.kOriginalName = "logreg_cnn", arc.kOutputFolder = "/qfs/people/jain432/pacer_saudade/code/ProxyTSPRD/scripts/test/sambanova/logreg_cnn", arc.kOverrideMaxFanout = 0 : i64, arc.kPefMetadataacc_report_json = "None", arc.kPefMetadataacc_test = "False", arc.kPefMetadataamp_level = "4", arc.kPefMetadataarc_debug_mode = "False", arc.kPefMetadatabatch_size = "1", arc.kPefMetadatabench_report_json = "None", arc.kPefMetadatacompiled_stats_json = "None", arc.kPefMetadatacompiler_mode = "", arc.kPefMetadatadata_folder = "mnist_data", arc.kPefMetadatadata_parallel = "False", arc.kPefMetadatadata_parallel_mode = "normal", arc.kPefMetadatadebug = "False", arc.kPefMetadatadefault_device = "DDR", arc.kPefMetadatadense_adam_fast_grad_compute = "False", arc.kPefMetadatadev_mode = "False", arc.kPefMetadatadisable_bf16_conversion = "False", arc.kPefMetadatadisable_mac_tiling = "False", arc.kPefMetadatadisable_retry_lower_visible_resources = "False", arc.kPefMetadatadistlearn_config = "", arc.kPefMetadatadropout_tiling_legalizer_error = "False", arc.kPefMetadatadump_accuracy_debug_info = "False", arc.kPefMetadatadump_compiled_stats_json = "False", arc.kPefMetadatadump_traced_graph = "False", arc.kPefMetadataenable_buffer_trial_compile = "False", arc.kPefMetadataenable_conv2d_conversion = "False", arc.kPefMetadataenable_conv_tiling = "False", arc.kPefMetadataenable_hd_retry_lower_visible_resources = "False", arc.kPefMetadataenable_hypersection = "False", arc.kPefMetadataenable_node_trial_compile = "False", arc.kPefMetadataenable_node_trial_compile_logging = "False", arc.kPefMetadataenable_stochastic_rounding = "False", arc.kPefMetadataforce_node_proximity = "False", arc.kPefMetadatafp32_params = "False", arc.kPefMetadatafuse_fwd_bwd = "False", arc.kPefMetadatagen_tensorboard = "False", arc.kPefMetadatagrad_accumulation_steps = "1", arc.kPefMetadatahas_human_decision = "False", arc.kPefMetadatahost_fifo = "False", arc.kPefMetadatahypersection_arc = "False", arc.kPefMetadatainclude_read_stall_cycles = "False", arc.kPefMetadatainference = "False", arc.kPefMetadatainput_layout = "None", arc.kPefMetadatajson = "None", arc.kPefMetadatajson_counters = "", arc.kPefMetadatalatency_budget_bwd = "None", arc.kPefMetadatalatency_budget_fwd = "None", arc.kPefMetadatalisten_for_input = "False", arc.kPefMetadatalocal_rank = "-1", arc.kPefMetadatalog_dir = "None", arc.kPefMetadatalr = "0.0015", "arc.kPefMetadatamac_conv_tiling_c++" = "False", arc.kPefMetadatamac_only = "False", arc.kPefMetadatamac_print_mapping_ir = "False", arc.kPefMetadatamac_split_cat_as_stage_buf = "False", arc.kPefMetadatamac_templatedb_dir = "", arc.kPefMetadatamac_templatedb_dir_backup_to = "", arc.kPefMetadatamac_templatedb_dir_init_from = "", arc.kPefMetadatamac_v1 = "False", arc.kPefMetadatamapping = "section", arc.kPefMetadatamax_expected_mac_latency = "-1.0", arc.kPefMetadatamax_mac_loop_attempt = "-1", arc.kPefMetadatamax_tiling_depth = "None", arc.kPefMetadatametapipe_disable = "False", arc.kPefMetadatamicrobatch_size = "None", arc.kPefMetadatamin_duration = "0.0", arc.kPefMetadatamlir_file_name = "None", arc.kPefMetadatamock_inference = "False", arc.kPefMetadatamodel = "PTConvCNN(\0A  (lambda_layer): Lambda()\0A  (conv_layer): Conv1d(136, 256, kernel_size=(3,), stride=(1,))\0A  (dense_layer): Linear(in_features=256, out_features=4080, bias=True)\0A  (criterion): MSELoss()\0A)", arc.kPefMetadatamodel_parallel = "False", arc.kPefMetadatamodelbox = "False", arc.kPefMetadatamomentum = "0.0", arc.kPefMetadatan_chips = "1", arc.kPefMetadatandtest = "False", arc.kPefMetadatandtest_mp = "False", arc.kPefMetadatanum_classes = "10", arc.kPefMetadatanum_epochs = "1", arc.kPefMetadatanum_features = "784", arc.kPefMetadatanum_iterations = "100", arc.kPefMetadatanum_sections = "None", arc.kPefMetadatanum_spatial_batches = "1", arc.kPefMetadatanum_tiles = "-1", arc.kPefMetadataoptim_level = "o3", arc.kPefMetadataoptimize_concat_split = "False", arc.kPefMetadatapef = "None", arc.kPefMetadataplot = "None", arc.kPefMetadatapp_lamb_optimizer = "False", arc.kPefMetadatarecompute_ratio = "-1.0", arc.kPefMetadatareduce_on_rdu = "False", arc.kPefMetadataresources_scaling_factors = "['-1.0', '-1.0', '-1.0', '-1.0']", arc.kPefMetadatarun_analysis_pass = "False", arc.kPefMetadatarun_graph_only = "False", arc.kPefMetadatasafe_mode = "False", arc.kPefMetadatasamba_plot = "False", arc.kPefMetadatasamba_version = "1.14.3", arc.kPefMetadatasambahd = "False", arc.kPefMetadatasambatune_graph = "False", arc.kPefMetadatasection_cut_beam_search = "[]", arc.kPefMetadatasection_cut_sort_order = "3", arc.kPefMetadatasingle_opt_sec = "False", arc.kPefMetadataskip_instrumentation_on_read0 = "False", arc.kPefMetadataskip_instrumentation_on_read1 = "False", arc.kPefMetadatastage_instrumentation = "none", "arc.kPefMetadatastop_mac_c++" = "False", "arc.kPefMetadatastop_mac_named_dims_c++" = "False", arc.kPefMetadatastrict_auto_cast = "False", arc.kPefMetadatastrict_conversion = "False", arc.kPefMetadatatensor_parallel = "none", arc.kPefMetadatatile_orientation = "auto", arc.kPefMetadatatraced_attributes_folder = "", arc.kPefMetadataunroll_first = "False", arc.kPefMetadatause_correct_tiling_cost_model = "False", arc.kPefMetadatause_integrated_bias = "False", arc.kPefMetadatavalidate_mac_resource_prediction = "False", arc.kPefMetadataverbose = "0", arc.kPefMetadatavisualize = "False", arc.kPefMetadataweight_caching = "False", arc.kPefMetadataweight_decay = "0.0003", arc.kPefMetadataweight_layout = "None", arc.kPefMetadataweight_norm = "False", arc.kPefMetadataworld_size = "1", arc.kPefMetadatayaml_config = "None", arc.kPefName = "logreg_cnn", arc.kPlasmaIncludeReadStallCycles = false, arc.kPlasmaSkipInstrumentationOnRead0 = false, arc.kPlasmaSkipInstrumentationOnRead1 = false, arc.kPlasmaStageInstrumentation = "none", arc.kPrintSrcs = [], arc.kResourceAwareBuffers = false, arc.kSambaTuneGraph = false, arc.kSkipBufferBandwidthWeight = 1 : i64, arc.kSkipBufferMaxDepth = 4096 : i64, arc.kSkipBufferMaxFanin = 8 : i64, arc.kSkipBufferPmuWeight = 1 : i64, arc.kSplitSkipBuffer = true, arc.kStrictNodeNameOrdering = true, arc.kTileSize = 5 : i64, arc.kUniqueIdCounter = 444 : i64, arc.kUseTBufferEverywhere = false, arc.kVerbose = false}  {
  module @preface  {
  }
  module @templates  {
  }
  module @sections  {
    %0 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 10 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__weight", kPlacementHint = [1, 0], kToDeviceTransform = "", kUniqueId = 77 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<256x136x3xbf16>
    %1 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e-01 : f64, distribution_min = -1.000000e-01 : f64, kConfigured = true, kFromDeviceTransform = ".long()", kGroup = 0 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = true, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = false, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "inp_window_slice_1_result0", kMemoryType = 2 : i64, kName = "inp_window_slice_1", kToDeviceTransform = ".int().int()", kUniqueId = 78 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<3xi32>
    %2 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e-01 : f64, distribution_min = -1.000000e-01 : f64, kConfigured = true, kFromDeviceTransform = "", kGroup = 1 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = true, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = false, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = true, kIsSliceStored = false, kIsStored = false, kIsUserFacing = true, kMacID = "inp_window_result0", kMemoryType = 0 : i64, kName = "inp_window", kToDeviceTransform = "", kUniqueId = 79 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<1x60x136xbf16>
    %3 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = ".squeeze(1)", kGroup = 2 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__bias", kPlacementHint = [1, 0], kToDeviceTransform = ".unsqueeze(1)", kUniqueId = 80 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<256x1xbf16>
    %4 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e-01 : f64, distribution_min = -1.000000e-01 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = ".squeeze(1)", kGroup = 11 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__bias", kPlacementHint = [1, 0], kToDeviceTransform = ".unsqueeze(1)", kUniqueId = 81 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<4080x1xbf16>
    %5 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 3 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__weight", kToDeviceTransform = "", kUniqueId = 82 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<4080x256xbf16>
    %6 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e-01 : f64, distribution_min = -1.000000e-01 : f64, kConfigured = true, kFromDeviceTransform = "", kGroup = 4 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = true, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = true, kIsSliceStored = false, kIsStored = false, kIsUserFacing = true, kMacID = "out_window_result0", kMemoryType = 0 : i64, kName = "out_window", kPlacementHint = [0, 1, 1, 0], kToDeviceTransform = "", kUniqueId = 83 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<1x30x136xbf16>
    %7 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e+00 : f64, distribution_min = 1.000000e+00 : f64, kConfigured = true, kFromDeviceTransform = "", kGroup = -8 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = false, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__criterion__mseloss__outputs__0__grad_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__criterion__mseloss__outputs__0__grad", kPlacementHint = [0, 1, 1, 0], kToDeviceTransform = "", kUniqueId = 84 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<1xbf16>
    %8 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 6 : i32, distribution_max = 1.000000e+00 : f64, distribution_min = 1.000000e+00 : f64, kConfigured = true, kFromDeviceTransform = "", kGroup = 5 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = false, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = true, kIsSliceStored = false, kIsStored = false, kIsUserFacing = true, kMacID = "ptconvcnn__view__outputs__0__grad_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__view__outputs__0__grad", kPlacementHint = [0, 1, 1, 0], kToDeviceTransform = "", kUniqueId = 85 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<1x30x136xbf16>
    %9 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 12 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt_result1", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__weight__sgd0__momentum", kToDeviceTransform = "", kUniqueId = 86 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<4080x256xbf16>
    %10 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 13 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt_result1", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__bias__sgd0__momentum", kToDeviceTransform = "", kUniqueId = 87 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<4080x1xbf16>
    %11 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 13 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt_result1", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__bias__sgd0__momentum", kToDeviceTransform = "", kUniqueId = 88 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<256x1xbf16>
    %12 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 7 : i32, distribution_gain = 1.000000e+00 : f64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 13 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsHostFifoInput = false, kIsInputOnly = false, kIsLoaded = true, kIsMask = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsRngSeed = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kIsWeight = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_result1", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__weight__sgd0__momentum", kToDeviceTransform = "", kUniqueId = 89 : i64, kUserCreated = true, kZeroFillDram = false} : () -> tensor<256x136x3xbf16>
    %13 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kGroup = 6 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = false, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = true, kIsSliceStored = true, kIsStored = true, kLinearGradBInputHint = 1 : i64, kMacID = "ptconvcnn__conv_layer__reshape_2_result0", kName = "ptconvcnn__conv_layer__reshape_20_used_by_ptconvcnn__dense_layer__linear_bwd_weight", kPlacementHint = [1, 0], kUniqueId = 90 : i64, kUserCreated = true} : () -> tensor<1x256x1xbf16>
    %14 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kGroup = 7 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = false, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = true, kIsSliceStored = true, kIsStored = true, kLinearGradAInputHint = 1 : i64, kMacID = "ptconvcnn__reshape_result0", kName = "ptconvcnn__reshape0_used_by_ptconvcnn__criterion__mseloss_bwd_sub", kUniqueId = 91 : i64, kUserCreated = true} : () -> tensor<1x4080xbf16>
    %15 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 8 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = false, kIsOneShotTransferred = false, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = true, kIsStored = true, kIsUserFacing = true, kMacID = "ptconvcnn__view_result0", kMemoryType = 2 : i64, kName = "ptconvcnn__view__outputs__0", kPlacementHint = [1, 0], kToDeviceTransform = "", kUniqueId = 92 : i64, kUserCreated = true} : () -> tensor<1x30x136xbf16>
    %16 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 9 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = false, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "default_72_result0", kMemoryType = 2 : i64, kName = "ptconvcnn__criterion__mseloss__outputs__0", kToDeviceTransform = "", kUniqueId = 93 : i64, kUserCreated = true} : () -> tensor<1xbf16>
    %17 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 14 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_weight_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__weight__grad", kToDeviceTransform = "", kUniqueId = 94 : i64, kUserCreated = true} : () -> tensor<4080x256xbf16>
    %18 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = ".squeeze(1)", kGroup = 15 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_weight_result1", kMemoryType = 0 : i64, kName = "ptconvcnn__dense_layer__bias__grad", kToDeviceTransform = ".unsqueeze(1)", kUniqueId = 95 : i64, kUserCreated = true} : () -> tensor<4080x1xbf16>
    %19 = "tlir.Region"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = ".squeeze(1)", kGroup = 15 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd_result2", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__bias__grad", kToDeviceTransform = ".unsqueeze(1)", kUniqueId = 96 : i64, kUserCreated = true} : () -> tensor<256x1xbf16>
    %20 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kFromDeviceTransform = "", kGroup = 15 : i64, kHasShape = true, kIsDataParallelAccumBuf = false, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = true, kIsUserFacing = true, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__reshape_1_bwd_result0", kMemoryType = 0 : i64, kName = "ptconvcnn__conv_layer__weight__grad", kToDeviceTransform = "", kUniqueId = 97 : i64, kUserCreated = true} : () -> tensor<256x136x3xbf16>
    "tlir.Section"() ( {
      "tlir.Chip"() ( {
        %21 = "tlir.Load"(%0) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 10 : i64, kGroupedDramLayoutName = "ptconvcnn__conv_layer__weight_0_0_99", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_99", kName = "ptconvcnn__conv_layer__weight_0_0_99", kPlacementHint = [1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_0_0_99", kUniqueId = 99 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>) -> tensor<256x136x3xbf16>
        %22:2 = "tlir.Buffer"(%21) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_430", kName = "gbuf1a_0_0_430", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 6 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kUniqueId = 430 : i64, kUserCreated = false} : (tensor<256x136x3xbf16>) -> (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>)
        %23 = "tlir.Realign"(%22#1) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayoutkInputLayout = #tlir.layout<RV,RM,VA>, DataLayoutkOutputLayout = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_412", kName = "realign_0_0_412", kPlacementHint = [1, 0], kStageId = 0 : i64, kTemplateName = "realign_0_0_412", kUniqueId = 412 : i64, kUserCreated = false} : (tensor<256x136x3xbf16>) -> tensor<256x136x3xbf16>
        %24:2 = "tlir.Buffer"(%23) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayout1 = #tlir.layout<RV,RM,UA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_395", kName = "gbuf1a_0_0_395", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kUniqueId = 395 : i64, kUserCreated = false} : (tensor<256x136x3xbf16>) -> (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>)
        %25 = "tlir.Reshape"(%24#1) {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape_1", kName = "ptconvcnn__conv_layer__reshape_1", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "reshape_0_0_287", kUniqueId = 287 : i64, kUserCreated = true} : (tensor<256x136x3xbf16>) -> tensor<256x136x3x1xbf16>
        %26 = "tlir.Load"(%1) {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 18 : i64, kGroupedDramLayoutName = "inp_window_slice_1_0_0_102", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_102", kName = "inp_window_slice_1_0_0_102", kPlacementHint = [1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_0_0_102", kUniqueId = 102 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<3xi32>) -> tensor<3xi32>
        %27 = "tlir.Realign"(%25) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayoutkInputLayout = #tlir.layout<RV,RM,UA>, DataLayoutkOutputLayout = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_413", kName = "realign_0_0_413", kPlacementHint = [1, 0], kStageId = 0 : i64, kTemplateName = "realign_0_0_413", kUniqueId = 413 : i64, kUserCreated = false} : (tensor<256x136x3x1xbf16>) -> tensor<256x136x3x1xbf16>
        %28 = "tlir.Permute"(%27) {DataLayout0 = #tlir.layout<RV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__conv2d_weight_permute", kName = "ptconvcnn__conv_layer__conv2d_weight_permute", kPermutation = [2 : index, 3 : index, 1 : index, 0 : index], kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "permute_0_0_288", kUniqueId = 288 : i64, kUserCreated = true} : (tensor<256x136x3x1xbf16>) -> tensor<3x1x136x256xbf16>
        %29 = "tlir.VectorTranspose"(%28) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_414", kName = "vector_transpose_0_0_414", kPlacementHint = [1, 0], kStageId = 0 : i64, kTemplateName = "vector_transpose_0_0_414", kUniqueId = 414 : i64, kUserCreated = false} : (tensor<3x1x136x256xbf16>) -> tensor<3x1x136x256xbf16>
        %30 = "tlir.Reshape"(%29) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__conv2d_weight_reshape", kName = "ptconvcnn__conv_layer__conv2d_weight_reshape", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "reshape_0_0_289", kUniqueId = 289 : i64, kUserCreated = true} : (tensor<3x1x136x256xbf16>) -> tensor<408x256xbf16>
        %31 = "tlir.Load"(%3) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = -25 : i64, kGroupedDramLayoutName = "ptconvcnn__conv_layer__bias_0_0_110", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_110", kName = "ptconvcnn__conv_layer__bias_0_0_110", kPlacementHint = [1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_0_0_110", kUniqueId = 110 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1xbf16>
        %32 = "tlir.Load"(%5) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 3 : i64, kGroupedDramLayoutName = "group_3", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_114", kName = "ptconvcnn__dense_layer__weight_0_0_114", kPlacementHint = [1, 0], kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_0_0_114", kUniqueId = 114 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>) -> tensor<4080x256xbf16>
        %33 = "tlir.Load"(%4) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 11 : i64, kGroupedDramLayoutName = "group_11", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_115", kName = "ptconvcnn__dense_layer__bias_0_0_115", kPlacementHint = [1, 0], kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_0_0_115", kUniqueId = 115 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
        %34 = "tlir.mutable.TemporalConcatBuffer"() {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAxis = 0 : i64, kChipID = 0 : i64, kConfigured = true, kKeepDim = false, kMacID = "default_193", kName = "ptconvcnn__reshape_concat_buffer", kPlacementHint = [1, 0], kStageId = 0 : i64, kTemplateName = "tconcatbuf_0_0_193", kUniqueId = 193 : i64, kUserCreated = true} : () -> tensor<1x4080xbf16>
        %35:2 = "tlir.Buffer"(%30) {DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_437", kName = "gbuf2a_0_0_437", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kTranspose = 1 : i64, kUniqueId = 437 : i64, kUserCreated = false, kWriteVT = true} : (tensor<408x256xbf16>) -> (tensor<408x256xbf16>, tensor<408x256xbf16>)
        "tlir.iter_loop.MetaPipeline"() ( {
          %47 = "tlir.Load"(%2) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 19 : i64, kGroupedDramLayoutName = "inp_window_0_0_268", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLoadSlice = true, kLoadTile = false, kMacID = "default_268", kMultiLoadDepth = 2 : i64, kName = "inp_window_0_0_268", kPlacementHint = [1, 0], kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_0_0_268", kUniqueId = 268 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x60x136xbf16>) -> tensor<60x136xbf16>
          %48:2 = "tlir.Buffer"(%47) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kMacID = "default_197", kName = "tbuf2u_0_0_197", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 197 : i64, kUserCreated = true} : (tensor<60x136xbf16>) -> (tensor<60x136xbf16>, tensor<60x136xbf16>)
          %49:2 = "tlir.Buffer"(%26) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayout1 = #tlir.layout<RV,RM,UA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kHead1MultipleSample = false, kIsStageBuffer = false, kMacID = "default_198", kName = "tbuf1u_0_0_198", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kRereads1 = [1], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 198 : i64, kUserCreated = true} : (tensor<3xi32>) -> (tensor<3xi32>, tensor<3xi32>)
          %50 = "tlir.Index"(%48#1, %49#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kDim = 0 : i64, kIsCriticalStage = false, kLatency = 1.100000e+01 : f64, kMacID = "ptconvcnn__lambda_layer__indexselect", kName = "ptconvcnn__lambda_layer__indexselect", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.100000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "rail_index_0_0_290", kUniqueId = 290 : i64, kUserCreated = true} : (tensor<60x136xbf16>, tensor<3xi32>) -> tensor<3x136xbf16>
          %51:2 = "tlir.Buffer"(%50) {DataLayout0 = #tlir.layout<CV,CM,VA>, DataLayout1 = #tlir.layout<CV,CM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kLayoutPermutation = [1, 0], kMacID = "default_202", kName = "tbuf2u_0_0_202", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 202 : i64, kUserCreated = true} : (tensor<3x136xbf16>) -> (tensor<136x3xbf16>, tensor<136x3xbf16>)
          %52 = "tlir.Reshape"(%51#1) {DataLayout0 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape", kName = "ptconvcnn__conv_layer__reshape", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_0_0_292", kUniqueId = 292 : i64, kUserCreated = true} : (tensor<136x3xbf16>) -> tensor<136x3x1xbf16>
          %53:2 = "tlir.Buffer"(%52) {DataLayout0 = #tlir.layout<DV,DM,VA>, DataLayout1 = #tlir.layout<DV,DM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsImageBuffer = true, kIsStageBuffer = true, kMacID = "default_204", kName = "gbuf2u_0_0_204", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 204 : i64, kUserCreated = true} : (tensor<136x3x1xbf16>) -> (tensor<136x3x1xbf16>, tensor<136x3x1xbf16>)
          %54 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayoutGatherInput = #tlir.layout<DV,DM,VA>, DataLayoutGatherOutput = #tlir.layout<RV,CM,VA>, DataPtrgather.list = [768, 384], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = false, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [1, 96, 5, 32], gather.base_mult = [0, 0, 64, 0], gather.base_stride = [1, 32, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = true, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 3 : i64, gather.fixed_length = 32 : i64, gather.group_packed = 480 : i64, gather.group_unpacked = 480 : i64, gather.input_vec_base = 0 : i64, gather.input_vec_bound = 14 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 96 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [1, 96, 5, 32], gather.offset_mult = [0, 1, 0, 1], gather.offset_stride = [1, 32, 1, 1], gather.output_mode = 1 : i64, gather.output_shape = [1, 408], gather.pace_shape = [32, 408], gather.permute = true, gather.reread = 43 : i64, gather.seg_length = 32 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 1 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 30720 : i64, gather.total_unpacked = 480 : i64, gather.use_tile_counter = false, kConfigured = true, kGroup = 16 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = false, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "ptconvcnn__conv_layer__conv2d_conv_fwd_stream0__gather_list", kPlacementHint = [1, 0], kStageMultiplier = 1 : i64, kUniqueId = 293 : i64, kUserCreated = true} : () -> tensor<96xi32>
          %55 = "tlir.Load"(%54) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kConfigured = true, kGroup = 16 : i64, kGroupedDramLayoutName = "ptconvcnn__conv_layer__conv2d_conv_fwd_stream0__gather_list_0_0_386", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_386", kName = "ptconvcnn__conv_layer__conv2d_conv_fwd_stream0__gather_list_0_0_386", kPlacementHint = [1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_0_0_386", kUniqueId = 386 : i64, kUseVectorTranspose = false, kUserCreated = false} : (tensor<96xi32>) -> tensor<96xi32>
          %56:2 = "tlir.Buffer"(%55) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 2 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "lbuf1a_0_0_396", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 396 : i64, kUserCreated = false} : (tensor<96xi32>) -> (tensor<96xi32>, tensor<96xi32>)
          %57 = "tlir.Gather"(%53#1, %56#1) {DataLayout0 = #tlir.layout<RV:UL,CM:UL,VA:UL>, DataLayoutGatherInput = #tlir.layout<DV,DM,VA>, DataLayoutGatherOutput = #tlir.layout<RV,CM,VA>, DataPtrgather.list = [1152, 384], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = false, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [1, 96, 5, 32], gather.base_mult = [0, 0, 64, 0], gather.base_stride = [1, 32, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = true, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 3 : i64, gather.fixed_length = 32 : i64, gather.group_packed = 480 : i64, gather.group_unpacked = 480 : i64, gather.input_vec_base = 0 : i64, gather.input_vec_bound = 14 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 96 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [1, 96, 5, 32], gather.offset_mult = [0, 1, 0, 1], gather.offset_stride = [1, 32, 1, 1], gather.output_mode = 1 : i64, gather.output_shape = [1, 408], gather.pace_shape = [32, 408], gather.permute = true, gather.reread = 43 : i64, gather.seg_length = 32 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 1 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 30720 : i64, gather.total_unpacked = 480 : i64, gather.use_tile_counter = false, kConfigured = true, kDepth2Col = false, kDepth2ColPointwise = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "gather294", kPaceMultiplier = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingTransposeShape = [136, 96], kUniqueId = 294 : i64, kUserCreated = true} : (tensor<136x3x1xbf16>, tensor<96xi32>) -> tensor<1x408xbf16>
          %58:2 = "tlir.Buffer"(%57) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 6 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = true, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "sbuf2u_0_0_295", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kUniqueId = 295 : i64, kUserCreated = true} : (tensor<1x408xbf16>) -> (tensor<1x408xbf16>, tensor<1x408xbf16>)
          %59:22 = "tlir.Split"(%35#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, DataLayout10 = #tlir.layout<CV,RM,VA>, DataLayout11 = #tlir.layout<CV,RM,VA>, DataLayout12 = #tlir.layout<CV,RM,VA>, DataLayout13 = #tlir.layout<CV,RM,VA>, DataLayout14 = #tlir.layout<CV,RM,VA>, DataLayout15 = #tlir.layout<CV,RM,VA>, DataLayout16 = #tlir.layout<CV,RM,VA>, DataLayout17 = #tlir.layout<CV,RM,VA>, DataLayout18 = #tlir.layout<CV,RM,VA>, DataLayout19 = #tlir.layout<CV,RM,VA>, DataLayout2 = #tlir.layout<CV,RM,VA>, DataLayout20 = #tlir.layout<CV,RM,VA>, DataLayout21 = #tlir.layout<CV,RM,VA>, DataLayout3 = #tlir.layout<CV,RM,VA>, DataLayout4 = #tlir.layout<CV,RM,VA>, DataLayout5 = #tlir.layout<CV,RM,VA>, DataLayout6 = #tlir.layout<CV,RM,VA>, DataLayout7 = #tlir.layout<CV,RM,VA>, DataLayout8 = #tlir.layout<CV,RM,VA>, DataLayout9 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples10 = 1 : i64, NumSamples10S = 2 : i64, NumSamples11 = 1 : i64, NumSamples11S = 2 : i64, NumSamples12 = 1 : i64, NumSamples12S = 2 : i64, NumSamples13 = 1 : i64, NumSamples13S = 2 : i64, NumSamples14 = 1 : i64, NumSamples14S = 2 : i64, NumSamples15 = 1 : i64, NumSamples15S = 2 : i64, NumSamples16 = 1 : i64, NumSamples16S = 2 : i64, NumSamples17 = 1 : i64, NumSamples17S = 2 : i64, NumSamples18 = 1 : i64, NumSamples18S = 2 : i64, NumSamples19 = 1 : i64, NumSamples19S = 2 : i64, NumSamples1S = 2 : i64, NumSamples2 = 1 : i64, NumSamples20 = 1 : i64, NumSamples20S = 2 : i64, NumSamples21 = 1 : i64, NumSamples21S = 2 : i64, NumSamples2S = 2 : i64, NumSamples3 = 1 : i64, NumSamples3S = 2 : i64, NumSamples4 = 1 : i64, NumSamples4S = 2 : i64, NumSamples5 = 1 : i64, NumSamples5S = 2 : i64, NumSamples6 = 1 : i64, NumSamples6S = 2 : i64, NumSamples7 = 1 : i64, NumSamples7S = 2 : i64, NumSamples8 = 1 : i64, NumSamples8S = 2 : i64, NumSamples9 = 1 : i64, NumSamples9S = 2 : i64, kAxis = 1 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "split_kernel_gbuf_0_0_296", kPlacementHint = [1, 0], kPreferTBuffer = false, kSectionSizes = [12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 12 : index, 4 : index], kSplitGemmReread = true, kSplitType = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "split_kernel_gbuf_0_0_296", kUniqueId = 296 : i64, kUserCreated = true} : (tensor<408x256xbf16>) -> (tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x12xbf16>, tensor<408x4xbf16>)
          %60 = "tlir.Linear"(%58#1, %59#0) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_297", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_297", kUniqueId = 297 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %61 = "tlir.Linear"(%58#1, %59#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_298", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_298", kUniqueId = 298 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %62 = "tlir.Linear"(%58#1, %59#2) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_299", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 24 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_299", kUniqueId = 299 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %63 = "tlir.Linear"(%58#1, %59#3) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_300", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 36 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_300", kUniqueId = 300 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %64 = "tlir.Linear"(%58#1, %59#4) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_301", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_301", kUniqueId = 301 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %65 = "tlir.Linear"(%58#1, %59#5) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_302", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_302", kUniqueId = 302 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %66 = "tlir.Linear"(%58#1, %59#6) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_303", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 24 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_303", kUniqueId = 303 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %67 = "tlir.Linear"(%58#1, %59#7) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_304", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 36 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_304", kUniqueId = 304 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %68 = "tlir.Linear"(%58#1, %59#8) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_305", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_305", kUniqueId = 305 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %69 = "tlir.Linear"(%58#1, %59#9) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_306", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_306", kUniqueId = 306 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %70 = "tlir.Linear"(%58#1, %59#10) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_307", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 24 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_307", kUniqueId = 307 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %71 = "tlir.Linear"(%58#1, %59#11) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_308", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 36 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_308", kUniqueId = 308 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %72 = "tlir.Linear"(%58#1, %59#12) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_309", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_309", kUniqueId = 309 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %73 = "tlir.Linear"(%58#1, %59#13) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_310", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_310", kUniqueId = 310 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %74 = "tlir.Linear"(%58#1, %59#14) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_311", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 24 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_311", kUniqueId = 311 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %75 = "tlir.Linear"(%58#1, %59#15) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_312", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 36 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_312", kUniqueId = 312 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %76 = "tlir.Linear"(%58#1, %59#16) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_313", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_313", kUniqueId = 313 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %77 = "tlir.Linear"(%58#1, %59#17) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_314", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_314", kUniqueId = 314 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %78 = "tlir.Linear"(%58#1, %59#18) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_315", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 24 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_315", kUniqueId = 315 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %79 = "tlir.Linear"(%58#1, %59#19) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_316", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 36 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_316", kUniqueId = 316 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %80 = "tlir.Linear"(%58#1, %59#20) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 2 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_317", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_317", kUniqueId = 317 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x12xbf16>) -> tensor<1x12xbf16>
          %81 = "tlir.Linear"(%58#1, %59#21) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 2 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "biggemm_0_0_318", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 12 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kStreamingColPar = true, kTemplateName = "biggemm_0_0_318", kUniqueId = 318 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<1x408xbf16>, tensor<408x4xbf16>) -> tensor<1x4xbf16>
          %82 = "tlir.ConcatView"(%60, %61, %62, %63, %64, %65, %66, %67, %68, %69, %70, %71, %72, %73, %74, %75, %76, %77, %78, %79, %80, %81) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayoutkPreserveLayout = #tlir.layout<??,??,??>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAxis = 1 : i64, kConcatCollapse = false, kConcatGroup = 4 : i64, kConcatType = 1 : i64, kConfigured = true, kForceM = 0 : i64, kIntColParVectors = 12 : i64, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "concatview435", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "concat_view_0_0_435", kTimeSlices = [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 4], kUniqueId = 435 : i64, kUserCreated = false} : (tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x12xbf16>, tensor<1x4xbf16>) -> tensor<1x256xbf16>
          %83:2 = "tlir.Buffer"(%82) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsLowerForConcatView = true, kIsStageBuffer = true, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "gbuf2u_0_0_321", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 321 : i64, kUserCreated = true} : (tensor<1x256xbf16>) -> (tensor<1x256xbf16>, tensor<1x256xbf16>)
          %84 = "tlir.BiasTransposeAdd"(%83#1, %31) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "bias_transpose_add_0_0_322", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStreaming = false, kTemplateName = "bias_transpose_add_0_0_322", kUniqueId = 322 : i64, kUserCreated = true} : (tensor<1x256xbf16>, tensor<256x1xbf16>) -> tensor<1x256xbf16>
          %85 = "tlir.StreamingPermute"(%84) {DataLayout0 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d", kName = "streaming_transpose_0_0_323", kOutputReshape = [256 : index, 1 : index, 1 : index], kPermuteType = 7 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "streaming_transpose_0_0_323", kUniqueId = 323 : i64, kUserCreated = true} : (tensor<1x256xbf16>) -> tensor<256x1x1xbf16>
          %86:2 = "tlir.Buffer"(%85) {DataLayout0 = #tlir.layout<DV,DM,VA>, DataLayout1 = #tlir.layout<DV,DM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kMacID = "default_206", kName = "gbuf2u_0_0_206", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 4 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 206 : i64, kUserCreated = true} : (tensor<256x1x1xbf16>) -> (tensor<256x1x1xbf16>, tensor<256x1x1xbf16>)
          %87 = "tlir.Reshape"(%86#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape_2", kName = "ptconvcnn__conv_layer__reshape_2", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_0_0_324", kUniqueId = 324 : i64, kUserCreated = true} : (tensor<256x1x1xbf16>) -> tensor<256x1xbf16>
          %88:2 = "tlir.Buffer"(%87) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1Hydra = 4 : i64, kHead1MultipleSample = false, kIsStageBuffer = true, kMacID = "default_208", kName = "gbuf2u_0_0_208", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 208 : i64, kUserCreated = true} : (tensor<256x1xbf16>) -> (tensor<256x1xbf16>, tensor<256x1xbf16>)
          %89 = "tlir.Linear"(%32, %88#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kBiasCaching = false, kBoxLayout = true, kBoxLayoutAnchor = [], kBoxPerPartition = true, kBoxPerWbufSplit = false, kConfigured = true, kDieID = -1 : i64, kDisableWrFrontingPMU = false, kExclusiveRoutes = false, kExclusiveVCA = false, kInputAIsWeight = true, kIsCriticalStage = false, kIsFromConv1x1 = false, kLatency = 4.570000e+02 : f64, kMacID = "ptconvcnn__dense_layer__linear", kName = "ptconvcnn__dense_layer__linear", kNumColComputeUnits = 1 : i64, kNumPartitions = 4 : i64, kNumRowComputeUnits = 32 : i64, kPlacementHint = [1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kStageId = 0 : i64, kStageLatency = 4.570000e+02 : f64, kStageMultiplier = 1 : i64, kStagingBias = false, kTemplateName = "biggemm_0_0_325", kUniqueId = 325 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufSplit = false} : (tensor<4080x256xbf16>, tensor<256x1xbf16>) -> tensor<4080x1xbf16>
          %90:2 = "tlir.Buffer"(%89) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kHead1MultipleSample = false, kIsStageBuffer = false, kMacID = "default_393", kName = "gbuf1a_0_0_393", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 393 : i64, kUserCreated = false} : (tensor<4080x1xbf16>) -> (tensor<4080x1xbf16>, tensor<4080x1xbf16>)
          %91 = "tlir.AddBias"(%33, %90#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_390", kName = "bias_add_0_0_390", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "bias_add_0_0_390", kUniqueId = 390 : i64, kUserCreated = false, kWbufSplit = false, kWeightCaching = false} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
          %92:2 = "tlir.Buffer"(%91) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, DataLayoutkLayoutCastOutputLayout = #tlir.layout<CV,CM,VA>, DataLayoutkLayoutCastRequiredLayout = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kLayoutCastChecked = false, kLayoutCastEmbedded = false, kMacID = "default_210", kName = "gbuf2u_0_0_210", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 210 : i64, kUserCreated = true} : (tensor<4080x1xbf16>) -> (tensor<4080x1xbf16>, tensor<4080x1xbf16>)
          %93 = "tlir.LayoutCast"(%92#1) {DataLayout0 = #tlir.layout<CV,CM,VA>, DataLayoutkOutputLayout = #tlir.layout<CV,CM,VA>, DataLayoutkRequiredLayout = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChecked = false, kConfigured = true, kMacID = "default_438", kName = "layout_cast_0_0_438", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "layout_cast_0_0_438", kUniqueId = 438 : i64, kUserCreated = false} : (tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
          %94 = "tlir.PermuteView"(%93) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 0.000000e+00 : f64, kMacID = "ptconvcnn__dense_layer__linear_t_output0", kName = "ptconvcnn__dense_layer__linear_t_output0", kPermutation = [1, 0], kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 0.000000e+00 : f64, kStageMultiplier = 1 : i64, kTemplateName = "permute_view_0_0_326", kUniqueId = 326 : i64, kUserCreated = true} : (tensor<4080x1xbf16>) -> tensor<1x4080xbf16>
          %95:2 = "tlir.Buffer"(%94) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = true, kHead0Hydra = 0 : i64, kHead0MultipleSample = true, kHead0ReadParFactor = 0 : i64, kHead1CtrlFlowEnable = true, kHead1Hydra = 0 : i64, kHead1MultipleSample = true, kHead1ReadParFactor = 0 : i64, kIsImageBuffer = false, kIsSplitImageBuffer = false, kIsStageBuffer = true, kMacID = "default_440", kName = "gbuf2a_0_0_440", kNumHead0RdEn = 2 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kReadVT = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTranspose = 0 : i64, kUniqueId = 440 : i64, kUserCreated = false, kWriteVT = false} : (tensor<1x4080xbf16>) -> (tensor<1x4080xbf16>, tensor<1x4080xbf16>)
          %96 = "tlir.Reshape"(%95#0) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__reshape", kName = "ptconvcnn__reshape", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_0_0_327", kUniqueId = 327 : i64, kUserCreated = true} : (tensor<1x4080xbf16>) -> tensor<4080xbf16>
          %97 = "tlir.Reshape"(%95#1) {DataLayout0 = #tlir.layout<RV,RM,SA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__view", kName = "ptconvcnn__view", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_0_0_328", kUniqueId = 328 : i64, kUserCreated = true} : (tensor<1x4080xbf16>) -> tensor<30x136xbf16>
          %98:2 = "tlir.Buffer"(%87) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = true, kMacID = "default_397", kName = "gbuf2a_0_0_397", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 397 : i64, kUserCreated = false} : (tensor<256x1xbf16>) -> (tensor<256x1xbf16>, tensor<256x1xbf16>)
          "tlir.Store"(%13, %98#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 20 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kMacID = "default_274", kName = "ptconvcnn__conv_layer__reshape_20_used_by_ptconvcnn__dense_layer__linear_bwd_weight_0_0_274", kOpRWPattern0 = "kWriteOperand", kPlacementHint = [1, 0], kRemovesAlignment = false, kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStoreSlice = true, kStoreTile = false, kTemplateName = "store_0_0_274", kUniqueId = 274 : i64, kUseVectorTranspose = true, kUserCreated = true} : (tensor<1x256x1xbf16>, tensor<256x1xbf16>) -> ()
          %99:2 = "tlir.Buffer"(%96) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = true, kHead0Hydra = 0 : i64, kHead0MultipleSample = true, kHead0ReadParFactor = 0 : i64, kHead1CtrlFlowEnable = false, kHead1Hydra = 0 : i64, kHead1ReadParFactor = 0 : i64, kIsImageBuffer = false, kIsSplitImageBuffer = false, kIsStageBuffer = true, kMacID = "default_441", kName = "gbuf2a_0_0_441", kNumHead0RdEn = 2 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kReadVT = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTranspose = 0 : i64, kUniqueId = 441 : i64, kUserCreated = false, kWriteVT = false} : (tensor<4080xbf16>) -> (tensor<4080xbf16>, tensor<4080xbf16>)
          "tlir.Store"(%14, %99#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 21 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kMacID = "default_275", kName = "ptconvcnn__reshape0_used_by_ptconvcnn__criterion__mseloss_bwd_sub_0_0_275", kOpRWPattern0 = "kWriteOperand", kPlacementHint = [1, 0], kRemovesAlignment = false, kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStoreSlice = true, kStoreTile = false, kTemplateName = "store_0_0_275", kUniqueId = 275 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x4080xbf16>, tensor<4080xbf16>) -> ()
          "tlir.mutate.TemporalConcat"(%34, %99#0) {kAxis = 0 : i64, kChipID = 0 : i64, kConfigured = true, kIsReverse = false, kKeepDim = false, kMacID = "default_217", kName = "temporalconcat217", kOpRWPattern0 = "kWriteOperand", kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "tconcat_0_0_217", kUniqueId = 217 : i64, kUserCreated = true} : (tensor<1x4080xbf16>, tensor<4080xbf16>) -> ()
          %100:2 = "tlir.Buffer"(%97) {DataLayout0 = #tlir.layout<RV,RM,SA>, DataLayout1 = #tlir.layout<RV,RM,SA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = true, kMacID = "default_399", kName = "gbuf2a_0_0_399", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 399 : i64, kUserCreated = false} : (tensor<30x136xbf16>) -> (tensor<30x136xbf16>, tensor<30x136xbf16>)
          "tlir.Store"(%15, %100#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 22 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kMacID = "default_276", kName = "ptconvcnn__view__outputs__0_0_0_276", kOpRWPattern0 = "kWriteOperand", kPlacementHint = [1, 0], kRemovesAlignment = true, kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStoreSlice = true, kStoreTile = false, kTemplateName = "store_0_0_276", kUniqueId = 276 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x30x136xbf16>, tensor<30x136xbf16>) -> ()
          "tlir.terminator"() {kConfigured = true, kMacID = "default_280", kName = "terminator280", kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 280 : i64, kUserCreated = true} : () -> ()
        }) {kConfigured = true, kMacID = "default_195", kName = "metapipeline279", kNumIterations = 1 : i64, kStageId = 0 : i64, kUniqueId = 279 : i64, kUserCreated = true, type = none} : () -> ()
        %36:2 = "tlir.Buffer"(%34) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kCoalesceFactor = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsLowerFromTemporalConcat = true, kIsStageBuffer = false, kMacID = "default_432", kName = "gbuf2a_0_0_432", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 432 : i64, kUserCreated = false} : (tensor<1x4080xbf16>) -> (tensor<1x4080xbf16>, tensor<1x4080xbf16>)
        %37 = "tlir.Load"(%6) {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 23 : i64, kGroupedDramLayoutName = "out_window_0_0_104", kIsGrouped = false, kIterations = 1 : i64, kMacID = "default_104", kName = "out_window_0_0_104", kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_0_0_104", kUniqueId = 104 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x30x136xbf16>) -> tensor<1x30x136xbf16>
        %38:2 = "tlir.Buffer"(%37) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayout1 = #tlir.layout<RV,RM,UA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_431", kName = "gbuf1a_0_0_431", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 431 : i64, kUserCreated = false} : (tensor<1x30x136xbf16>) -> (tensor<1x30x136xbf16>, tensor<1x30x136xbf16>)
        %39 = "tlir.Realign"(%38#1) {DataLayout0 = #tlir.layout<RV,RM,SA>, DataLayoutkInputLayout = #tlir.layout<RV,RM,UA>, DataLayoutkOutputLayout = #tlir.layout<RV,RM,SA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_418", kName = "realign_0_0_418", kStageId = 0 : i64, kTemplateName = "realign_0_0_418", kUniqueId = 418 : i64, kUserCreated = false} : (tensor<1x30x136xbf16>) -> tensor<1x30x136xbf16>
        %40:2 = "tlir.Buffer"(%39) {DataLayout0 = #tlir.layout<RV,RM,SA>, DataLayout1 = #tlir.layout<RV,RM,SA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_400", kName = "gbuf1a_0_0_400", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 400 : i64, kUserCreated = false} : (tensor<1x30x136xbf16>) -> (tensor<1x30x136xbf16>, tensor<1x30x136xbf16>)
        %41 = "tlir.Reshape"(%40#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__reshape_1", kName = "ptconvcnn__reshape_1", kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "reshape_0_0_329", kUniqueId = 329 : i64, kUserCreated = true} : (tensor<1x30x136xbf16>) -> tensor<1x4080xbf16>
        %42 = "tlir.Sub"(%36#1, %41) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kBinaryOp = true, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 3.190000e+02 : f64, kMacID = "default_70", kName = "sub_0_0_330", kStageId = 0 : i64, kStageLatency = 3.190000e+02 : f64, kTemplateName = "sub_0_0_330", kUniqueId = 330 : i64, kUserCreated = true} : (tensor<1x4080xbf16>, tensor<1x4080xbf16>) -> tensor<1x4080xbf16>
        %43:2 = "tlir.Buffer"(%42) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead0Hydra = 0 : i64, kHead0ReadParFactor = 0 : i64, kHead1CtrlFlowEnable = false, kHead1Hydra = 0 : i64, kHead1ReadParFactor = 0 : i64, kIsImageBuffer = false, kIsSplitImageBuffer = false, kIsStageBuffer = false, kMacID = "default_442", kName = "gbuf1a_0_0_442", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kReadVT = false, kStageId = 0 : i64, kTranspose = 0 : i64, kUniqueId = 442 : i64, kUserCreated = false, kWriteVT = false} : (tensor<1x4080xbf16>) -> (tensor<1x4080xbf16>, tensor<1x4080xbf16>)
        %44 = "tlir.Mul"(%43#0, %43#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kBinaryOp = true, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 3.190000e+02 : f64, kMacID = "default_71", kName = "mul_0_0_331", kStageId = 0 : i64, kStageLatency = 3.190000e+02 : f64, kTemplateName = "mul_0_0_331", kUniqueId = 331 : i64, kUserCreated = true} : (tensor<1x4080xbf16>, tensor<1x4080xbf16>) -> tensor<1x4080xbf16>
        %45 = "tlir.MeanAll"(%44) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 3.190000e+02 : f64, kMacID = "default_72", kName = "mean_unalign_0_0_332", kStageId = 0 : i64, kStageLatency = 3.190000e+02 : f64, kTemplateName = "mean_unalign_0_0_332", kUniqueId = 332 : i64, kUserCreated = true} : (tensor<1x4080xbf16>) -> tensor<1xbf16>
        %46:2 = "tlir.Buffer"(%45) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_401", kName = "gbuf1a_0_0_401", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 401 : i64, kUserCreated = false} : (tensor<1xbf16>) -> (tensor<1xbf16>, tensor<1xbf16>)
        "tlir.Store"(%16, %46#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 24 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_125", kName = "_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = false, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_0_0_125", kUniqueId = 125 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1xbf16>, tensor<1xbf16>) -> ()
        "tlir.terminator"() {kConfigured = true, kMacID = "default_278", kName = "terminator278", kStageId = 0 : i64, kUniqueId = 278 : i64, kUserCreated = true} : () -> ()
      }) {kConfigured = true, kMacID = "default_277", kName = "chip0_0", kPartitionId = 0 : i64, kStageId = 0 : i64, kUniqueId = 277 : i64, kUserCreated = true, type = none} : () -> ()
      "tlir.terminator"() {kConfigured = true, kMacID = "default_126", kName = "terminator126", kStageId = 0 : i64, kUniqueId = 126 : i64, kUserCreated = true} : () -> ()
    }) {kConfigured = true, kGlobalId = 0 : i64, kIsHostSection = false, kMacID = "default_98", kName = "section0", kPartitionId = 0 : i64, kSectionLatency = 5.6866094382712618E-5 : f64, kSectionName = "$FWD", kSectionUniqueName = "ptconvcnn__lambda_layer__indexselect_as_initial", kStageId = 0 : i64, kUniqueId = 98 : i64, kUserCreated = true, type = none} : () -> ()
    "tlir.Section"() ( {
      %21 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayoutGatherInput = #tlir.layout<CV,RM,VA>, DataLayoutGatherOutput = #tlir.layout<CV,RM,VA>, DataPtrgather.list = [0, 384], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = false, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [1, 13, 256, 3], gather.base_mult = [0, 0, 64, 0], gather.base_stride = [1, 1, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = false, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 0 : i64, gather.fixed_length = 0 : i64, gather.group_packed = 13 : i64, gather.group_unpacked = 39 : i64, gather.input_vec_base = -1 : i64, gather.input_vec_bound = -1 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 39 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [1, 13, 256, 3], gather.offset_mult = [0, 3, 0, 1], gather.offset_stride = [1, 1, 1, 1], gather.output_mode = 0 : i64, gather.output_shape = [408, 256], gather.pace_shape = [], gather.permute = false, gather.reread = 1 : i64, gather.seg_length = 3 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 0 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 212992 : i64, gather.total_unpacked = 9984 : i64, gather.use_tile_counter = false, kChipID = 0 : i64, kConfigured = true, kGroup = 17 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = false, kLayoutHeuristics = false, kMacID = "default_158", kName = "gather_gradient_output_reshape_id1__gather_list", kUniqueId = 158 : i64, kUserCreated = true} : () -> tensor<96xi32>
      "tlir.Chip"() ( {
        %22 = "tlir.Load"(%7) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = -26 : i64, kGroupedDramLayoutName = "ptconvcnn__criterion__mseloss__outputs__0__grad_1_0_135", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_135", kName = "ptconvcnn__criterion__mseloss__outputs__0__grad_1_0_135", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_1_0_135", kUniqueId = 135 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1xbf16>) -> tensor<1xbf16>
        %23 = "tlir.Load"(%1) {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 25 : i64, kGroupedDramLayoutName = "inp_window_slice_1_1_0_148", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_148", kName = "inp_window_slice_1_1_0_148", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_1_0_148", kUniqueId = 148 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<3xi32>) -> tensor<3xi32>
        %24 = "tlir.mutable.AccumBuffer"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "default_220", kName = "ptconvcnn__dense_layer__linear_bwd_weight_accum_buffer", kStageId = 0 : i64, kTemplateName = "accum_buffer_1_0_220", kUniqueId = 220 : i64, kUserCreated = true} : () -> tensor<4080x256xbf16>
        %25 = "tlir.mutable.AccumBuffer"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "default_221", kName = "ptconvcnn__dense_layer__linear_bwd_weight_accum_buffer_1", kStageId = 0 : i64, kTemplateName = "accum_buffer_1_0_221", kUniqueId = 221 : i64, kUserCreated = true} : () -> tensor<4080x1xbf16>
        %26 = "tlir.mutable.AccumBuffer"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "default_222", kName = "ptconvcnn__conv_layer__conv2d_bwd_accum_buffer", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kTemplateName = "accum_buffer_1_0_222", kUniqueId = 222 : i64, kUserCreated = true} : () -> tensor<480x256xbf16>
        %27 = "tlir.mutable.AccumBuffer"() {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "default_223", kName = "ptconvcnn__conv_layer__conv2d_bwd_accum_buffer_1", kStageId = 0 : i64, kTemplateName = "accum_buffer_1_0_223", kUniqueId = 223 : i64, kUserCreated = true} : () -> tensor<256x1xbf16>
        "tlir.iter_loop.MetaPipeline"() ( {
          %43 = "tlir.Load"(%8) {DataLayout0 = #tlir.layout<RV,RM,SA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = 4 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 26 : i64, kGroupedDramLayoutName = "ptconvcnn__view__outputs__0__grad_1_0_269", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLoadSlice = true, kLoadTile = false, kMacID = "default_269", kMultiLoadDepth = 2 : i64, kName = "ptconvcnn__view__outputs__0__grad_1_0_269", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_269", kUniqueId = 269 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x30x136xbf16>) -> tensor<30x136xbf16>
          %44:2 = "tlir.Buffer"(%43) {DataLayout0 = #tlir.layout<RV,RM,SA>, DataLayout1 = #tlir.layout<RV,RM,SA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kMacID = "default_226", kName = "gbuf2u_1_0_226", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 4 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 226 : i64, kUserCreated = true} : (tensor<30x136xbf16>) -> (tensor<30x136xbf16>, tensor<30x136xbf16>)
          %45 = "tlir.Reshape"(%44#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__view_bwd", kName = "ptconvcnn__view_bwd", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_336", kUniqueId = 336 : i64, kUserCreated = true} : (tensor<30x136xbf16>) -> tensor<1x4080xbf16>
          %46 = "tlir.Load"(%6) {DataLayout0 = #tlir.layout<RV,RM,SA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = 4 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 27 : i64, kGroupedDramLayoutName = "out_window_1_0_270", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLoadSlice = true, kLoadTile = false, kMacID = "default_270", kMultiLoadDepth = 2 : i64, kName = "out_window_1_0_270", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_270", kUniqueId = 270 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x30x136xbf16>) -> tensor<30x136xbf16>
          %47:2 = "tlir.Buffer"(%46) {DataLayout0 = #tlir.layout<RV,RM,SA>, DataLayout1 = #tlir.layout<RV,RM,SA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kMacID = "default_229", kName = "gbuf2u_1_0_229", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 229 : i64, kUserCreated = true} : (tensor<30x136xbf16>) -> (tensor<30x136xbf16>, tensor<30x136xbf16>)
          %48 = "tlir.Reshape"(%47#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__reshape_1_recompute_", kName = "ptconvcnn__reshape_1_recompute_", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_337", kUniqueId = 337 : i64, kUserCreated = true} : (tensor<30x136xbf16>) -> tensor<4080xbf16>
          %49 = "tlir.Load"(%14) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 28 : i64, kGroupedDramLayoutName = "ptconvcnn__reshape0_used_by_ptconvcnn__criterion__mseloss_bwd_sub_1_0_271", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLinearGradAInputHint = 1 : i64, kLoadSlice = true, kLoadTile = false, kMacID = "default_271", kMultiLoadDepth = 2 : i64, kName = "ptconvcnn__reshape0_used_by_ptconvcnn__criterion__mseloss_bwd_sub_1_0_271", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_271", kUniqueId = 271 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x4080xbf16>) -> tensor<4080xbf16>
          %50:2 = "tlir.Buffer"(%49) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kLinearGradAInputHint = 1 : i64, kMacID = "default_232", kName = "gbuf2u_1_0_232", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 232 : i64, kUserCreated = true} : (tensor<4080xbf16>) -> (tensor<4080xbf16>, tensor<4080xbf16>)
          %51 = "tlir.Sub"(%50#1, %48) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kBinaryOp = true, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.060000e+02 : f64, kLinearGradAInputHint = 1 : i64, kMacID = "ptconvcnn__criterion__mseloss_bwd", kName = "ptconvcnn__criterion__mseloss_bwd_sub", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.060000e+02 : f64, kStageMultiplier = 1 : i64, kTemplateName = "sub_1_0_338", kUniqueId = 338 : i64, kUserCreated = true} : (tensor<4080xbf16>, tensor<4080xbf16>) -> tensor<4080xbf16>
          %52 = "tlir.Scale"(%51) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConditionalScaling = false, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.060000e+02 : f64, kLinearGradAInputHint = 1 : i64, kMacID = "default_75", kName = "scale_1_0_339", kPlacementHint = [0, 1, 1, 0], kScaleFactorFloat = 4.920960e-04 : bf16, kStageId = 0 : i64, kStageLatency = 1.060000e+02 : f64, kStageMultiplier = 1 : i64, kTemplateName = "scale_1_0_339", kUniqueId = 339 : i64, kUserCreated = true, kUsingInputB = false} : (tensor<4080xbf16>) -> tensor<4080xbf16>
          %53 = "tlir.Scale"(%52, %22) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConditionalScaling = false, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.060000e+02 : f64, kLinearGradAInputHint = 1 : i64, kMacID = "default_76", kName = "scale_1_0_340", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.060000e+02 : f64, kStageMultiplier = 1 : i64, kTemplateName = "scale_1_0_340", kUniqueId = 340 : i64, kUserCreated = true, kUsingInputB = true} : (tensor<4080xbf16>, tensor<1xbf16>) -> tensor<4080xbf16>
          %54:2 = "tlir.Buffer"(%53) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kLinearGradAInputHint = 1 : i64, kMacID = "default_237", kName = "gbuf2u_1_0_237", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 4 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 237 : i64, kUserCreated = true} : (tensor<4080xbf16>) -> (tensor<4080xbf16>, tensor<4080xbf16>)
          %55 = "tlir.Reshape"(%54#1) {DataLayout0 = #tlir.layout<RV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kLinearGradAInputHint = 1 : i64, kMacID = "ptconvcnn__reshape_bwd", kName = "ptconvcnn__reshape_bwd", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_341", kUniqueId = 341 : i64, kUserCreated = true} : (tensor<4080xbf16>) -> tensor<1x4080xbf16>
          %56 = "tlir.LayoutCast"(%45) {DataLayout0 = #tlir.layout<RV,CM,VA>, DataLayoutkOutputLayout = #tlir.layout<RV,CM,VA>, DataLayoutkRequiredLayout = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChecked = false, kConfigured = true, kMacID = "default_439", kName = "layout_cast_1_0_439", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "layout_cast_1_0_439", kUniqueId = 439 : i64, kUserCreated = false} : (tensor<1x4080xbf16>) -> tensor<1x4080xbf16>
          %57 = "tlir.AddN"(%55, %56) {DataLayout0 = #tlir.layout<RV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.060000e+02 : f64, kLinearGradAInputHint = 1 : i64, kMacID = "ptconvcnn__dense_layer__linear_t_output0_bwd_addn0", kName = "ptconvcnn__dense_layer__linear_t_output0_bwd_addn0", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.060000e+02 : f64, kStageMultiplier = 1 : i64, kTemplateName = "addn_1_0_342", kUniqueId = 342 : i64, kUserCreated = true} : (tensor<1x4080xbf16>, tensor<1x4080xbf16>) -> tensor<1x4080xbf16>
          %58:2 = "tlir.Buffer"(%57) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kLayoutPermutation = [1, 0], kMacID = "default_244", kName = "gbuf2u_1_0_244", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 244 : i64, kUserCreated = true} : (tensor<1x4080xbf16>) -> (tensor<4080x1xbf16>, tensor<4080x1xbf16>)
          %59 = "tlir.Load"(%5) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 29 : i64, kGroupedDramLayoutName = "ptconvcnn__dense_layer__weight_1_0_344", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_140", kName = "ptconvcnn__dense_layer__weight_1_0_344", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_344", kUniqueId = 344 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>) -> tensor<4080x256xbf16>
          %60:2 = "tlir.Buffer"(%59) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kHead1MultipleSample = false, kIsStageBuffer = false, kMacID = "default_402", kName = "gbuf1a_1_0_402", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 5 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTranspose = 2 : i64, kUniqueId = 402 : i64, kUserCreated = false} : (tensor<4080x256xbf16>) -> (tensor<4080x256xbf16>, tensor<256x4080xbf16>)
          %61 = "tlir.Linear"(%60#1, %58#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kBoxLayout = true, kBoxPerPartition = true, kConfigured = true, kInputAIsWeight = true, kIsCriticalStage = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_loss", kName = "ptconvcnn__dense_layer__linear_bwd_loss_grad_b", kNumColComputeUnits = 1 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 8 : i64, kPlacementHint = [0, 1, 1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kStageId = 0 : i64, kStageLatency = 4.367000e+03 : f64, kStageMultiplier = 1 : i64, kTemplateName = "biggemm_1_0_346", kUniqueId = 346 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufSplit = false} : (tensor<256x4080xbf16>, tensor<4080x1xbf16>) -> tensor<256x1xbf16>
          %62 = "tlir.Load"(%13) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 30 : i64, kGroupedDramLayoutName = "ptconvcnn__conv_layer__reshape_20_used_by_ptconvcnn__dense_layer__linear_bwd_weight_1_0_272", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLinearGradBInputHint = 1 : i64, kLoadSlice = true, kLoadTile = false, kMacID = "default_272", kMultiLoadDepth = 2 : i64, kName = "ptconvcnn__conv_layer__reshape_20_used_by_ptconvcnn__dense_layer__linear_bwd_weight_1_0_272", kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_272", kUniqueId = 272 : i64, kUseVectorTranspose = true, kUserCreated = true} : (tensor<1x256x1xbf16>) -> tensor<256x1xbf16>
          %63:2 = "tlir.Buffer"(%62) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kLinearGradBInputHint = 1 : i64, kMacID = "default_247", kName = "gbuf2u_1_0_247", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTranspose = 2 : i64, kUniqueId = 247 : i64, kUserCreated = true} : (tensor<256x1xbf16>) -> (tensor<256x1xbf16>, tensor<1x256xbf16>)
          %64:2 = "tlir.Buffer"(%57) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = true, kHead0MultipleSample = true, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kLayoutPermutation = [1, 0], kLinearGradAInputHint = 1 : i64, kMacID = "default_248", kName = "gbuf2u_1_0_248", kNumHead0RdEn = 1 : i64, kNumHead1RdEn = 1 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 248 : i64, kUseBothHeads = true, kUserCreated = true} : (tensor<1x4080xbf16>) -> (tensor<4080x1xbf16>, tensor<4080x1xbf16>)
          %65:3 = "tlir.BigLinearGrad"(%64#1, %63#1, %64#0) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, DataLayout2 = #tlir.layout<??,??,??>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kColPar = 1 : i64, kConfigured = true, kEnableAccumulatorA = true, kEnableAccumulatorBias = true, kEnableBoxAccumTailPmu = true, kEnableBoxLayout = true, kEnableBoxOutput = true, kEnableBoxPerPartition = false, kEnableFusedGradientBias = false, kEnableLoopBuffer = false, kExternalBTranspose = false, kHasBias = true, kIsCriticalStage = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_weight", kName = "ptconvcnn__dense_layer__linear_bwd_weight_grad_a", kNumPartitions = 32 : i64, kRowPar = 1 : i64, kStageId = 0 : i64, kStageLatency = 4.096000e+03 : f64, kStageMultiplier = 1 : i64, kTemplateName = "big_gemm_grad_1_0_348", kUniqueId = 348 : i64, kUseExternalBiasAccumulator = true, kUseExternalGradAAccumulator = true, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<1x256xbf16>, tensor<4080x1xbf16>) -> (tensor<4080x256xbf16>, tensor<4080x1xbf16>, tensor<4080x1xbf16>)
          %66:2 = "tlir.Buffer"(%61) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kMacID = "default_250", kName = "gbuf2u_1_0_250", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 250 : i64, kUserCreated = true} : (tensor<256x1xbf16>) -> (tensor<256x1xbf16>, tensor<256x1xbf16>)
          %67 = "tlir.Reshape"(%66#1) {DataLayout0 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape_2_bwd", kName = "ptconvcnn__conv_layer__reshape_2_bwd", kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_349", kUniqueId = 349 : i64, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1x1xbf16>
          %68 = "tlir.Load"(%2) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 31 : i64, kGroupedDramLayoutName = "inp_window_1_0_273", kIsGrouped = false, kIterations = 1 : i64, kKeepDim = false, kLoadSlice = true, kLoadTile = false, kMacID = "default_273", kMultiLoadDepth = 2 : i64, kName = "inp_window_1_0_273", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kReverseLoops = [false], kSliceAxes = [0], kSliceSize = 1 : i64, kSliceSubtensor = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_273", kUniqueId = 273 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<1x60x136xbf16>) -> tensor<60x136xbf16>
          %69:2 = "tlir.Buffer"(%68) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kMacID = "default_253", kName = "tbuf2u_1_0_253", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 253 : i64, kUserCreated = true} : (tensor<60x136xbf16>) -> (tensor<60x136xbf16>, tensor<60x136xbf16>)
          %70:2 = "tlir.Buffer"(%23) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayout1 = #tlir.layout<RV,RM,UA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kHead1MultipleSample = false, kIsStageBuffer = false, kMacID = "default_254", kName = "tbuf1u_1_0_254", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kRereads1 = [1], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kUniqueId = 254 : i64, kUserCreated = true} : (tensor<3xi32>) -> (tensor<3xi32>, tensor<3xi32>)
          %71 = "tlir.Index"(%69#1, %70#1) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kDim = 0 : i64, kIsCriticalStage = false, kLatency = 1.100000e+01 : f64, kMacID = "ptconvcnn__lambda_layer__indexselect_recompute_", kName = "ptconvcnn__lambda_layer__indexselect_recompute_", kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageLatency = 1.100000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "rail_index_1_0_350", kUniqueId = 350 : i64, kUserCreated = true} : (tensor<60x136xbf16>, tensor<3xi32>) -> tensor<3x136xbf16>
          %72:2 = "tlir.Buffer"(%71) {DataLayout0 = #tlir.layout<CV,CM,VA>, DataLayout1 = #tlir.layout<CV,CM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 7 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsStageBuffer = true, kLayoutPermutation = [1, 0], kMacID = "default_258", kName = "tbuf2u_1_0_258", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kUniqueId = 258 : i64, kUserCreated = true} : (tensor<3x136xbf16>) -> (tensor<136x3xbf16>, tensor<136x3xbf16>)
          %73 = "tlir.Reshape"(%72#1) {DataLayout0 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape_recompute_", kName = "ptconvcnn__conv_layer__reshape_recompute_", kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageLatency = 1.300000e+01 : f64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_352", kUniqueId = 352 : i64, kUserCreated = true} : (tensor<136x3xbf16>) -> tensor<136x3x1xbf16>
          %74:2 = "tlir.Buffer"(%67) {DataLayout0 = #tlir.layout<DV,DM,VA>, DataLayout1 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = true, kHead0Hydra = 0 : i64, kHead0MultipleSample = true, kHead0ReadParFactor = 0 : i64, kHead1CtrlFlowEnable = true, kHead1Hydra = 0 : i64, kHead1MultipleSample = true, kHead1ReadParFactor = 0 : i64, kIsImageBuffer = false, kIsSplitImageBuffer = false, kIsStageBuffer = true, kMacID = "default_443", kName = "gbuf2a_1_0_443", kNumHead0RdEn = 2 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReadVT = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTranspose = 0 : i64, kUniqueId = 443 : i64, kUserCreated = false, kWriteVT = false} : (tensor<256x1x1xbf16>) -> (tensor<256x1x1xbf16>, tensor<256x1x1xbf16>)
          %75 = "tlir.StreamingPermute"(%74#0) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "streaming_transpose_1_0_365", kPermuteType = 4 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "streaming_transpose_1_0_365", kUniqueId = 365 : i64, kUserCreated = true} : (tensor<256x1x1xbf16>) -> tensor<1x256xbf16>
          %76:2 = "tlir.Buffer"(%73) {DataLayout0 = #tlir.layout<DV,DM,VA>, DataLayout1 = #tlir.layout<DV,DM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = true, kIsImageBuffer = true, kIsReshapeBuffer = true, kIsSplitImageBuffer = false, kIsStageBuffer = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "gbuf2u_1_0_366", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 2 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReshapeBase = 0 : i64, kReshapeBound = 4 : i64, kReshapeInner = true, kReshapeVecInner = 5 : i64, kReshapeVecOuter = 3 : i64, kStageId = 6 : i64, kStageMultiplier = 1 : i64, kUniqueId = 366 : i64, kUserCreated = true} : (tensor<136x3x1xbf16>) -> (tensor<136x3x1xbf16>, tensor<136x3x1xbf16>)
          %77 = "tlir.Region"() {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayoutGatherInput = #tlir.layout<DV,DM,VA>, DataLayoutGatherOutput = #tlir.layout<CV,RM,VA>, DataPtrgather.list = [837888, 64], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = true, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [320, 3, 1], gather.base_mult = [1, 0, 0], gather.base_stride = [64, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = false, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 0 : i64, gather.fixed_length = 32 : i64, gather.group_packed = 15 : i64, gather.group_unpacked = 15 : i64, gather.input_vec_base = -1 : i64, gather.input_vec_bound = -1 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 3 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [160, 3], gather.offset_mult = [0, 1], gather.offset_stride = [32, 1], gather.output_mode = 1 : i64, gather.output_shape = [480, 1], gather.pace_shape = [32, 1], gather.permute = false, gather.reread = 1 : i64, gather.seg_length = 1 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 0 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 960 : i64, gather.total_unpacked = 15 : i64, gather.use_tile_counter = false, kConfigured = true, kGroup = 17 : i64, kHasShape = true, kIsDynamicLoadTable = false, kIsEmbeddingTable = false, kIsLoaded = true, kIsOneShotTransferred = true, kIsPlaceholder = false, kIsScatterNdTable = false, kIsScatterTable = false, kIsSliceLoaded = false, kIsSliceStored = false, kIsStored = false, kLayoutHeuristics = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "ptconvcnn__conv_layer__conv2d_bwd_conv_grad_stream0_kernel0__gather_list", kPlacementHint = [0, 1, 1, 0], kStageMultiplier = 1 : i64, kUniqueId = 367 : i64, kUserCreated = true} : () -> tensor<16xi32>
          %78 = "tlir.Load"(%77) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kConfigured = true, kGroup = 17 : i64, kGroupedDramLayoutName = "group_17", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_388", kName = "ptconvcnn__conv_layer__conv2d_bwd_conv_grad_stream0_kernel0__gather_list_1_0_388", kPlacementHint = [0, 1, 1, 0], kRequiresWBuf = false, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "load_1_0_388", kUniqueId = 388 : i64, kUseVectorTranspose = false, kUserCreated = false} : (tensor<16xi32>) -> tensor<16xi32>
          %79:2 = "tlir.Buffer"(%78) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 2 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "lbuf1a_1_0_405", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 405 : i64, kUserCreated = false} : (tensor<16xi32>) -> (tensor<16xi32>, tensor<16xi32>)
          %80 = "tlir.Gather"(%76#1, %79#1) {DataLayout0 = #tlir.layout<CV:UL,RM:UL,VA:UL>, DataLayoutGatherInput = #tlir.layout<DV,DM,VA>, DataLayoutGatherOutput = #tlir.layout<CV,RM,VA>, DataPtrgather.list = [837952, 64], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = true, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [320, 3, 1], gather.base_mult = [1, 0, 0], gather.base_stride = [64, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = false, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 0 : i64, gather.fixed_length = 32 : i64, gather.group_packed = 15 : i64, gather.group_unpacked = 15 : i64, gather.input_vec_base = -1 : i64, gather.input_vec_bound = -1 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 3 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [160, 3], gather.offset_mult = [0, 1], gather.offset_stride = [32, 1], gather.output_mode = 1 : i64, gather.output_shape = [480, 1], gather.pace_shape = [32, 1], gather.permute = false, gather.reread = 1 : i64, gather.seg_length = 1 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 0 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 960 : i64, gather.total_unpacked = 15 : i64, gather.use_tile_counter = false, kConfigured = true, kDepth2Col = false, kDepth2ColPointwise = false, kDepth2ColPointwiseGrad = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "gather368", kPaceMultiplier = 15 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kUniqueId = 368 : i64, kUserCreated = true} : (tensor<136x3x1xbf16>, tensor<16xi32>) -> tensor<480x1xbf16>
          %81:2 = "tlir.Buffer"(%80) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufferType = 6 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "sbuf2u_1_0_369", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kStageMultiplierBase = 1 : i64, kUniqueId = 369 : i64, kUserCreated = true} : (tensor<480x1xbf16>) -> (tensor<480x1xbf16>, tensor<480x1xbf16>)
          %82:4 = "tlir.Split"(%75) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, DataLayout2 = #tlir.layout<CV,RM,VA>, DataLayout3 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, NumSamples2 = 1 : i64, NumSamples2S = 2 : i64, NumSamples3 = 1 : i64, NumSamples3S = 2 : i64, kAxis = 1 : i64, kBufferDepth = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "split_kernel_gbuf_1_0_370", kPlacementHint = [0, 1, 1, 0], kPreferTBuffer = false, kSectionSizes = [72 : index, 72 : index, 72 : index, 40 : index], kSplitGemmReread = false, kSplitType = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "split_kernel_gbuf_1_0_370", kUniqueId = 370 : i64, kUserCreated = true} : (tensor<1x256xbf16>) -> (tensor<1x72xbf16>, tensor<1x72xbf16>, tensor<1x72xbf16>, tensor<1x40xbf16>)
          %83 = "tlir.Linear"(%81#1, %82#0) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "biggemm_1_0_371", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 0 : i64, kStageId = 6 : i64, kStageMultiplier = 15 : i64, kStageMultiplierBase = 15 : i64, kStreamingColPar = true, kTemplateName = "biggemm_1_0_371", kUniqueId = 371 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<480x1xbf16>, tensor<1x72xbf16>) -> tensor<480x72xbf16>
          %84 = "tlir.Linear"(%81#1, %82#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "biggemm_1_0_372", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 72 : i64, kStageId = 6 : i64, kStageMultiplier = 15 : i64, kStageMultiplierBase = 15 : i64, kStreamingColPar = true, kTemplateName = "biggemm_1_0_372", kUniqueId = 372 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<480x1xbf16>, tensor<1x72xbf16>) -> tensor<480x72xbf16>
          %85 = "tlir.Linear"(%81#1, %82#2) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "biggemm_1_0_373", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 144 : i64, kStageId = 6 : i64, kStageMultiplier = 15 : i64, kStageMultiplierBase = 15 : i64, kStreamingColPar = true, kTemplateName = "biggemm_1_0_373", kUniqueId = 373 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<480x1xbf16>, tensor<1x72xbf16>) -> tensor<480x72xbf16>
          %86 = "tlir.Linear"(%81#1, %82#3) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConcatGroup = 4 : i64, kConfigured = true, kHasWeight = false, kIgnoreLinearColParUpdate = true, kInputAIsWeight = false, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "biggemm_1_0_374", kNumColComputeUnits = 2 : i64, kNumPartitions = 1 : i64, kNumRowComputeUnits = 1 : i64, kPlacementHint = [0, 1, 1, 0], kReadAHead = 0 : i32, kReadBHead = 1 : i32, kSeqIdBase = 216 : i64, kStageId = 6 : i64, kStageMultiplier = 15 : i64, kStageMultiplierBase = 15 : i64, kStreamingColPar = true, kTemplateName = "biggemm_1_0_374", kUniqueId = 374 : i64, kUseBigGemm = true, kUserCreated = true, kWbufBlockInterleavedWrite = false, kWbufRepeat = 0 : i64, kWbufRepeatClipAt = 0 : i64, kWbufRepeatInterleaveSize = 0 : i64} : (tensor<480x1xbf16>, tensor<1x40xbf16>) -> tensor<480x40xbf16>
          %87 = "tlir.ConcatView"(%83, %84, %85, %86) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayoutkPreserveLayout = #tlir.layout<??,??,??>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAxis = 1 : i64, kConcatCollapse = false, kConcatGroup = 4 : i64, kConcatType = 1 : i64, kConfigured = true, kForceM = 0 : i64, kIntColParVectors = 72 : i64, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "concatview433", kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kTemplateName = "concat_view_1_0_433", kTimeSlices = [72, 72, 72, 40], kUniqueId = 433 : i64, kUserCreated = false} : (tensor<480x72xbf16>, tensor<480x72xbf16>, tensor<480x72xbf16>, tensor<480x40xbf16>) -> tensor<480x256xbf16>
          %88:2 = "tlir.Buffer"(%87) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsLowerForConcatView = true, kIsStageBuffer = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "gbuf2u_1_0_376", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 1 : i64, kNumPMUs = 1 : i64, kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kUniqueId = 376 : i64, kUserCreated = true} : (tensor<480x256xbf16>) -> (tensor<480x256xbf16>, tensor<480x256xbf16>)
          %89 = "tlir.ConcatView"(%88#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayoutkPreserveLayout = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAxis = 0 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "concatview377", kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kTemplateName = "concat_view_1_0_377", kUniqueId = 377 : i64, kUserCreated = true} : (tensor<480x256xbf16>) -> tensor<480x256xbf16>
          %90 = "tlir.BiasTransposeGrad"(%74#1) {DataLayout0 = #tlir.layout<DV,DM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "bias_transpose_grad_1_0_378", kStageId = 0 : i64, kStageMultiplier = 1 : i64, kStreaming = true, kTemplateName = "bias_transpose_grad_1_0_378", kUniqueId = 378 : i64, kUserCreated = true} : (tensor<256x1x1xbf16>) -> tensor<256x1x1xbf16>
          %91:2 = "tlir.Buffer"(%90) {DataLayout0 = #tlir.layout<DV,DM,VA>, DataLayout1 = #tlir.layout<DV,DM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = true, kHead1MultipleSample = false, kIsStageBuffer = true, kMacID = "default_406", kName = "gbuf2a_1_0_406", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 1 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 406 : i64, kUserCreated = false} : (tensor<256x1x1xbf16>) -> (tensor<256x1x1xbf16>, tensor<256x1x1xbf16>)
          %92 = "tlir.Reshape"(%91#1) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "reshape_1_0_379", kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "reshape_1_0_379", kUniqueId = 379 : i64, kUserCreated = true} : (tensor<256x1x1xbf16>) -> tensor<256x1xbf16>
          %93 = "tlir.LayoutCast"(%92) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayoutkOutputLayout = #tlir.layout<CV,RM,VA>, DataLayoutkRequiredLayout = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kChecked = false, kConfigured = true, kForced = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "layout_cast_1_0_380", kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "layout_cast_1_0_380", kUniqueId = 380 : i64, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1xbf16>
          "tlir.mutate.Accumulate"(%24, %65#0) {kAccumulatorStochasticRndSeed = 1 : i64, kChipID = 0 : i64, kConfigured = true, kEnableAccumulatorStochasticRnd = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_weight", kName = "ptconvcnn__dense_layer__linear_bwd_weight_accum", kNumPartitions = 32 : i64, kOpRWPattern0 = "kWriteOperand", kReadCredit = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "par_accum_1_0_263", kUniqueId = 263 : i64, kUserCreated = true} : (tensor<4080x256xbf16>, tensor<4080x256xbf16>) -> ()
          "tlir.mutate.Accumulate"(%25, %65#1) {kAccumulatorStochasticRndSeed = 1 : i64, kChipID = 0 : i64, kConfigured = true, kEnableAccumulatorStochasticRnd = false, kMacID = "ptconvcnn__dense_layer__linear_bwd_weight", kName = "ptconvcnn__dense_layer__linear_bwd_weight_accum_1", kNumPartitions = 32 : i64, kOpRWPattern0 = "kWriteOperand", kReadCredit = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "par_accum_1_0_264", kUniqueId = 264 : i64, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> ()
          "tlir.mutate.Accumulate"(%26, %89) {kAccumVersion = 3 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "ptconvcnn__conv_layer__conv2d_bwd_accum", kNumPartitions = 1 : i64, kOpRWPattern0 = "kWriteOperand", kPlacementHint = [0, 1, 1, 0], kStageId = 6 : i64, kStageMultiplier = 1 : i64, kTemplateName = "par_accum_1_0_265", kUniqueId = 265 : i64, kUserCreated = true} : (tensor<480x256xbf16>, tensor<480x256xbf16>) -> ()
          "tlir.mutate.Accumulate"(%27, %93) {kAccumVersion = 3 : i64, kChipID = 0 : i64, kConfigured = true, kMacID = "ptconvcnn__conv_layer__conv2d_bwd", kName = "ptconvcnn__conv_layer__conv2d_bwd_accum_1", kOpRWPattern0 = "kWriteOperand", kReadCredit = 1 : i64, kStageId = 0 : i64, kStageMultiplier = 1 : i64, kTemplateName = "par_accum_1_0_266", kUniqueId = 266 : i64, kUserCreated = true} : (tensor<256x1xbf16>, tensor<256x1xbf16>) -> ()
          "tlir.terminator"() {kConfigured = true, kMacID = "default_284", kName = "terminator284", kStageId = 0 : i64, kStageMultiplier = 1 : i64, kUniqueId = 284 : i64, kUserCreated = true} : () -> ()
        }) {kConfigured = true, kMacID = "default_224", kName = "metapipeline283", kNumIterations = 1 : i64, kStageId = 0 : i64, kUniqueId = 283 : i64, kUserCreated = true, type = none} : () -> ()
        "tlir.Store"(%17, %24) {kChipID = 0 : i64, kConfigured = true, kGroup = 32 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_144", kName = "ptconvcnn__dense_layer__linear_bwd_weight_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = false, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_1_0_144", kUniqueId = 144 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>, tensor<4080x256xbf16>) -> ()
        "tlir.Store"(%18, %25) {kChipID = 0 : i64, kConfigured = true, kGroup = 33 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_145", kName = "ptconvcnn__dense_layer__linear_bwd_weight_tensor1", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = false, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_1_0_145", kUniqueId = 145 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> ()
        %28:2 = "tlir.Buffer"(%26) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kChipID = 0 : i64, kConfigured = true, kDepth = 2 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsImageBuffer = true, kIsStageBuffer = false, kMacID = "default_157", kName = "gbuf2u_1_0_157", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 157 : i64, kUserCreated = true} : (tensor<480x256xbf16>) -> (tensor<480x256xbf16>, tensor<480x256xbf16>)
        %29 = "tlir.Load"(%21) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kConfigured = true, kGroup = 17 : i64, kGroupedDramLayoutName = "group_17", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_387", kName = "gather_gradient_output_reshape_id1__gather_list_1_0_387", kRequiresWBuf = false, kStageId = 0 : i64, kTemplateName = "load_1_0_387", kUniqueId = 387 : i64, kUseVectorTranspose = false, kUserCreated = false} : (tensor<96xi32>) -> tensor<96xi32>
        %30:2 = "tlir.Buffer"(%29) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 2 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_159", kName = "lbuf1a_1_0_407", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 407 : i64, kUserCreated = false} : (tensor<96xi32>) -> (tensor<96xi32>, tensor<96xi32>)
        %31 = "tlir.Gather"(%28#1, %30#1) {DataLayout0 = #tlir.layout<CV:UL,RM:UL,VA:UL>, DataLayoutGatherInput = #tlir.layout<CV,RM,VA>, DataLayoutGatherOutput = #tlir.layout<CV,RM,VA>, DataPtrgather.list = [384, 384], DataPtrgather.listS = 2 : i64, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, distribution = 9 : i32, gather.allow_oob = false, gather.allow_overflow = false, gather.base_list_tile_counters = 0 : i64, gather.base_max = [1, 13, 256, 3], gather.base_mult = [0, 0, 64, 0], gather.base_stride = [1, 1, 1, 1], gather.crush_par = 1 : i64, gather.depth2col = false, gather.depth_base_at = 1 : i64, gather.depth_group = 1 : i64, gather.depth_offset_at = 2 : i64, gather.filter_area = 0 : i64, gather.fixed_length = 0 : i64, gather.group_packed = 13 : i64, gather.group_unpacked = 39 : i64, gather.input_vec_base = -1 : i64, gather.input_vec_bound = -1 : i64, gather.input_vec_inner = -1 : i64, gather.input_vec_outer = -1 : i64, gather.list_length = 39 : i64, gather.list_tiles = 1 : i64, gather.num_channels = 136 : i64, gather.offset_list_tile_counters = 0 : i64, gather.offset_max = [1, 13, 256, 3], gather.offset_mult = [0, 3, 0, 1], gather.offset_stride = [1, 1, 1, 1], gather.output_mode = 0 : i64, gather.output_shape = [408, 256], gather.pace_shape = [], gather.permute = false, gather.reread = 1 : i64, gather.seg_length = 3 : i64, gather.streaming = 1 : i64, gather.streaming_repeat = 0 : i64, gather.surface_output_vectors = 0 : i64, gather.surface_par = 1 : i64, gather.swarm_par = 1 : i64, gather.tile_shape = [], gather.total_bytes = 212992 : i64, gather.total_unpacked = 9984 : i64, gather.use_tile_counter = false, kChipID = 0 : i64, kConfigured = true, kDisableReread = true, kMacID = "default_159", kName = "gather159", kStageId = 0 : i64, kUniqueId = 159 : i64, kUserCreated = true} : (tensor<480x256xbf16>, tensor<96xi32>) -> tensor<408x256xbf16>
        "tlir.Store"(%19, %27) {kChipID = 0 : i64, kConfigured = true, kGroup = 34 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_160", kName = "ptconvcnn__conv_layer__conv2d_bwd_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = false, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_1_0_160", kUniqueId = 160 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>, tensor<256x1xbf16>) -> ()
        %32:2 = "tlir.Buffer"(%31) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 6 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_408", kName = "sbuf1a_1_0_408", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 1 : i64, kStageId = 0 : i64, kUniqueId = 408 : i64, kUserCreated = false} : (tensor<408x256xbf16>) -> (tensor<408x256xbf16>, tensor<408x256xbf16>)
        %33 = "tlir.VectorTranspose"(%32#1) {DataLayout0 = #tlir.layout<CV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_426", kName = "vector_transpose_1_0_426", kStageId = 0 : i64, kTemplateName = "vector_transpose_1_0_426", kUniqueId = 426 : i64, kUserCreated = false} : (tensor<408x256xbf16>) -> tensor<408x256xbf16>
        %34 = "tlir.PermuteView"(%33) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_424", kName = "permute_view_1_0_424", kPermutation = [1, 0], kStageId = 0 : i64, kTemplateName = "permute_view_1_0_424", kUniqueId = 424 : i64, kUserCreated = false} : (tensor<408x256xbf16>) -> tensor<256x408xbf16>
        %35 = "tlir.Realign"(%34) {DataLayout0 = #tlir.layout<RV,RM,UA>, DataLayoutkInputLayout = #tlir.layout<RV,RM,VA>, DataLayoutkOutputLayout = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_427", kName = "realign_1_0_427", kStageId = 0 : i64, kTemplateName = "realign_1_0_427", kUniqueId = 427 : i64, kUserCreated = false} : (tensor<256x408xbf16>) -> tensor<256x408xbf16>
        %36 = "tlir.Reshape"(%35) {DataLayout0 = #tlir.layout<RV,RM,UA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__conv2d_weight_reshape_bwd", kName = "ptconvcnn__conv_layer__conv2d_weight_reshape_bwd", kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "reshape_1_0_381", kUniqueId = 381 : i64, kUserCreated = true} : (tensor<256x408xbf16>) -> tensor<256x3x1x136xbf16>
        %37 = "tlir.Realign"(%36) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayoutkInputLayout = #tlir.layout<RV,RM,UA>, DataLayoutkOutputLayout = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_428", kName = "realign_1_0_428", kStageId = 0 : i64, kTemplateName = "realign_1_0_428", kUniqueId = 428 : i64, kUserCreated = false} : (tensor<256x3x1x136xbf16>) -> tensor<256x3x1x136xbf16>
        %38 = "tlir.Permute"(%37) {DataLayout0 = #tlir.layout<RV,CM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_425", kName = "permute_1_0_425", kPermutation = [1 : index, 2 : index, 3 : index, 0 : index], kStageId = 0 : i64, kTemplateName = "permute_1_0_425", kUniqueId = 425 : i64, kUserCreated = false} : (tensor<256x3x1x136xbf16>) -> tensor<3x1x136x256xbf16>
        %39 = "tlir.Transpose"(%38) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kMacID = "default_429", kName = "transpose_1_0_429", kNoExperimentalHD = false, kStageId = 0 : i64, kTemplateName = "transpose_1_0_429", kTransposeType = 1 : i64, kUniqueId = 429 : i64, kUserCreated = false} : (tensor<3x1x136x256xbf16>) -> tensor<3x1x136x256xbf16>
        %40 = "tlir.Permute"(%39) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__conv2d_weight_permute_bwd", kName = "ptconvcnn__conv_layer__conv2d_weight_permute_bwd", kPermutation = [3 : index, 2 : index, 0 : index, 1 : index], kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "permute_1_0_382", kUniqueId = 382 : i64, kUserCreated = true} : (tensor<3x1x136x256xbf16>) -> tensor<256x136x3x1xbf16>
        %41 = "tlir.Reshape"(%40) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kConfigured = true, kDieID = -1 : i64, kIsCriticalStage = false, kLatency = 1.300000e+01 : f64, kMacID = "ptconvcnn__conv_layer__reshape_1_bwd", kName = "ptconvcnn__conv_layer__reshape_1_bwd", kStageId = 0 : i64, kStageLatency = 1.300000e+01 : f64, kTemplateName = "reshape_1_0_383", kUniqueId = 383 : i64, kUserCreated = true} : (tensor<256x136x3x1xbf16>) -> tensor<256x136x3xbf16>
        %42:2 = "tlir.Buffer"(%41) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kBufHead = 1 : i64, kBufferType = 1 : i64, kConfigured = true, kDepth = 1 : i64, kHead0CtrlFlowEnable = false, kHead1CtrlFlowEnable = false, kIsStageBuffer = false, kMacID = "default_409", kName = "gbuf1a_1_0_409", kNumHead0RdEn = 0 : i64, kNumHead1RdEn = 0 : i64, kNumPMUs = 6 : i64, kStageId = 0 : i64, kUniqueId = 409 : i64, kUserCreated = false} : (tensor<256x136x3xbf16>) -> (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>)
        "tlir.Store"(%20, %42#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 35 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_164", kName = "ptconvcnn__conv_layer__reshape_1_bwd_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = false, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_1_0_164", kUniqueId = 164 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>) -> ()
        "tlir.terminator"() {kConfigured = true, kMacID = "default_282", kName = "terminator282", kStageId = 0 : i64, kUniqueId = 282 : i64, kUserCreated = true} : () -> ()
      }) {kConfigured = true, kMacID = "default_281", kName = "chip1_0", kPartitionId = 0 : i64, kStageId = 0 : i64, kUniqueId = 281 : i64, kUserCreated = true, type = none} : () -> ()
      "tlir.terminator"() {kConfigured = true, kMacID = "default_165", kName = "terminator165", kStageId = 0 : i64, kUniqueId = 165 : i64, kUserCreated = true} : () -> ()
    }) {kConfigured = true, kGlobalId = 1 : i64, kIsHostSection = false, kMacID = "default_127", kName = "section1", kPartitionId = 1 : i64, kSectionLatency = 7.8274148108903319E-5 : f64, kSectionName = "$BCKWD", kSectionUniqueName = "ptconvcnn__reshape_1_recompute__as_initial", kStageId = 0 : i64, kUniqueId = 127 : i64, kUserCreated = true, type = none} : () -> ()
    "tlir.Section"() ( {
      "tlir.Chip"() ( {
        %21 = "tlir.Load"(%5) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 3 : i64, kGroupedDramLayoutName = "group_3", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_167", kName = "ptconvcnn__dense_layer__weight_2_0_167", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_167", kUniqueId = 167 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>) -> tensor<4080x256xbf16>
        %22 = "tlir.Load"(%17) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 14 : i64, kGroupedDramLayoutName = "group_14", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_168", kName = "ptconvcnn__dense_layer__weight__grad_2_0_168", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_168", kUniqueId = 168 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>) -> tensor<4080x256xbf16>
        %23 = "tlir.Load"(%9) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 12 : i64, kGroupedDramLayoutName = "group_12", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_169", kName = "ptconvcnn__dense_layer__weight__sgd0__momentum_2_0_169", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_169", kUniqueId = 169 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>) -> tensor<4080x256xbf16>
        %24:2 = "tlir.SGD"(%21, %23, %22) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kDecayArgInName = "weight_decay", kDecayRate = 3.0000001424923539E-4 : f64, kLrArgInName = "lr", kLrRate = 0.001500000013038516 : f64, kMacID = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt", kMixP = true, kMomentumArgInName = "momentum", kMomentumRate = 0.000000e+00 : f64, kName = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt", kStageId = 0 : i64, kStrndSeed = 43690 : i64, kStrndSeedArgInName = "strnd_seed", kTemplateName = "optimizer_sgd_2_0_170", kUniqueId = 170 : i64, kUserCreated = true} : (tensor<4080x256xbf16>, tensor<4080x256xbf16>, tensor<4080x256xbf16>) -> (tensor<4080x256xbf16>, tensor<4080x256xbf16>)
        "tlir.Store"(%5, %24#0) {kChipID = 0 : i64, kConfigured = true, kGroup = 3 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_171", kName = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_171", kUniqueId = 171 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>, tensor<4080x256xbf16>) -> ()
        "tlir.Store"(%9, %24#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 12 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_172", kName = "ptconvcnn__dense_layer__weight__ptconvcnn__dense_layer__linear_bwd_weight_opt_tensor1", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_172", kUniqueId = 172 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x256xbf16>, tensor<4080x256xbf16>) -> ()
        %25 = "tlir.Load"(%4) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 11 : i64, kGroupedDramLayoutName = "group_11", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_173", kName = "ptconvcnn__dense_layer__bias_2_0_173", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_173", kUniqueId = 173 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
        %26 = "tlir.Load"(%18) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 15 : i64, kGroupedDramLayoutName = "group_15", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_174", kName = "ptconvcnn__dense_layer__bias__grad_2_0_174", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_174", kUniqueId = 174 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
        %27 = "tlir.Load"(%10) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kGroupedDramLayoutName = "group_13", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_175", kName = "ptconvcnn__dense_layer__bias__sgd0__momentum_2_0_175", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_175", kUniqueId = 175 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>) -> tensor<4080x1xbf16>
        %28:2 = "tlir.SGD"(%25, %27, %26) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kDecayArgInName = "weight_decay", kDecayRate = 3.0000001424923539E-4 : f64, kLrArgInName = "lr", kLrRate = 0.001500000013038516 : f64, kMacID = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt", kMixP = true, kMomentumArgInName = "momentum", kMomentumRate = 0.000000e+00 : f64, kName = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt", kStageId = 0 : i64, kStrndSeed = 43690 : i64, kStrndSeedArgInName = "strnd_seed", kTemplateName = "optimizer_sgd_2_0_176", kUniqueId = 176 : i64, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> (tensor<4080x1xbf16>, tensor<4080x1xbf16>)
        "tlir.Store"(%4, %28#0) {kChipID = 0 : i64, kConfigured = true, kGroup = 11 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_177", kName = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_177", kUniqueId = 177 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> ()
        "tlir.Store"(%10, %28#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_178", kName = "ptconvcnn__dense_layer__bias__ptconvcnn__dense_layer__linear_bwd_weight_opt_tensor1", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_178", kUniqueId = 178 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<4080x1xbf16>, tensor<4080x1xbf16>) -> ()
        %29 = "tlir.Load"(%3) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 2 : i64, kGroupedDramLayoutName = "group_2", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_179", kName = "ptconvcnn__conv_layer__bias_2_0_179", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_179", kUniqueId = 179 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1xbf16>
        %30 = "tlir.Load"(%19) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 15 : i64, kGroupedDramLayoutName = "group_15", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_180", kName = "ptconvcnn__conv_layer__bias__grad_2_0_180", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_180", kUniqueId = 180 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1xbf16>
        %31 = "tlir.Load"(%11) {DataLayout0 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kGroupedDramLayoutName = "group_13", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_181", kName = "ptconvcnn__conv_layer__bias__sgd0__momentum_2_0_181", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_181", kUniqueId = 181 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>) -> tensor<256x1xbf16>
        %32:2 = "tlir.SGD"(%29, %31, %30) {DataLayout0 = #tlir.layout<CV,RM,VA>, DataLayout1 = #tlir.layout<CV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kDecayArgInName = "weight_decay", kDecayRate = 3.0000001424923539E-4 : f64, kLrArgInName = "lr", kLrRate = 0.001500000013038516 : f64, kMacID = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt", kMixP = true, kMomentumArgInName = "momentum", kMomentumRate = 0.000000e+00 : f64, kName = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt", kStageId = 0 : i64, kStrndSeed = 43690 : i64, kStrndSeedArgInName = "strnd_seed", kTemplateName = "optimizer_sgd_2_0_182", kUniqueId = 182 : i64, kUserCreated = true} : (tensor<256x1xbf16>, tensor<256x1xbf16>, tensor<256x1xbf16>) -> (tensor<256x1xbf16>, tensor<256x1xbf16>)
        "tlir.Store"(%3, %32#0) {kChipID = 0 : i64, kConfigured = true, kGroup = 2 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_183", kName = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_183", kUniqueId = 183 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>, tensor<256x1xbf16>) -> ()
        "tlir.Store"(%11, %32#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_184", kName = "ptconvcnn__conv_layer__bias__ptconvcnn__conv_layer__conv2d_bwd_opt_tensor1", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_184", kUniqueId = 184 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x1xbf16>, tensor<256x1xbf16>) -> ()
        %33 = "tlir.Load"(%0) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 10 : i64, kGroupedDramLayoutName = "group_10", kIsGrouped = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_185", kName = "ptconvcnn__conv_layer__weight_2_0_185", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_185", kUniqueId = 185 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>) -> tensor<256x136x3xbf16>
        %34 = "tlir.Load"(%20) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 15 : i64, kGroupedDramLayoutName = "group_15", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_186", kName = "ptconvcnn__conv_layer__weight__grad_2_0_186", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_186", kUniqueId = 186 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>) -> tensor<256x136x3xbf16>
        %35 = "tlir.Load"(%12) {DataLayout0 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, kAddedAlignment = -1 : i64, kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kGroupedDramLayoutName = "group_13", kIsGrouped = true, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_187", kName = "ptconvcnn__conv_layer__weight__sgd0__momentum_2_0_187", kRequiresWBuf = true, kStageId = 0 : i64, kTemplateName = "load_2_0_187", kUniqueId = 187 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>) -> tensor<256x136x3xbf16>
        %36:2 = "tlir.SGD"(%33, %35, %34) {DataLayout0 = #tlir.layout<RV,RM,VA>, DataLayout1 = #tlir.layout<RV,RM,VA>, NumSamples0 = 1 : i64, NumSamples0S = 2 : i64, NumSamples1 = 1 : i64, NumSamples1S = 2 : i64, kChipID = 0 : i64, kConfigured = true, kDecayArgInName = "weight_decay", kDecayRate = 3.0000001424923539E-4 : f64, kLrArgInName = "lr", kLrRate = 0.001500000013038516 : f64, kMacID = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt", kMixP = true, kMomentumArgInName = "momentum", kMomentumRate = 0.000000e+00 : f64, kName = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt", kStageId = 0 : i64, kStrndSeed = 43690 : i64, kStrndSeedArgInName = "strnd_seed", kTemplateName = "optimizer_sgd_2_0_188", kUniqueId = 188 : i64, kUserCreated = true} : (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>, tensor<256x136x3xbf16>) -> (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>)
        "tlir.Store"(%0, %36#0) {kChipID = 0 : i64, kConfigured = true, kGroup = 10 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_189", kName = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_tensor", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_189", kUniqueId = 189 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>) -> ()
        "tlir.Store"(%12, %36#1) {kChipID = 0 : i64, kConfigured = true, kGroup = 13 : i64, kIsCheckPoint = false, kIterations = 1 : i64, kLayoutHeuristics = false, kMacID = "default_190", kName = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_tensor1", kOpRWPattern0 = "kWriteOperand", kRemovesAlignment = false, kRequiresWBuf = true, kSliceAxes = [], kStageId = 0 : i64, kStoreSlice = false, kTemplateName = "store_2_0_190", kUniqueId = 190 : i64, kUseVectorTranspose = false, kUserCreated = true} : (tensor<256x136x3xbf16>, tensor<256x136x3xbf16>) -> ()
        "tlir.terminator"() {kConfigured = true, kMacID = "default_286", kName = "terminator286", kStageId = 0 : i64, kUniqueId = 286 : i64, kUserCreated = true} : () -> ()
      }) {kConfigured = true, kMacID = "default_285", kName = "chip2_0", kPartitionId = 0 : i64, kStageId = 0 : i64, kUniqueId = 285 : i64, kUserCreated = true, type = none} : () -> ()
      "tlir.terminator"() {kConfigured = true, kMacID = "default_191", kName = "terminator191", kStageId = 0 : i64, kUniqueId = 191 : i64, kUserCreated = true} : () -> ()
    }) {kConfigured = true, kGlobalId = 2 : i64, kIsHostSection = false, kMacID = "default_166", kName = "section2", kPartitionId = 2 : i64, kSectionLatency = 1.4240607561077923E-4 : f64, kSectionName = "$OPT", kSectionUniqueName = "ptconvcnn__conv_layer__weight__ptconvcnn__conv_layer__reshape_1_bwd_opt_as_initial", kStageId = 0 : i64, kUniqueId = 166 : i64, kUserCreated = true, type = none} : () -> ()
  }
  module @schedule  {
  }
  module @rnn_function  {
  }
}
