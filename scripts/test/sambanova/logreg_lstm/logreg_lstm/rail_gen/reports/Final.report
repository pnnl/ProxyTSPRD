========= Summary IR ========
tbuffer partition_0_0__tbuf2u_0_0_334
    loc("LogregTorchSamba.cpp":923:0)
    layout: <BF16[60, 64]RVCM/64@0x0> vec_order: {1, 0} vec_dim: 1 depth: 2 dims: {60, 64}
    pmu: D_0_0 depth: 2 capacity: 3840 (words) is_transpose: 0
        uctx: D_0_0.kDefaultWrite
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (120 # steps): 
                  iter[0] : (0 until 3840 by 64)
                  iter[1] : (0 until 7680 by 3840)
                ctx done: L0(kDefaultWrite_iter0,) (120 # steps)
            addresses:
                addr : ((0 until 7680 by 3840).c1 + (0 until 3840 by 64).c0)
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(kDefaultWrite_iter0,)
                cout[wdone__] - src: L0(kDefaultWrite_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_0_0_.ptconvlstm__indexselect@kLutRd
            loc("software/templates/src/templates/index/rail/Index.cpp":137:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 7680 by 3840)
                ctx done: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kLutRd_iter0,) (2 # steps)
            addresses:
                addr : (sin[idx] * 64 + (0 until 7680 by 3840).c0)
                ofst : 0
                pred : cast<UInt32>((sin[idx] >= 60))
                vec = 1
            triggers:
                sin[idx] - popif: ctx_en
                tb init: 1 pushif: cin[0] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kLutRd_iter0,)
                tb init: 2 pushif: cin[1] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kLutRd_iter0,)
                tb init: 0 pushif: cin[kDefaultWrite_wdone_in__] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kLutRd_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kLutRd_iter0,)
========= Summary IR ========
tbuffer partition_0_0__rbuf1u_0_0_335
    loc("LogregTorchSamba.cpp":934:0)
    layout: <INT32[1]RM@0x0> vec_order: {0} vec_dim: 0 depth: 1 dims: {1}
    pmu: D_0_0 depth: 1 capacity: 16 (words) is_transpose: 0
        uctx: D_0_0.kFrontDynamicWriteCtx
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {1} 
            iter_chains:
                addr_chain  (1 # steps): 
                  iter[0] : (0 until 1 by 16)
                ctx done: L0(kFrontDynamicWriteCtx_iter0,) (1 # steps)
            addresses:
                addr : 0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(kFrontDynamicWriteCtx_iter0,)
                cout[wdone__] - src: L0(kFrontDynamicWriteCtx_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_0_0_.ptconvlstm__indexselect@kIndexRd
            loc("software/templates/src/templates/index/rail/Index.cpp":124:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 64 by 32)
                ctx done: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kIndexRd_iter0,) (200 # steps)
            addresses:
                addr : 0
                ofst : 0
                pred : 0
                vec = 0
            triggers:
                tb init: 1 pushif: cin[0] popif: L1(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kIndexRd_iter1,)
                tb init: 2 pushif: cin[1] popif: L1(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kIndexRd_iter1,)
                tb init: 0 pushif: cin[kFrontDynamicWriteCtx_wdone_in__] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kIndexRd_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kIndexRd_iter0,)
========= Summary IR ========
tbuffer partition_0_0__tbuf2u_0_0_342
    loc("LogregTorchSamba.cpp":958:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 2 dims: {64, 1}
    pmu: D_0_0 depth: 2 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0.LogregTorchSamba.partition_0_0_.ptconvlstm__indexselect@kOutWr
            loc("software/templates/src/templates/index/rail/Index.cpp":161:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kOutWr_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kOutWr_iter0,)
                cout[wdone__] - src: L0(LogregTorchSamba_partition_0_0__ptconvlstm__indexselect_kOutWr_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_0_0_.ptconvlstm__dense_layer__linear@kFwdPropB
            loc("software/templates/src/templates/gemm/prism/GemmSubnet.cpp":2012:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (256 # steps): 
                  iter[0] : (0 until 128 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(LogregTorchSamba_partition_0_0__ptconvlstm__dense_layer__linear_kFwdPropB_iter0,) (256 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 1 pushif: cin[0] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__dense_layer__linear_kFwdPropB_iter0,)
                tb init: 2 pushif: cin[1] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__dense_layer__linear_kFwdPropB_iter0,)
                tb init: 0 pushif: cin[LogregTorchSamba.partition_0_0_.ptconvlstm__indexselect@kOutWr_wdone_in__] popif: L0(LogregTorchSamba_partition_0_0__ptconvlstm__dense_layer__linear_kFwdPropB_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_0_0__ptconvlstm__dense_layer__linear_kFwdPropB_iter0,)
========= Summary IR ========
tbuffer partition_1_0__tbuf2u_1_0_401
    loc("LogregTorchSamba.cpp":2497:0)
    layout: <BF16[60, 64]RVCM/64@0x0> vec_order: {1, 0} vec_dim: 1 depth: 2 dims: {60, 64}
    pmu: D_0_0 depth: 2 capacity: 3840 (words) is_transpose: 0
        uctx: D_0_0.kDefaultWrite
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (120 # steps): 
                  iter[0] : (0 until 7680 by 64)
                ctx done: L0(kDefaultWrite_iter0,) (120 # steps)
            addresses:
                addr : (0 until 7680 by 64).c0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(kDefaultWrite_iter0,)
                cout[wdone__] - src: L0(kDefaultWrite_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kLutRd
            loc("software/templates/src/templates/index/rail/Index.cpp":137:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 7680 by 3840)
                ctx done: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,) (2 # steps)
            addresses:
                addr : (sin[idx] * 64 + (0 until 7680 by 3840).c0)
                ofst : 0
                pred : cast<UInt32>((sin[idx] >= 60))
                vec = 1
            triggers:
                sin[idx] - popif: ctx_en
                tb init: 1 pushif: cin[0] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
                tb init: 1 pushif: cin[1] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
                tb init: 2 pushif: cin[2] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
                tb init: 2 pushif: cin[3] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
                tb init: 0 pushif: cin[kDefaultWrite_wdone_in__] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kLutRd_iter0,)
========= Summary IR ========
tbuffer partition_1_0__rbuf1u_1_0_402
    loc("LogregTorchSamba.cpp":2508:0)
    layout: <INT32[1]RM@0x0> vec_order: {0} vec_dim: 0 depth: 1 dims: {1}
    pmu: D_0_0 depth: 1 capacity: 16 (words) is_transpose: 0
        uctx: D_0_0.kFrontDynamicWriteCtx
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {1} 
            iter_chains:
                addr_chain  (1 # steps): 
                  iter[0] : (0 until 1 by 16)
                ctx done: L0(kFrontDynamicWriteCtx_iter0,) (1 # steps)
            addresses:
                addr : 0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(kFrontDynamicWriteCtx_iter0,)
                cout[wdone__] - src: L0(kFrontDynamicWriteCtx_iter0,)
        uctx: D_0_0.kDefaultRead1
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            pacing_window: 1 port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (100 # steps): 
                  iter[0] : (0 until 100 by 1)
                ctx done: L0(kDefaultRead1_addr_chain_iter0,) (100 # steps)
                pacing_chain  (1 # steps): 
                  iter[0] : (0 until 1 by 1)
            addresses:
                addr : 0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 2 pushif: cin[0] popif: L1(kDefaultRead1_pacing_chain_iter0,)
                tb init: 12 pushif: cin[1] popif: L1(kDefaultRead1_pacing_chain_iter0,)
                tb init: 2 pushif: cin[2] popif: L1(kDefaultRead1_pacing_chain_iter0,)
                tb init: 12 pushif: cin[3] popif: L1(kDefaultRead1_pacing_chain_iter0,)
                tb init: 0 pushif: cin[kFrontDynamicWriteCtx_wdone_in__] popif: L0(kDefaultRead1_addr_chain_iter0,)
                cout[1000] - src: L0(kDefaultRead1_addr_chain_iter0,)
========= Summary IR ========
tbuffer partition_1_0__tbuf2a_1_0_850
    loc("LogregTorchSamba.cpp":2519:0)
    layout: <INT32[1]RM@0x0> vec_order: {0} vec_dim: 0 depth: 2 dims: {1}
    pmu: D_0_0 depth: 2 capacity: 16 (words) is_transpose: 0
        uctx: D_0_0.kDefaultWrite
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (1 # steps): 
                  iter[0] : (0 until 1 by 16)
                ctx done: L0(kDefaultWrite_iter0,) (1 # steps)
            addresses:
                addr : 0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(kDefaultWrite_iter0,)
                cout[wdone__] - src: L0(kDefaultWrite_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kIndexRd
            loc("software/templates/src/templates/index/rail/Index.cpp":124:0)
            pacing_window: 1 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 64 by 32)
                ctx done: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,) (2 # steps)
            addresses:
                addr : 0
                ofst : 0
                pred : 0
                vec = 0
            triggers:
                tb init: 1 pushif: cin[0] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
                tb init: 1 pushif: cin[1] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
                tb init: 2 pushif: cin[2] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
                tb init: 2 pushif: cin[3] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
                tb init: 0 pushif: cin[kDefaultWrite_wdone_in__] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kIndexRd_iter0,)
========= Summary IR ========
tbuffer partition_1_0__tbuf2u_1_0_406
    loc("LogregTorchSamba.cpp":2543:0)
    layout: <BF16[1, 64]RVCM/64@0x0> vec_order: {1, 0} vec_dim: 1 depth: 2 dims: {1, 64}
    pmu: D_0_0 depth: 2 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0.LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kOutWr
            loc("software/templates/src/templates/index/rail/Index.cpp":161:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,)
                cout[wdone__] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,)
        uctx: D_0_0.kDefaultRead1
            loc("software/compiler/rail/src/lib/node/tbuffer/TBufferContext.cpp":469:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kDefaultRead1_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 1 pushif: cin[0] popif: L0(kDefaultRead1_iter0,)
                tb init: 7 pushif: cin[1] popif: L0(kDefaultRead1_iter0,)
                tb init: 0 pushif: cin[LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kOutWr_wdone_in__] popif: L0(kDefaultRead1_iter0,)
                cout[1000] - src: L0(kDefaultRead1_iter0,)
========= Summary IR ========
tbuffer partition_1_0__tbuf2u_1_0_409
    loc("LogregTorchSamba.cpp":2565:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 2 dims: {64, 1}
    pmu: D_0_0 depth: 2 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0.LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kOutWr
            loc("software/templates/src/templates/index/rail/Index.cpp":161:0)
            port: WRITE ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[1000] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,)
                cout[wdone__] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__indexselect_recompute__kOutWr_iter0,)
        uctx: D_0_0.LogregTorchSamba.partition_1_0_.ptconvlstm__dense_layer__linear_recompute_@kFwdPropB
            loc("software/templates/src/templates/gemm/prism/GemmSubnet.cpp":2012:0)
            pacing_window: 2 port: READ0 ctxid: 0 metapipe_iter (post divider): {100} 
            iter_chains:
                addr_chain  (256 # steps): 
                  iter[0] : (0 until 128 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_recompute__kFwdPropB_iter0,) (256 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 1 pushif: cin[0] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_recompute__kFwdPropB_iter0,)
                tb init: 2 pushif: cin[1] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_recompute__kFwdPropB_iter0,)
                tb init: 0 pushif: cin[LogregTorchSamba.partition_1_0_.ptconvlstm__indexselect_recompute_@kOutWr_wdone_in__] popif: L0(LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_recompute__kFwdPropB_iter0,)
                cout[1000] - src: L0(LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_recompute__kFwdPropB_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_bwd_weight_accum_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[262144, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {262144, 1}
    pmu: D_0_0_0 depth: 1 capacity: 262144 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (819200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 524288 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (8192 # steps)
            addresses:
                addr : (0 until 524288 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 1024 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (811008 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 524288 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (8192 # steps)
            addresses:
                addr : (0 until 524288 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 8192 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (8192 # steps): 
                  iter[0] : (0 until 524288 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (8192 # steps)
            addresses:
                addr : (0 until 524288 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                tb init: 1 pushif: cin[pacing_in] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__dense_layer__linear_bwd_weight_accum_1_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[4096, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {4096, 1}
    pmu: D_0_0_0 depth: 1 capacity: 4096 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12800 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12672 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (128 # steps): 
                  iter[0] : (0 until 8192 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                tb init: 4 pushif: cin[pacing_in] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[4096, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {4096, 1}
    pmu: D_0_0_0 depth: 1 capacity: 4096 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12800 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12672 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (128 # steps): 
                  iter[0] : (0 until 8192 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_1_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[4096, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {4096, 1}
    pmu: D_0_0_0 depth: 1 capacity: 4096 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12800 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12672 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (128 # steps): 
                  iter[0] : (0 until 8192 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_2_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[4096, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {4096, 1}
    pmu: D_0_0_0 depth: 1 capacity: 4096 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12800 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12672 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (128 # steps): 
                  iter[0] : (0 until 8192 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_3_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[4096, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {4096, 1}
    pmu: D_0_0_0 depth: 1 capacity: 4096 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12800 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (12672 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 8192 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (128 # steps): 
                  iter[0] : (0 until 8192 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (128 # steps)
            addresses:
                addr : (0 until 8192 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_4_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[8704, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {8704, 1}
    pmu: D_0_0_0 depth: 1 capacity: 8704 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (27200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (26928 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (272 # steps): 
                  iter[0] : (0 until 17408 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_5_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[8704, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {8704, 1}
    pmu: D_0_0_0 depth: 1 capacity: 8704 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (27200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (26928 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (272 # steps): 
                  iter[0] : (0 until 17408 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_6_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[8704, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {8704, 1}
    pmu: D_0_0_0 depth: 1 capacity: 8704 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (27200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (26928 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (272 # steps): 
                  iter[0] : (0 until 17408 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_7_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[8704, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {8704, 1}
    pmu: D_0_0_0 depth: 1 capacity: 8704 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (27200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 128 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (26928 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 17408 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 128 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (272 # steps): 
                  iter[0] : (0 until 17408 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (272 # steps)
            addresses:
                addr : (0 until 17408 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_8_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_9_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_10_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_11_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_12_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_13_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_14_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
========= Summary IR ========
tbuffer partition_1_0__LogregTorchSamba_partition_1_0__ptconvlstm__lstm_layer__lstm_bwd_accum_15_tbuf
    loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":578:0)
    layout: <BF16[64, 1]CVRM/64@0x0> vec_order: {0, 1} vec_dim: 0 depth: 1 dims: {64, 1}
    pmu: D_0_0_0 depth: 1 capacity: 64 (words) is_transpose: 0
        uctx: D_0_0_0.w_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":424:0)
            disable_full_stall port: WRITE ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (200 # steps): 
                  iter[0] : (0 until 100 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(w_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 2
                vec = 1
            triggers:
                vin[8] - popif: ctx_en
                cout[w_loop_done] - src: L1(w_loop_0_0_iter0,)
                cout[w_loop_special_done] - src: L0(w_loop_0_0_iter1,)
                cout[1000] - src: L0(w_loop_0_0_iter1,)
        uctx: D_0_0_0.r_loop_0_0
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":473:0)
            pacing_window: 2 disable_empty_stall port: READ1 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (198 # steps): 
                  iter[0] : (0 until 99 by 1)
                  iter[1] : (0 until 128 by 64)
                ctx done: L0(r_loop_0_0_iter1,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c1
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_loop_special_done_in] popif: (L0(r_loop_0_0_iter1,) || cin[r_drain_done_in])
                tb init: 1 pushif: cin[not_last] popif: L1(r_loop_0_0_iter0,)
                cout[1000] - src: L0(r_loop_0_0_iter1,)
        uctx: D_0_0_0.kBackReadCtx
            loc("software/templates/src/templates/accumulator/rail/ParAccum.cpp":629:0)
            pacing_window: 2 disable_empty_stall port: READ0 ctxid: 0 metapipe_iter (post divider): {1} metapipe_divider: {100} 
            iter_chains:
                addr_chain  (2 # steps): 
                  iter[0] : (0 until 128 by 64)
                ctx done: L0(kBackReadCtx_iter0,) (2 # steps)
            addresses:
                addr : (0 until 128 by 64).c0
                ofst : 0
                pred : 0
                vec = 1
            triggers:
                tb init: 0 pushif: cin[w_done_in_0_0] popif: L0(kBackReadCtx_iter0,)
                cout[r_drain_done] - src: L0(kBackReadCtx_iter0,)
                cout[1000] - src: L0(kBackReadCtx_iter0,)
