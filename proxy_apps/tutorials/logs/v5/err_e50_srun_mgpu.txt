Now you should run one of the following depending on your shell
source /share/apps/python/anaconda3.2019.3/etc/profile.d/conda.sh
source /share/apps/python/anaconda3.2019.3/etc/profile.d/conda.csh
2021-05-12 23:51:32.221097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 23:51:59.524047: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:51:59.552185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-05-12 23:52:00.233115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:07:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.235403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.237597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.239774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.242008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: 
pciBusID: 0000:87:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.244208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: 
pciBusID: 0000:90:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.246398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: 
pciBusID: 0000:b7:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.248583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: 
pciBusID: 0000:bd:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:00.248607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 23:52:00.837674: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 23:52:00.837720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-12 23:52:01.237660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-12 23:52:01.928223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-12 23:52:02.282615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-12 23:52:02.628335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-12 23:52:02.836877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-12 23:52:02.872161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2021-05-12 23:52:02.872988: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.875280: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.877468: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.879652: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.881839: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.884044: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.886426: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.888605: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:02.912070: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-12 23:52:02.929438: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-05-12 23:52:04.010917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:07:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.013055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:0f:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.015169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:47:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.017280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:4e:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.019389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: 
pciBusID: 0000:87:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.021493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: 
pciBusID: 0000:90:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.023597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: 
pciBusID: 0000:b7:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.025713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: 
pciBusID: 0000:bd:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-05-12 23:52:04.025751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 23:52:04.025783: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 23:52:04.025801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-12 23:52:04.025813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-05-12 23:52:04.025822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-05-12 23:52:04.025831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-05-12 23:52:04.025839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-05-12 23:52:04.025849: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-05-12 23:52:04.060675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2021-05-12 23:52:04.060710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-05-12 23:52:08.965478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-12 23:52:08.965558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 
2021-05-12 23:52:08.965572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y 
2021-05-12 23:52:08.965577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y 
2021-05-12 23:52:08.965581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y 
2021-05-12 23:52:08.965586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y 
2021-05-12 23:52:08.965590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y 
2021-05-12 23:52:08.965594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y 
2021-05-12 23:52:08.965598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y 
2021-05-12 23:52:08.965603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N 
2021-05-12 23:52:08.988183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 37571 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:07:00.0, compute capability: 8.0)
2021-05-12 23:52:08.994160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 37571 MB memory) -> physical GPU (device: 1, name: A100-SXM4-40GB, pci bus id: 0000:0f:00.0, compute capability: 8.0)
2021-05-12 23:52:08.999109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 37571 MB memory) -> physical GPU (device: 2, name: A100-SXM4-40GB, pci bus id: 0000:47:00.0, compute capability: 8.0)
2021-05-12 23:52:09.004415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 37571 MB memory) -> physical GPU (device: 3, name: A100-SXM4-40GB, pci bus id: 0000:4e:00.0, compute capability: 8.0)
2021-05-12 23:52:09.010011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 37571 MB memory) -> physical GPU (device: 4, name: A100-SXM4-40GB, pci bus id: 0000:87:00.0, compute capability: 8.0)
2021-05-12 23:52:09.015004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 37571 MB memory) -> physical GPU (device: 5, name: A100-SXM4-40GB, pci bus id: 0000:90:00.0, compute capability: 8.0)
2021-05-12 23:52:09.019818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 37571 MB memory) -> physical GPU (device: 6, name: A100-SXM4-40GB, pci bus id: 0000:b7:00.0, compute capability: 8.0)
2021-05-12 23:52:09.024826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 37571 MB memory) -> physical GPU (device: 7, name: A100-SXM4-40GB, pci bus id: 0000:bd:00.0, compute capability: 8.0)
2021-05-12 23:52:09.435808: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-05-12 23:52:09.436382: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2245830000 Hz
2021-05-12 23:52:12.032924: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-05-12 23:52:12.033316: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2021-05-12 23:52:12.033355: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 8 GPUs
2021-05-12 23:52:12.041040: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcupti.so.11.0'; dlerror: libcupti.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/apps/cuda/11.0/lib:/share/apps/cuda/11.0/lib64:/usr/lib64/:/share/apps/python/anaconda3.2019.3/lib:/share/apps/cuda/11.0/lib64/stubs
2021-05-12 23:52:12.099350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so
2021-05-12 23:52:13.429855: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-05-12 23:52:13.430042: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-05-12 23:52:15.219475: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_8"
op: "FlatMapDataset"
input: "ParallelMapDatasetV2/_7"
attr {
  key: "Targuments"
  value {
    list {
    }
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_Dataset_flat_map_lambda_195"
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 136
        }
      }
    }
  }
}
attr {
  key: "output_types"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
2021-05-12 23:52:27.880067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-05-12 23:52:29.772397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-05-12 23:52:36.108334: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2021-05-12 23:52:43.837425: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2021-05-12 23:52:43.837828: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_begin` time: 0.5529s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.0370s). Check your callbacks.
2021-05-12 23:52:47.417685: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.
2021-05-12 23:52:47.479232: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2021-05-12 23:52:47.874074: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:228]  GpuTracer has collected 26210 callback api events and 26234 activity events. 
2021-05-12 23:52:48.690933: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2021-05-12 23:52:49.356854: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48
2021-05-12 23:52:49.930808: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.trace.json.gz
2021-05-12 23:52:50.490672: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48
2021-05-12 23:52:50.551044: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.memory_profile.json.gz
2021-05-12 23:52:50.743065: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48Dumped tool data for xplane.pb to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.xplane.pb
Dumped tool data for overview_page.pb to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.overview_page.pb
Dumped tool data for input_pipeline.pb to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to /qfs/people/jain432/pacer/logs/fit_v6/e20_TFDataOptMPMGPU_20210512-235202/train/plugins/profile/2021_05_12_23_52_48/a100-03.kernel_stats.pb

2021-05-12 23:53:51.096038: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: "FlatMapDataset/_8"
op: "FlatMapDataset"
input: "ParallelMapDatasetV2/_7"
attr {
  key: "Targuments"
  value {
    list {
    }
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_Dataset_flat_map_lambda_170"
    }
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 136
        }
      }
    }
  }
}
attr {
  key: "output_types"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.
Traceback (most recent call last):
  File "./t4_TimeSeriesPrediction_MultipleGPUs.py", line 271, in <module>
    Psi_X, PSI_X, Psi_Y, PSI_Y, Kloss = K_model.predict(test_data)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 1629, in predict
    tmp_batch_outputs = self.predict_function(iterator)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 871, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 726, in _initialize
    *args, **kwds))
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 2969, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3361, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3206, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 990, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 634, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 977, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *
        return step_function(self, iterator)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1470 step_function  **
        outputs, self.distribute_strategy, reduction='concat')
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2707 reduce_per_replica
        return nest.map_structure(_reduce, values)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/util/nest.py:659 map_structure
        structure[0], [func(*x) for x in entries],
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/util/nest.py:659 <listcomp>
        structure[0], [func(*x) for x in entries],
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2703 _reduce
        return concat(strategy.unwrap(v))
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2716 concat
        return array_ops.concat(tensors, axis=axis)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1677 concat
        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:1208 concat_v2
        "ConcatV2", values=values, axis=axis, name=name)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal
        compute_device)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal
        op_def=op_def)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:2016 __init__
        control_input_ops, op_def)
    /people/jain432/.conda/envs/pacer_ml_grid/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op
        raise ValueError(str(e))

    ValueError: Can't concatenate scalars (use tf.stack instead) for '{{node concat_6}} = ConcatV2[N=8, T=DT_FLOAT, Tidx=DT_INT32](norm/Squeeze, replica_1/norm/Squeeze, replica_2/norm/Squeeze, replica_3/norm/Squeeze, replica_4/norm/Squeeze, replica_5/norm/Squeeze, replica_6/norm/Squeeze, replica_7/norm/Squeeze, concat_6/axis)' with input shapes: [], [], [], [], [], [], [], [], [].

